

# 八、构建提取转换机器学习用例

类似于 [*第 7 章*](B17343_07_Final_JC_ePub.xhtml#_idTextAnchor141) ，*构建一个示例 ML 微服务*，本章的目的是尝试将我们在本书中学到的许多工具和技术具体化，并将它们应用到现实场景中。这将基于 [*第 1 章*](B17343_01_Final_JC_ePub.xhtml#_idTextAnchor014) 、*ML 工程简介*中介绍的另一个用例，其中我们设想需要在预定的基础上对出租车乘坐数据进行聚类。我们将探讨这一场景，以便我们能够概述在现实中构建解决方案时我们将做出的关键决策，并讨论如何利用其他章节中介绍的内容来实现它。

这个用例将允许我们探索世界上**机器学习** ( **ML** )解决方案中最常用的模式——批量推理过程。由于检索、转换，然后对数据执行 ML 的性质，我将这种提取转换机器学习称为**提取转换机器学习** ( **ETML** )。

我们将遵循与 [*第 7 章*](B17343_07_Final_JC_ePub.xhtml#_idTextAnchor141) 、*构建示例 ML 微服务*中的用例相同的高级格式，并在本章中讨论以下主题:

*   理解批处理问题
*   设计 ETML 解决方案
*   选择工具
*   执行构建

所有这些主题都将帮助我们理解为了构建成功的 ETML 解决方案，我们需要采取的特定决策和步骤。

在下一节中，我们将重温在第 1 章 、*ML 工程简介*中介绍的高级问题，并探索如何将业务需求映射到技术解决方案需求，给出我们目前在本书中学到的所有内容。

# 技术要求

要应用本章中的示例，您需要安装或提供以下工具:

*   JIRA 大西洋账户
*   Github 帐户
*   sci kit-学习
*   日志 Python 库

# 理解批处理问题

在 [*第一章*](B17343_01_Final_JC_ePub.xhtml#_idTextAnchor014) ，*ML 工程介绍*中，我们看到了一家出租车公司想要在每天结束时分析异常乘车的场景。客户有以下要求:

*   游乐设备应根据游乐设备距离和时间以及识别的异常/异常值进行分组。
*   速度(距离/时间)不被使用，因为分析师想要了解长距离或长时间的乘坐。
*   该分析应每天进行。
*   用于推断的数据应该从公司的数据湖中消耗。
*   结果应该可供其他公司系统使用。

正如我们在 [*第 2 章*](B17343_02_Final_JC_ePub.xhtml#_idTextAnchor030) 、*机器学习开发流程*和 [*第 7 章*](B17343_07_Final_JC_ePub.xhtml#_idTextAnchor141) 、*构建示例 ML 微服务*中所做的那样，我们现在可以从这些需求中构建一些用户案例，如下所示:

*   **用户故事 1** :作为一名运营分析师，我希望得到那些骑行时间或距离异常长的骑行的清晰标签。
*   **用户故事 2** :作为一个内部应用开发者，我希望对于带有异常标签的数据有一个清晰的访问点。这些数据应该存储在云中。
*   **用户故事 3** :作为一名运营分析师，我希望每天早上都能看到前一天的乘车标签。

用户故事 1 应该由我们的通用聚类方法来处理，特别是因为我们正在使用带有噪声的应用程序的**基于密度的空间聚类** ( **DBSCAN** )算法，该算法为离群值提供了一个标签 *-1* 。

用户故事 2 意味着我们必须将结果推送到云上的一个位置，然后可以通过数据工程管道或 web 应用程序管道获取。为了尽可能灵活地使用，我们将把结果推送到一个指定的**亚马逊网络服务** ( **AWS** ) **简单存储服务** ( **S3** )桶中。我们最初将以 **JavaScript 对象符号** ( **JSON** )格式导出数据，作为这是应用程序开发中经常使用的格式，可以被大多数数据工程工具读入。

最后一个用户故事，用户故事 3，为我们提供了系统所需的调度指导。在这个案例中，需求意味着我们应该在每日批处理作业中运行。

让我们根据一些 ML 解决方案技术要求将这些想法列表如下:

![Figure 8.1 – Translating user stories to technical requirements
](img/B17343_08_001.jpg)

图 8.1——将用户故事转化为技术需求

在下一节中，我们将把这些技术需求映射到一个高级设计中。

# 设计 ETML 解决方案

这些需求清楚地向我们指出了一个解决方案，在将数据输出到目标位置之前，该方案接收一些数据并用 ML 推理对其进行扩充。我们提出的任何设计都必须包含这些步骤。

我们的设计必须涵盖的关键要素可以通过扩展我们在*图 8.1* 中写下的内容来阐明；如下图所示:

![Figure 8.2 – High-level design for the ETML clustering system
](img/B17343_08_002.jpg)

图 8.2-ETML 聚类系统的概要设计

在下一节中，鉴于我们在前几章中学到的一切，我们将看看一些可以用来解决这个问题的潜在工具。

# 选择工具

对于这个例子，以及几乎每当我们遇到 ETML 问题时，我们的主要考虑因素归结为几件简单的事情，我们将在下面的部分中涉及。

## 接口

当我们执行 ETML 的提取和加载部分时，我们需要考虑如何与存储我们数据的系统接口。重要的是，无论我们从哪个数据库或数据技术中提取，我们都要使用适当的工具，以我们需要的任何规模和速度进行提取。在这个例子中，我们的接口可以由 AWS `boto3`库和 S3 **应用程序编程接口** ( **API** )来处理。

下表显示了使用该选项的利弊:

![Figure 8.3 – Pros and cons of using the AWS CLI and boto3 for interfacing with our data sources
](img/B17343_08_003.jpg)

图 8.3-使用 AWS CLI 和 boto3 与我们的数据源接口的利与弊

在下一节中，我们将考虑我们必须围绕建模方法的可伸缩性做出的决策。这在处理批量数据时非常重要，在某些情况下，批量数据可能非常大。

## 模型的缩放

在 [*第 6 章*](B17343_06_Final_JC_ePub.xhtml#_idTextAnchor132) 、*纵向扩展*中，我们讨论了一些纵向扩展我们的分析和 ML 工作负载的机制。我们应该问自己，这些方法，甚至其他方法，是否适用于手头的用例，并相应地使用它们。这也是另一种方式:如果我们正在查看相对少量的数据，就没有必要提供大量的基础设施，也没有必要花费时间来创建非常优化的处理。每个案件都应根据其本身的是非曲直和具体情况进行审查。

我们在这里列出了一些选项及其利弊:

![Figure 8.4 – Options for the modeling part of the ETML solution, with their pros and cons and with a particular focus on scalability
](img/B17343_08_004.jpg)

图 8.4–ETML 解决方案建模部分的选项，及其优缺点，特别关注可扩展性

现在，我们已经探索了我们必须围绕可扩展 ML 模型做出的工具决策；我们继续讨论 ETML 解决方案的另一个重要话题——我们如何管理批处理的调度。

## ETML 管道的调度

ETML 对应的那种批处理过程通常与日常批处理配合得非常好，但是考虑到前面概述的其他两点，我们可能需要在调度作业时小心谨慎——例如，我们管道中的一个步骤可能需要连接到一个没有读取副本(专门用于读取的数据库副本)的生产数据库。如果是这样的话，那么如果我们在周一早上 9 点开始用查询敲打这个数据库，我们可能会给使用这个数据库的任何解决方案的用户带来重大的性能问题。类似地，如果我们通宵运行，并希望加载到正在进行其他批量上传过程的系统中，我们可能会造成资源争用，从而减慢该过程。这里没有*一刀切*的回答；重要的是考虑你的选择。我们看看使用 Apache Airflow 的利与弊，我们在第五章[](B17343_05_Final_JC_ePub.xhtml#_idTextAnchor116)**【部署模式和工具】*中介绍了它的，对于这个问题的调度和作业管理见下表:*

*![Figure 8.5 – Pros and cons of using Apache Airflow for managing our scheduling
](img/B17343_08_005.jpg)

图 8.5–使用 Apache Airflow 管理我们的日程安排的利与弊

鉴于图 8.5 中的一些要点，似乎实际上，对于一个相对较小的数据集，scikit-learn 建模与 Apache Airflow 的组合可以满足我们的所有需求。

下一节将讨论在给定这些信息的情况下，我们如何继续执行解决方案。

# 执行构建

在这种情况下，构建的执行在很大程度上取决于我们如何获取第 1 章*ML 工程介绍*中显示的**概念验证**代码，然后将其拆分为组件，这些组件可以被另一个调度工具(如 Apache Airflow)调用。这将展示我们如何应用在第 4 章 、*打包*中学到的技能。

在接下来的几节中，我们将介绍如何将一些工程最佳实践注入到代码库中，并且我们将讨论一些编码示例来帮助实现这一点。我们将不会关注 Apache Airflow 的调度和流水线方面(请参考第 5 章[](B17343_05_Final_JC_ePub.xhtml#_idTextAnchor116)*，*部署模式和工具，*)，而是将关注如何对现有代码库进行一些简单的调整，以显著提高其生产就绪性。*

 *## 实践中没有多此一举

正如在第 3 章 、*从模型到模型工厂*中所讨论的，无论我们以训练运行还是训练持续模式运行 ML 管道，我们仍然需要一个特征工程步骤！由于使用的数据集相对较小，我们决定在这里使用`sklearn`,我们可以只使用那个包的特性工程功能。

这有一个额外的好处，即与我们(假想的)数据科学家开发的原始 POC 非常接近！

在建模方面，同样，我们在生产中使用`sklearn`将意味着我们的数据科学家在 POC 阶段提供的基本功能将是我们开发工作的一个良好开端。

然而，我们能做的是添加一些我们在第四章*中讨论过的工程技术，以帮助强化这段代码。老实说，没有比利用我们在那一章中已经做的大量艰苦工作更好的方法了！具体来说，我们开发了一个检测异常值的包，这正是我们在这里想要做的。我们唯一要做的就是添加我们的数据科学家使用 ML 工程最佳实践开发的新功能。*

 *这是一个很好的例子，说明了我们在工作时不应多此一举的原则，正如在第四章*结束时强调的那样[*。*](B17343_04_Final_JC_ePub.xhtml#_idTextAnchor095)*

 *下一节将介绍我们如何通过利用在 [*第 2 章*](B17343_02_Final_JC_ePub.xhtml#_idTextAnchor030) 、*中解释的 Gitflow 工作流，将 [*第 4 章*](B17343_04_Final_JC_ePub.xhtml#_idTextAnchor095) 、*打包、*中开发的`outliers`包添加到机器学习开发过程*中。

## 使用 Gitflow 工作流程

首先，为了让我们处理这个库，我们导航到位于 https://github.com/AndyMc629/mleip-outliers T2 的 GitHub 库。在撰写本文时，这个库只包含了在 [*第四章*](B17343_04_Final_JC_ePub.xhtml#_idTextAnchor095)*打包时开发的代码，在主分支中*。

接下来，我们可以将在第 1 章 、*ML 工程简介*中创建的吉拉实例集成到这个 GitHub 存储库中。为此，我们采取了以下步骤:

1.  We install the GitHub integration plugin in Atlassian Marketplace, given here: [https://marketplace.atlassian.com/apps/1224265/github-integration-for-jira?hosting=cloud&tab=overview](https://marketplace.atlassian.com/apps/1224265/github-integration-for-jira?hosting=cloud&tab=overview). When prompted, provide the repository name. This is shown in the following screenshot:![Figure 8.6 – Configuring JIRA with our package repository
    ](img/B17343_08_006.jpg)

    图 8.6–用我们的包存储库配置 JIRA

2.  Now the GitHub integration plugin is installed, we can create branches or trigger **Pull Requests** (**PRs**) via JIRA. First, we navigate to the relevant user story and click the **GitHub toolkit** button in the lower-right corner of the screen, as illustrated in the following screenshot:![Figure 8.7 – Selecting the GitHub toolkit option to create a new feature branch based on the Jira ticket
    ](img/B17343_08_007.jpg)

    图 8.7–选择 GitHub 工具包选项，基于吉拉票据创建一个新的特性分支

3.  After clicking this, a new part of the window opens with some options. We select Create and the branch name is auto-populated with a suggestion. This can be edited. Finally, we push the **Create branch** button on the bottom right. A view of these steps is shown in the following screenshot:![Figure 8.8 – Creation of a feature branch via Jira
    ](img/B17343_08_008.jpg)

    图 8.8–通过吉拉创建特征分支

4.  前面的步骤应该已经成功创建了特征分支。如果您导航到您的 GitHub 存储库并选择存储库顶部的**分支**图标，您应该能够看到您的分支确实已经被创建了。下面的屏幕截图显示了一个示例:

![Figure 8.9 – Confirmation that the feature branch has been created in GitHub
](img/B17343_08_009.jpg)

图 8.9–确认特性分支已经在 GitHub 中创建

我们刚刚讨论了如何在中以一种健壮的方式使用版本控制。在下一节中，我们将介绍如何利用我们以前学到的关于工程最佳实践的知识，并在这里实施它们。我们还将展示如何继续使用 Gitflow 工作流在代码库中实现这些更改。

## 注入一些工程实践

对于这里呈现的用例，我们可以在业务主要是希望`outliers`包增加新功能的假设下继续进行。我们还将讨论如何在包中注入一些工程实践。我们将介绍作为 ML 工程师，我们如何朝着这些目标前进。我们将如下进行:

1.  首先，由数据科学家在`outliers`包中产生的 POC，我们必须添加一些额外的逻辑来处理当这个模型类型被传递到`model_config.json`文件中时的情况。该逻辑再次利用了在 [*第 3 章*](B17343_03_Final_JC_ePub.xhtml#_idTextAnchor055) 、*从模型到模型工厂*中解释的`**kwargs`语法，以允许将可变数量的参数传递给 DBSCAN 模型实例，如下面的代码片段所示:

    ```
        def create_model(self, model_name=None, params=None):         logging.debug(f"Creating model with params: model_name:{model_name} and params:{params}")         if model_name is None and params is None:             return None         if model_name == 'IsolationForest' and params is not None:             return IsolationForest(**params)         if model_name == 'DBSCAN' and params is not None:             return DBSCAN(**params)
    ```

2.  最初版本的`outliers`包中没有很多日志记录。在前面的代码示例和`outliers`包的其他部分中，我们添加了更多的日志功能，以帮助诊断生产中可能出现的任何问题。我们还添加了异常处理，这是第四章 、*打包*中确定的另一个最佳实践。代码如下面的代码片段所示:

    ```
        def detect(self, data):         try:             logging.debug("Fitting pipeline")             return self.pipeline.fit_predict(data)         except Exception as e:             logging.debug(f"fit_predict() failed with object {self.pipeline}")             logging.debug(e)             print(e)
    ```

3.  由于`outliers`包主要充当`main()`方法的包装器，包中的作为如何在应用程序中使用的示例，可以简单地集中于实例化适当的模型，应用它们，然后输出结果，如下面的代码片段所示:

    ```
        logging.info("Reading in models")     models = DetectionModels(MODEL_CONFIG_PATH).get_models()       logging.info("Iterating over models")     for model in models:         logging.info("Create detector")         detector = detectors.pipelines.OutlierDetector(model=model)         logging.info("Detector created")         result = detector.detect(data)         logging.info("Result calculated")
    ```

所有这些加在一起意味着我们现在在`outliers`包中有了更适合生产的代码，这些代码可以与各种工具一起使用，包括作为一个可由 Apache Airflow 管道在预定的 ETML 作业中调用的脚本。

我们现在将定义将代码变更合并到包的主分支中所需的步骤，如下所示:

1.  Once the engineering team is happy with the changes to the package, a PR can be raised for merging in the changes to the master. This can be done via the Jira board for the original task, as shown in the following screenshot:![Figure 8.10 – Creating a PR via the Jira GitHub integration plugin
    ](img/B17343_08_010.jpg)

    图 8.10–通过吉拉 GitHub 集成插件创建公关

2.  We are then redirected to the Git web **User Interface** (**UI**), and we can fill in the relevant details for our PR, including details of the changes being proposed. This is illustrated in the screenshot shown next. After this, we click **Create pull request**:![Figure 8.11 – PR for the code changes in GitHub
    ](img/B17343_08_011.jpg)

    图 8.11-GitHub 中代码变更的 PR

3.  提交 PR 后，如果我们导航到 web UI 中的**拉动请求**部分，我们可以看到活动的请求，并单击它以查看变更的详细信息。这包括选项，用于查看哪些提交是在 PR 中提交的，哪些检查是通过 GitHub 操作执行的(参见 [*第 4 章*](B17343_04_Final_JC_ePub.xhtml#_idTextAnchor095) 、*打包*)，以及单个文件和行级别的变更。对更改感到满意后，请求的审核者可以按下屏幕底部的**合并拉取请求**按钮，如下图所示:

![Figure 8.12 – Merging in our changes to the outliers package with a PR
](img/B17343_08_012.jpg)

图 8.12–将我们的变更合并到带有 PR 的离群值包中

这就是我们如何使`outliers`包更加健壮并准备好用于生产流水线的方法。剩下要做的就是应用流程图**中逻辑的相关步骤** ( **DAG** )，如 [*第 5 章*](B17343_05_Final_JC_ePub.xhtml#_idTextAnchor116) 、*部署模式和工具*所示。我们不会在这里重复这些步骤，而只是强调对代码库的扩充意味着我们的 ETML 管道的核心逻辑已经准备就绪。

我们现在将结束这一章和这本书，对我们在这一章中所涉及的内容做一个简短的总结。

摘要

本章涵盖了如何应用本书中学到的许多技术，特别是从第 [*章第 2*](B17343_02_Final_JC_ePub.xhtml#_idTextAnchor030)*机器学习开发过程*[*第 3 章*](B17343_03_Final_JC_ePub.xhtml#_idTextAnchor055)*从模型到模型工厂*[*第 4 章*](B17343_04_Final_JC_ePub.xhtml#_idTextAnchor095)*打包*，到涉及更新现有 ML 包的实际 ML 问题。这个场景是一个可以使用 ETML 模式解决的例子，我们已经详细解释过了。涵盖了潜在解决方案的设计，以及任何 ML 工程团队都必须经历的一些工具选择的讨论。最后，我们深入研究了将该解决方案投入生产所需的一些关键工作。这集中在增强现有包的 ML 功能和强化解决方案的代码更改上。它还涵盖了如何使用吉拉和 Git 通过版本控制来实现这些变化，正如本书第 2 章*机器学习开发过程*中所讨论的那样。

至此，你不仅完成了这一章，也完成了这本书，所以恭喜你！在本书中，我们涵盖了 ML 工程中的各种各样的主题，从如何建立你的团队和开发过程看起来像什么，一直到打包、缩放、调度、部署、测试、日志，以及中间的一大堆东西。有太多的主题我们只是简单地介绍了一下，可能会有整本书专门介绍它们，还有太多的其他主题我们没有足够的空间来介绍。尽管如此，我还是希望你在读完这本书后，能够更好地走出去构建软件解决方案，每天使用 ML 交付真正的价值。当然，我希望它能帮助你使用最流行的编程语言之一——也是我最喜欢的一种——Python 来做到这一点。****