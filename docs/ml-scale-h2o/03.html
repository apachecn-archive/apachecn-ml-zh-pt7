<html><head/><body>


	
		<title>B16721_02_Final_SK_ePub</title>
		
	
	
		<div><h1 id="_idParaDest-25"><em class="italic"> <a id="_idTextAnchor024"/>第二章</em>:平台组件和关键概念</h1>
			<p>在这一章中，我们将获得对H2O机器学习规模化技术的组件的基本理解。我们将查看H2O机器学习的一个简单代码示例，理解它做什么，并识别该示例在企业范围内与机器学习相关的任何问题。这个<em class="italic"> Hello World </em>代码示例将作为一个简单的表示，以进一步加深我们的理解。</p>
			<p>我们将大规模概述机器学习的每个H2O组件，确定每个组件如何实现规模，并确定每个组件如何与我们的简单代码片段相关。然后，我们将使用这些组件将这些组件连接到一个参考机器学习工作流中。最后，我们将关注这些组件中的关键概念。本章中获得的理解将是本书其余部分的基础，其中我们将实施H2O技术，在企业环境中大规模构建和部署最先进的机器学习模型。</p>
			<p>在本章中，我们将讨论以下主要话题:</p>
			<ul>
				<li>你好世界——H2O机器学习代码</li>
				<li>大规模H2O机器学习的组成部分</li>
				<li>使用这些H2O组件的机器学习工作流</li>
				<li>H2O关键概念</li>
			</ul>
			<h1 id="_idParaDest-26"><a id="_idTextAnchor025"/>技术要求</h1>
			<p>对于这一章，你需要在本地安装H2O-3来运行一个最简单的<em class="italic"> Hello World </em>工作流程。要实现它，请遵循<a href="B16721_Appendix_Final_SK_ePub.xhtml#_idTextAnchor268"> <em class="italic">附录</em> </a>中的说明。请注意，我们将在整本书中使用Python API，所以请按照说明用Python安装它。</p>
			<h1 id="_idParaDest-27"><a id="_idTextAnchor026"/>你好，世界——H2O机器学习代码</h1>
			<p>H2O核心是为大规模机器学习而设计的<a id="_idIndexMarker042"/>；但是，它也可以用于用户笔记本电脑上的小型数据集。在下一节中，我们将使用H2O-3的最小代码示例来构建机器学习模型，并将其导出为可部署的工件。我们将使用这个示例作为理解H2O机器学习代码的最基本单元，就像查看人类简笔画开始学习人类生物学一样。</p>
			<h2 id="_idParaDest-28"><a id="_idTextAnchor027"/>代码示例</h2>
			<p>看看下面的<a id="_idIndexMarker043"/>代码示例。在这里，我们是用Python写的，它可能来自Jupyter、PyCharm或另一个Python客户端。我们将了解到R和Java/Scala是编写H2O代码的替代语言。</p>
			<p>让我们从导入H2O库开始:</p>
			<pre class="source-code">import h2o</pre>
			<p>回想一下文档，这是从H2O下载的，并安装在客户端或IDE环境中。这个<code>h2o</code>包允许我们使用Python编写的H2O API从IDE中运行H2O内存分布式机器学习。</p>
			<p>接下来，我们创建一个H2O集群:</p>
			<pre class="source-code">h2o.init(ip="localhost", port=54323)</pre>
			<p>前面的代码行创建了一个叫做<strong class="bold">的H2O集群</strong>。这是H2O模型构建技术的一个关键概念。它是一种分布式内存架构。在<em class="italic"> Hello World </em>案例中，H2O集群将作为本地主机创建在笔记本电脑上，并且不会被分发。我们将在本章的<em class="italic"> H2O关键概念</em>部分了解更多关于H2O集群的信息。</p>
			<p>用于启动H2O集群的<code>ip</code>和<code>port</code>配置应该提供足够的线索，表明H2O代码将通过API发送到计算环境，对于企业环境来说，计算环境可以位于数据中心或云中。然而，在这里，它是在我们的本地主机上。</p>
			<p>然后，我们导入一个数据集:</p>
			<pre class="source-code">loans = h2o.import_file("https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/main/chapt2/loans-lite.csv")</pre>
			<p>现在我们探索数据集:</p>
			<pre class="source-code">loans.describe()</pre>
			<p>这是一个<a id="_idIndexMarker045"/>最小量的数据探索。它只是返回行数和列数。</p>
			<p>好了，现在让我们为我们的模型准备数据:</p>
			<pre class="source-code">train, validation = loans.split_frame(ratios=[0.75])</pre>
			<pre class="source-code">label = "bad_loan"</pre>
			<pre class="source-code">predictors = loans.col_names</pre>
			<pre class="source-code">predictors.remove(label)</pre>
			<p>我们将数据分成训练集和验证集，训练集使用<code>0.75</code>比例。我们将预测一笔贷款是否会成为坏账(即，它是否会违约)，并将此列标识为标签。最后，我们通过使用数据集中除不良贷款列之外的所有列来定义用于预测不良贷款的列。</p>
			<p>现在，我们建立模型:</p>
			<pre class="source-code">from h2o.estimators import H2OXGBoostEstimator</pre>
			<pre class="source-code">param = {"ntrees" : 25, "nfolds" : 10}</pre>
			<pre class="source-code">xgboost_model = H2OXGBoostEstimator(**param)</pre>
			<pre class="source-code">xgboost_model.train(x = predictors,</pre>
			<pre class="source-code">                    y = label,</pre>
			<pre class="source-code">                    training_frame = train,</pre>
			<pre class="source-code">                    validation_frame = validation)</pre>
			<p>我们导入了H2O的<strong class="bold"> XGBoost </strong>模块<a id="_idIndexMarker046"/>，并为其配置了两个超参数。然后，我们通过将引用输入到预测器列、标签列、训练数据和测试数据来开始模型训练。</p>
			<p>XGBoost是<code>h2o</code>模块中众多广为认可和广泛使用的机器学习算法之一。该模块公开的H2O API将在企业基础设施上运行H2O架构中的XGBoost模型，我们将在后面了解到。关于超参数，我们会发现，H2O提供了一个广泛的超参数集来配置每个模型。</p>
			<p>当模型完成时，我们可以使用一行代码导出模型:</p>
			<pre class="source-code">xgboost_model.download_mojo(path="~/loans-model", get_genmodel_jar=True)</pre>
			<p>导出的评分工件现在可以传递给DevOps进行部署了。<code>get_genmodel_jar=True</code>参数触发下载包含<code>h2o-genmodel.jar</code>。这是模型用于在H2O群集之外(即在生产环境中)评分的库。我们将在<em class="italic">第3节-将您的模型部署到生产环境</em>中了解更多关于生产H2O模型的信息。</p>
			<p>目前，我们已经完成了模型构建。因此，我们将关闭集群:</p>
			<pre class="source-code">h2o.cluster().shutdown()</pre>
			<p>这释放了H2O集群一直在使用的资源。</p>
			<p>请记住，这是一个简单的<em class="italic"> Hello World </em> H2O模型构建示例。它旨在完成以下两项任务:</p>
			<ul>
				<li>简单介绍一下H2O模型建筑。</li>
				<li>作为讨论企业中规模问题的基础，我们将在下一节中讨论。</li>
			</ul>
			<p>在<em class="italic">第2节——使用H2O在大数据量上构建最先进的模型</em>中，我们将探索广泛的技术来构建高度可预测和可解释的大规模模型。让我们从讨论我们的<em class="italic"> Hello World </em>示例暴露的一些规模问题开始我们的旅程。</p>
			<h2 id="_idParaDest-29"><a id="_idTextAnchor028"/>规模的一些问题</h2>
			<p>这段<a id="_idIndexMarker048"/> <em class="italic"> Hello World </em>代码在企业设置中不会很好地伸缩。让我们重温一下代码，以便更好地理解这些缩放约束。</p>
			<p>我们在IDE代码中导入这个库:</p>
			<pre class="source-code">import h2o</pre>
			<p>大多数企业希望对所使用的库的版本有一些控制。此外，他们通常希望提供一个中央平台来托管和验证某项技术的所有用户，并让管理员管理该平台。我们将会发现，Enterprise Steam在集中管理用户和H2O环境方面发挥着关键作用。</p>
			<p>我们初始化H2O集群:</p>
			<pre class="source-code">h2o.init(ip="localhost", port=54323)</pre>
			<p>大规模机器学习需要跨服务器集群分布计算资源，以实现水平扩展(即跨许多服务器分而治之地分配计算资源)。因此，IP地址和端口应该指向服务器群集的一个成员，而不是单个计算机，如本例所示。我们将看到H2O核心创建自己的自组织集群，分布和水平扩展模型构建。</p>
			<p>由于扩展是在企业服务器集群上进行的，通常由许多个人和团体使用，企业希望控制用户对该环境的访问以及用户消耗的资源数量。但是，什么会阻止用户启动多个H2O集群，在每个集群上使用尽可能多的资源，从而阻止其他用户使用资源呢？Enterprise Steam管理企业服务器集群上的H2O用户和H2O资源消耗。</p>
			<p>我们导入数据集:</p>
			<pre class="source-code">loans = h2o.import_file("https://raw.githubusercontent.com/PacktPublishing/Machine-Learning-at-Scale-with-H2O/main/chapt2/loans-lite.csv")</pre>
			<p>大量数据需要非常长的时间在网络上传输，需要几个小时或几天才能完成传输，或者可能会提前超时。大规模建模期间的计算应该在数据驻留的地方进行，以防止数据移动中的这一瓶颈。我们将发现，在企业系统上启动的H2O集群将数据从存储层直接接收到服务器内存中。因为数据是跨组成H2O集群的服务器进行分区的，所以数据接收与这些分区并行发生。</p>
			<p>我们将看到【Enterprise Steam如何集中用户认证，以及如何将用户的身份传递给企业系统，在企业系统中实现其本地授权机制。</p>
			<p>我们训练模型:</p>
			<pre class="source-code">xgboost_model.train(x = predictors,</pre>
			<pre class="source-code">                    y = label,</pre>
			<pre class="source-code">                    training_frame = train,</pre>
			<pre class="source-code">                    validation_frame = validation)</pre>
			<p>当然，这是模型构建过程的核心，同样也是本书大部分内容的重点:如何使用H2O广泛的机器学习算法和模型构建能力，针对大量数据构建世界级的机器学习模型。</p>
			<p>我们下载可部署模型:</p>
			<pre class="source-code">xgboost_model.download_mojo(path="~/loans-model", get_genmodel_jar=True)</pre>
			<p>请记住，从商业的角度来看，直到模型被导出并部署到产品中，价值才得以实现。这样做涉及到多个企业利益相关者的复杂性。我们将了解导出的<strong class="bold"> MOJO </strong> ( <strong class="bold">模型对象，优化的</strong>)的设计和功能如何使<a id="_idIndexMarker050"/>易于部署到涉及这些利益相关者的不同软件系统。</p>
			<p>我们关闭了H2O集群:</p>
			<pre class="source-code">h2o.cluster().shutdown()</pre>
			<p>H2O群集使用资源，不使用时应该关闭。如果不这样做，企业系统上的其他用户或作业可能会争用这些资源，从而受到影响。此外，在必须扩展基础设施之前，可以向系统添加更少的新用户。我们将看到企业级Steam控制着H2O用户如何使用企业系统上的资源。由此带来的资源效率提升允许H2O用户及其工作在给定的基础设施分配上更有效地扩展。</p>
			<p>现在，我们已经运行了我们的<em class="italic"> Hello World </em>示例，并探索了一些关于规模的问题，让我们继续了解用于机器学习模型构建和大规模部署的H2O组件。</p>
			<h1 id="_idParaDest-30"><a id="_idTextAnchor029"/>H2O机器学习规模化的组成部分</h1>
			<p>正如前一章介绍的和本书强调的，H2O机器学习克服了规模问题。以下是对大规模H2O机器学习的每个组件以及每个组件如何克服这些挑战的简要介绍。</p>
			<h2 id="_idParaDest-31"><a id="_idTextAnchor030"/> H2O核心-内存分布式模型构建</h2>
			<p>H2O核心<a id="_idIndexMarker053"/>允许数据科学家使用众所周知的机器学习算法编写代码来构建<a id="_idIndexMarker054"/>模型。编码体验是通过用Python、R或Java/Scala语言表达的H2O API，并在他们最喜欢的客户端或IDE中编写，例如Jupyter笔记本中的Python。然而，模型构建的实际计算发生在企业服务器集群(而不是IDE环境)上，并利用服务器集群的巨大内存池和CPU来针对海量数据运行机器学习算法。</p>
			<p>那么，这是如何工作的呢？首先，用于模型构建的数据由服务器集群上的H2O在内存中进行分区和分配。IDE向服务器群集发送H2O指令。集群中的服务器接收这些指令，并将它们分发给集群中的其他服务器。这些指令在分区的内存数据上并行运行。接收指令的服务器收集和组合结果，并将它们发送回IDE。随着代码在IDE中排序，这一过程会重复进行。</p>
			<p>这种<em class="italic">分而治之</em>的方法<a id="_idIndexMarker055"/>是大规模建立H2O模型的基础。H2O分而治之体系结构的一个单元称为H2O集群，在本章的后面将作为一个关键概念进行阐述。结果是在大量数据的基础上快速建立模型。</p>
			<h3>H2O核心的主要特征</h3>
			<p>H2O核心的一些<a id="_idIndexMarker056"/>关键特性如下:</p>
			<ul>
				<li><strong class="bold">水平缩放</strong>:数据操作<a id="_idIndexMarker057"/>和机器学习算法并行分布在内存中，并有额外的优化，如分布式键/值存储，以在模型构建期间快速访问数据和对象。</li>
				<li><strong class="bold">熟悉的体验</strong>:数据<a id="_idIndexMarker058"/>科学家使用熟悉的语言和ide编写H2O API代码，就像我们刚刚做的一样。</li>
				<li><strong class="bold">开源</strong> : H2O核心<a id="_idIndexMarker059"/>开源。</li>
				<li><strong class="bold">多种文件格式</strong> : H2O <a id="_idIndexMarker060"/>支持多种源数据格式。</li>
				<li><strong class="bold">数据操作</strong>:<a id="_idIndexMarker061"/>H2O API包括广泛的任务，这些任务通常用来为机器学习准备数据。苏打水(将在下一节介绍)将数据工程技术扩展到Spark。</li>
				<li><strong class="bold">公认的机器学习算法</strong> : H2O使用广泛的公认的<a id="_idIndexMarker062"/>监督和非监督机器学习算法。</li>
				<li><strong class="bold">培训、测试和评估</strong>:交叉验证、网格搜索、变量<a id="_idIndexMarker063"/>重要性和性能<a id="_idIndexMarker064"/>度量的广泛技术被用于培训、测试和<a id="_idIndexMarker065"/>评估模型；这也包括模型检查点功能。</li>
				<li><strong class="bold">自动机器学习(AutoML)</strong>:H2O核心AutoML API提供了一个<a id="_idIndexMarker066"/>简单的包装器函数，简洁地自动化多个模型的训练和调优，包括堆叠集成，并在排行榜中呈现结果。</li>
				<li><strong class="bold">模型可解释性</strong>:它<a id="_idIndexMarker067"/>为单个模型或AutoML中涉及的那些模型提供了广泛的局部和全局可解释性方法和可视化，所有这些都来自单个包装器函数。</li>
				<li><strong class="bold"> AutoDoc </strong> : It <a id="_idIndexMarker068"/>使<a id="_idIndexMarker069"/>能够自动生成标准化的Word文档，广泛详细地描述模型构建和可解释性；请注意，AutoDoc不是免费的开源平台。</li>
				<li><strong class="bold">可导出的评分工件(MOJO) </strong>:它使用一行代码将模型导出为<a id="_idIndexMarker070"/>可部署的评分工件(模型部署将在<em class="italic">第3节——将您的模型部署到生产环境</em>中更详细地讨论)。</li>
				<li><strong class="bold"> H2O流程网络用户界面</strong>:这个<a id="_idIndexMarker071"/>是一个可选的基于网络的交互式用户界面，以一种简单而丰富的点击式体验指导用户完成模型构建工作流程，这对于H2O模型的快速实验和原型制作非常有用。</li>
			</ul>
			<h3>H2O-3和H2O苏打水</h3>
			<p>H2O核心有两种口味:<strong class="bold"> H2O-3 </strong>和<strong class="bold"> H2O苏打水</strong>。</p>
			<p>H2O-3是H2O核心，如前一节所述。H2O苏打水是H2O-3包装的<a id="_idIndexMarker074"/>通过火花集成。它与H2O-3相同，并具有以下附加功能:</p>
			<ul>
				<li><strong class="bold">Spark和H2O API代码无缝集成</strong>:用户在同一个IDE中编写Spark和H2O代码；例如，使用SparkSQL代码来设计数据，使用H2O代码来构建世界级的模型。</li>
				<li><strong class="bold">H2O和Spark数据帧之间的转换</strong>:作为无缝集成的一部分，H2O和Spark数据帧<a id="_idIndexMarker076"/>相互转换；因此，SparkSQL数据管理的结果可以作为H2O模型建立的输入。</li>
				<li><strong class="bold"> Spark engine </strong>:苏打水作为Spark框架上的原生Spark应用程序运行。</li>
			</ul>
			<p>H2O-3和苏打水<a id="_idIndexMarker077"/>是更一般的H2O核心的模型建造替代品。在更大的企业服务器集群上推出的H2O集群的概念与<a id="_idIndexMarker078"/>和<a id="_idIndexMarker079"/> H2O核心版本相似，尽管一些实施细节有所不同，这对于数据科学家来说基本上是不可见的。如上所述，苏打水对于整合Spark数据工程和H2O模型构建工作流特别有用。</p>
			<h2 id="_idParaDest-32"><a id="_idTextAnchor031"/> H2O企业Steam——一个受管的自助供应门户</h2>
			<p>Enterprise Steam <a id="_idIndexMarker080"/>提供了一个集中的web UI和<a id="_idIndexMarker081"/> API，供数据科学家初始化和终止他们的H2O环境(称为H2O集群),并供管理员管理H2O用户和H2O与企业服务器集群的集成。</p>
			<h3>企业蒸汽的主要特征</h3>
			<p>企业蒸汽的主要特性<a id="_idIndexMarker082"/>如下:</p>
			<ul>
				<li><strong class="bold">数据科学自我调配</strong>:这<a id="_idIndexMarker083"/>是数据科学家管理其H2O环境的一种简单、基于UI的方式。</li>
				<li><strong class="bold">所有H2O用户的中央访问点</strong>:这简化了H2O用户管理，并为H2O访问企业服务器集群提供了一个<a id="_idIndexMarker084"/>单一入口点。</li>
				<li><strong class="bold">管理用户资源消耗</strong>:管理员建立分配给用户或用户组的资源使用边界<a id="_idIndexMarker085"/>的配置文件。这限制了用户可以在企业服务器集群上分配的资源数量。</li>
				<li><strong class="bold">无缝安全</strong>:用户<a id="_idIndexMarker086"/>认证<a id="_idIndexMarker087"/>到企业级的流通过到企业服务器集群上的资源的授权。Enterprise Steam根据企业服务器集群使用的同一身份提供者(例如，LDAP)进行身份验证。</li>
				<li><strong class="bold">配置集成</strong>:管理员<a id="_idIndexMarker088"/>配置H2O与企业服务器集群和身份提供者的集成。</li>
				<li><strong class="bold">管理H2O核心版本</strong>:<a id="_idIndexMarker089"/>管理员管理一个或多个H2O核心版本，数据科学家使用这些版本来创建H2O集群以进行建模。</li>
			</ul>
			<h2 id="_idParaDest-33"><a id="_idTextAnchor032"/>H2O魔咒——一种灵活、低延迟的得分神器</h2>
			<p>从H2O核心构建的<a id="_idIndexMarker090"/>模型<a id="_idIndexMarker091"/>被导出为名为H2O魔咒的可部署计分工件。MOJOs可以在任何JVM环境中运行(可能除了非常小的边缘设备)。</p>
			<p>在<em class="italic">第3节——将您的模型部署到生产环境</em>中，我们将了解到MOJOs已经准备好直接部署到H2O软件以及许多第三方评分解决方案，无需编码。但是，如果您希望将MOJO直接嵌入到您自己的软件中，有一个MOJO Java API来构建Java助手类，以公开MOJO功能(例如，除了预测之外还输出原因代码)，并提供与您的评分输入和输出的灵活集成。</p>
			<p>在所有模型中，不管用于构建模型的机器学习算法如何，MOJOs在<a id="_idIndexMarker092"/>构造中都是相同的。因此，从DevOps的角度来看，部署是可重复和可自动化的。</p>
			<h3>MOJOs的主要特点</h3>
			<p><a id="_idIndexMarker093"/>MOJO的主要特点如下:</p>
			<ul>
				<li><strong class="bold">低延迟</strong>:通常情况下，每次评分不到100毫秒。</li>
				<li><strong class="bold">灵活的数据速度</strong> : Mojos可以对批处理、实时和流数据进行预测(例如，对整个数据库表，分别作为REST端点和Kafka主题，等等)。</li>
				<li><strong class="bold">灵活的目标系统</strong>:这适合JVM运行时，包括JDBC客户端、<strong class="bold"> REST服务器</strong>、<strong class="bold"> AWS Lambda </strong>、<strong class="bold"> AWS SageMaker </strong>、<strong class="bold"> Kafka队列</strong>、<strong class="bold"> Flink streams </strong>、Spark <a id="_idIndexMarker094"/>管道<a id="_idIndexMarker095"/>包括流、Hive UDF、雪花的外部函数等等。目标系统可以是<a id="_idIndexMarker096"/>专业<a id="_idIndexMarker097"/> H2O评分软件，第三方评分<a id="_idIndexMarker098"/>软件，或者你自己的软件。一种常见的模式是将MOJO部署到REST服务器，并通过来自客户端应用程序(例如，Excel电子表格)的REST调用来使用它的预测。</li>
				<li><strong class="bold">可解释性特性</strong>:除了预测，你还可以在实时评分时从MOJO接收K-Lime或Shapley原因代码，你可以将MOJO加载到H2O核心中进行评分和检查MOJO属性。</li>
				<li><strong class="bold">可重复部署</strong>:mojo很容易集成到组织用于软件部署的现有部署自动化(CI/CD)管道中。</li>
			</ul>
			<p>请注意，除了<a id="_idIndexMarker099"/> H2O魔咒，还有一种叫做<strong class="bold"> POJO </strong>的替代方法，用于不常见的边缘情况。这将在<a href="B16721_08_Final_SK_ePub.xhtml#_idTextAnchor137"> <em class="italic">第8章</em> </a>、<em class="italic">综合</em>中进一步探讨。</p>
			<h1 id="_idParaDest-34"><a id="_idTextAnchor033"/>使用H2O组件的工作流</h1>
			<p>现在，我们已经了解了H2O的大规模机器学习组件的角色和关键功能，让我们<a id="_idIndexMarker100"/>将它们结合到一个高级工作流中，如下图所示:</p>
			<div><div><img src="img/B16721_Figure_2.1.jpg" alt="Figure 2.1 – A high-level machine learning at scale workflow with H2O&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图2.1–H2O的大规模高级机器学习工作流</p>
			<p>工作流程按以下顺序进行:</p>
			<ol>
				<li>管理员配置<strong class="bold"> H2O企业蒸汽</strong>。</li>
				<li>数据科学家登录<strong class="bold"> H2O企业蒸汽</strong>并启动<strong class="bold"> H2O核心</strong>集群(选择<strong class="bold"> H2O-3 </strong>或<strong class="bold"> H2O苏打水</strong>)。</li>
				<li>数据科学家使用他们最喜欢的客户端，使用H2O模型构建API的Python、R或Java/Scala语言风格来构建模型。数据科学家使用UI或IDE对<strong class="bold"> H2O企业Steam </strong>进行身份验证，并连接到在H2O企业Steam上启动的<strong class="bold"> H2O集群</strong>。</li>
				<li>数据科学家使用IDE通过H2O迭代模型构建步骤。</li>
				<li>在数据科学家决定了要部署的模型之后，<strong class="bold"> H2O </strong> <strong class="bold"> AutoDoc </strong>被生成，并且<strong class="bold"> H2O MOJO </strong>被从IDE中导出。</li>
				<li>数据科学家要么终止<strong class="bold"> H2O集群</strong>，要么在超过空闲或绝对正常运行时间后等待<strong class="bold"> H2O企业蒸汽</strong>执行此操作。管理员在分配给用户的资源配置文件中配置了这些持续时间。请注意，被终止的集群检查点确实工作，并且新的<strong class="bold"> H2O集群</strong>总是可以被启动以从终止点继续工作。</li>
				<li>模型<a id="_idIndexMarker101"/>被导出为<strong class="bold"> H2O魔咒</strong>并被部署到任何一组不同的主机目标。模型在业务环境中被消费，业务价值的实现开始了。</li>
			</ol>
			<h1 id="_idParaDest-35"><a id="_idTextAnchor034"/> H2O关键概念</h1>
			<p>在以下部分中，我们将确定并描述H2O的关键概念，这些概念是上一部分工作流步骤的基础。这些概念对于理解本书的其余部分是必要的。</p>
			<h2 id="_idParaDest-36"><a id="_idTextAnchor035"/>数据科学家的经验</h2>
			<p><a id="_idIndexMarker102"/>数据科学家拥有构建大规模H2O模型的熟悉经验，同时从企业服务器集群上复杂的基础设施和架构中抽象出来。这在下图中有更详细的描述:</p>
			<div><div><img src="img/B16721_Figure_2.2.jpg" alt="Figure 2.2 – Details of the data scientist's experience with H2O Core&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图2.2–数据科学家使用H2O核心的详细体验</p>
			<p>数据科学家使用众所周知的无监督和有监督的机器学习技术，这些技术可以跨企业的分布式基础设施和架构进行扩展。这些技术是用H2O模型构建API编写的，该API是用熟悉的ide(例如Jupyter或RStudio)用熟悉的语言(例如Python、R或Java)编写的。</p>
			<p class="callout-heading">H2O流——一个方便的可选用户界面</p>
			<p class="callout">H2O生成了自己的名为H2O流的web用户界面，在模型构建过程中可以选择使用。H2O流的UI焦点和丰富的特性可用于完整的模型构建工作流，或利用便利的技巧，正如我们将在第5章 、<em class="italic">高级模型构建-第1部分</em>中演示的那样。</p>
			<p>因此，数据科学家在一个熟悉的世界中工作，这个世界连接到一个复杂的架构，以将模型构建扩展到大型或海量数据集。我们将在下一节探讨这个架构。</p>
			<h2 id="_idParaDest-37"><a id="_idTextAnchor036"/>H2O星团</h2>
			<p>对于所有利益相关者来说，<a id="_idIndexMarker104"/> H2O集群可能是最需要理解的核心概念。这就是H2O如何创建其在企业服务器集群上构建机器学习模型的架构单元。我们可以通过下图来理解这个<a id="_idIndexMarker105"/>概念:</p>
			<div><div><img src="img/B16721_Figure_2.3.jpg" alt="Figure 2.3 – The architecture of the H2O cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图2.3–H2O集群的架构</p>
			<p>当一名数据科学家启动一个H2O集群时，他们会指定分配工作的服务器数量(也称为<em class="italic">节点</em>的数量)，以及每个节点使用的内存和CPU数量。我们将了解到，这可以通过手动配置或允许Enterprise Steam根据训练数据量自动计算这些规格来实现。</p>
			<p>当H2O集群启动时，IDE将H2O软件(单个JAR文件)推送到企业服务器集群中每个指定数量的节点，其中每个节点分配指定的内存和CPU。然后，H2O软件组织成一个自通信集群，其中一个节点被选为与IDE通信并与H2O集群的其余节点协调的主节点。</p>
			<p>数据科学家从IDE连接到已启动的H2O集群。然后，数据科学家编写模型构建代码。代码的每一部分都由IDE中的H2O库翻译成给H2O集群的指令。每条指令按顺序发送到H2O集群上的主节点，主节点将指令分发到其他H2O集群成员，在那里并行执行指令。leader节点收集和组合结果，并将它们发送回IDE。</p>
			<p>以下是一些需要牢记的重要注意事项:</p>
			<ul>
				<li>数据直接从数据源接收到H2O节点的内存中。源数据在H2O节点之间进行分区，不会在它们之间重复。从存储层(例如，S3、HDFS等)接收的数据是并行完成的，因此速度很快。来自外部来源的数据(例如GitHub存储库和JDBC数据库表)不是并行完成的。在所有情况下，数据都不会通过IDE或客户端传递。</li>
				<li>每个H2O集群都是独立的，与其他集群隔离开来，包括接收到其中的数据。因此，启动集群并使用相同数据源的两个用户不会共享数据。</li>
				<li>我们将<a id="_idIndexMarker107"/>看到Enterprise Steam的管理员为用户可以启动的并发集群数量指定了上限，以及用户在启动集群时可以指定的内存、CPU和其他资源的数量。</li>
				<li>H2O星团是静态的。一旦启动，节点数量和每个节点的资源数量不会改变，直到它们被终止，在这种情况下，H2O集群被拆除。如果其中一个节点关闭，则必须重新启动H2O集群，并从头开始从IDE构建模型。对于较长时间的工作，H2O的检查点功能可以帮助您从一个还原点继续。</li>
			</ul>
			<p>让我们看看H2O集群的<a id="_idIndexMarker108"/>生命周期，如下图所示:</p>
			<div><div><img src="img/B16721_Figure_2.4.jpg" alt="Figure 2.4 – The life cycle of the H2O cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图2.4-H2O集群的生命周期</p>
			<p>让我们一个接一个地看看生命周期的每个阶段，以了解它们是如何工作的:</p>
			<ol>
				<li value="1"><strong class="bold">启动</strong>:数据科学家从企业Steam UI或API启动H2O集群。选择H2O-3或苏打水。H2O集群大小和资源(即节点数量、每个节点的内存和其他配置)是手动输入的，或者是由Enterprise Steam根据用户输入的数据量自动生成的。H2O星系团如前所述形成。</li>
				<li><strong class="bold">连接到</strong>:数据科学家切换到他们的IDE，通过指定集群名称连接到H2O集群。</li>
				<li><strong class="bold">在</strong>上建立模型:数据科学家使用H2O建立模型。IDE中使用的H2O库将每次模型构建迭代的H2O API代码翻译成指令。这些数据被发送到主节点，并分布在H2O集群中。</li>
				<li><strong class="bold">停止</strong>:H2O集群关闭。释放资源，并从H2O集群的每个节点上删除H2O软件。这可以由用户从IDE中完成，也可以在空闲一段时间后或超过H2O集群的绝对运行时间时自动完成(这些持续时间是在生命周期的第1步中的H2O集群启动中指定的)。尽管没有运行，但用户仍然可以获得有关该集群的信息(例如，名称、H2O版本和大小)。</li>
			</ol>
			<p><strong class="bold">停止/保存数据&amp;重启</strong>:这是<strong class="bold">停止</strong>的替代选项，当企业Steam管理员为用户或用户组配置此选项时，这是可能的。在这种情况下，当H2O集群停止时，它将模型<a id="_idIndexMarker110"/>构建步骤中的数据保存到存储层(即保存模型构建状态)。当群集重新启动时(使用与启动时相同的名称)，群集将启动并返回到其先前的状态。</p>
			<ol>
				<li value="5"><strong class="bold">删除</strong>:这将停止集群(如果正在运行)并永久删除对H2O集群的所有引用。如果它已停止并保存了模型构建状态，该数据也将被永久删除。</li>
			</ol>
			<h2 id="_idParaDest-38"><a id="_idTextAnchor037"/>企业蒸汽作为H2O门户</h2>
			<p>所有H2O管理活动都发生在企业Steam上，用户必须通过Steam启动H2O集群。这种<em class="italic">条条大路通企业Steam </em>的方法意味着Steam在用户及其H2O集群被发布到企业系统之前对其进行管理。下图对此进行了详细说明:</p>
			<div><div><img src="img/B16721_Figure_2.5.jpg" alt="Figure 2.5 – Enterprise Steam viewed as an H2O gateway to the enterprise cluster&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图2.5–企业Steam被视为企业集群的H2O网关</p>
			<p>管理员<a id="_idIndexMarker112"/>配置设置以管理H2O用户，并将Enterprise Steam与企业服务器集群集成。此外，管理员存储H2O软件版本，这些版本将在H2O群集启动时被推送到服务器群集，并在群集停止和资源释放时被删除。管理员还可以访问用户使用数据。这都是通过一个仅用于管理的UI来完成的。</p>
			<p>管理员配置用户以及用户如何在企业环境中启动H2O集群。这些配置定义了用户可以同时启动的并发集群数量、大小(即节点数量)以及为每个启动的H2O集群分配的资源数量(例如，每个节点的内存)。配置还定义了当用户不在IDE中从H2O模型构建代码手动停止或删除时，群集将何时停止或删除。一组这样的配置被定义为一个配置文件，一个或多个配置文件被分配给用户或用户组。因此，管理员可以将一些用户指定为高级用户，将其他用户指定为轻度用户。</p>
			<p>用户通过同一个身份提供者(例如LDAP)向Enterprise Steam进行身份验证，该身份提供者用于授权访问企业服务器集群环境中的资源(例如S3存储桶)。当<a id="_idIndexMarker113"/>用户启动一个集群时，Enterprise Steam传递用户身份，这个身份在企业系统上的授权质询期间使用。ide中的用户必须通过Enterprise Steam API的身份验证才能连接到他们已经启动的集群。</p>
			<p class="callout-heading">H2O核心需要企业蒸汽吗？</p>
			<p class="callout">请注意，H2O核心不需要企业蒸汽。企业管理员可以配置其企业服务器集群基础架构，以允许在此基础架构上启动H2O集群。</p>
			<p class="callout">然而，这种方法并不是一种合理的企业实践。它引入了控制和治理的缺失，而Enterprise Steam提供了一个集中式H2O网关来保护、管理和登录用户，如本节所述。此外，Enterprise Steam还为用户带来了好处，让他们在启动H2O集群时，不必再经历将H2O核心与企业集群集成的技术步骤，例如Kerberos安全要求。在<a href="B16721_11_Final_SK_ePub.xhtml#_idTextAnchor207"> <em class="italic">第11章</em> </a>、<em class="italic">管理员和运营视图</em>以及<a href="B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226"> <em class="italic">第12章</em> </a>、<em class="italic">企业架构师和安全视图</em>中更详细地探讨了企业Steam的企业优势。</p>
			<p class="callout">此外，请记住，H2O核心是免费和开源的，而企业蒸汽不是。</p>
			<h2 id="_idParaDest-39"><a id="_idTextAnchor038"/>企业Steam和H2O核心高层架构</h2>
			<p>现在<a id="_idIndexMarker114"/>我们已经知道了H2O集群是如何形成的，以及Enterprise Steam在管理H2O用户和启动H2O集群中扮演的角色，让我们从高级部署的角度来理解Enterprise Steam和H2O核心架构。下图描述了这种部署架构:</p>
			<div><div><img src="img/B16721_Figure_2.6.jpg" alt="Figure 2.6 – Enterprise Steam and the H2O Core high-level deployment architecture&#13;&#10;"/>
				</div>
			</div>
			<p class="figure-caption">图2.6–企业Steam和H2O核心高级部署架构</p>
			<p>Enterprise Steam <a id="_idIndexMarker115"/>运行在自己的专用服务器上，通过HTTP(S)与企业服务器集群通信。如前所述，Enterprise Steam存储H2O核心(H2O-3或苏打水)JAR文件，该文件被推送到服务器集群，然后服务器集群自组织成一个协调但分布式的H2O集群。这个H2O集群可以是一个native YARN或Kubernetes作业，这取决于实现了哪个后端。注意，H2O-3是在Map-Reduce框架上运行的，而苏打水是在Spark框架上运行的。</p>
			<p>H2O-3或苏打水API库被安装到data science IDE中(例如，Jupyter环境中H2O-3包的<code>pip install</code>)。它必须与用于从Enterprise Steam启动集群的版本相匹配。如前所述，数据科学家使用IDE对企业级Steam进行认证，连接到H2O集群，并编写H2O模型构建代码。H2O客户端库将H2O模型构建代码翻译成REST消息，并发送给H2O集群的领导节点。然后，在H2O集群中分配工作，并将结果返回给IDE。</p>
			<p>请注意，企业集群可以是内部部署、云基础设施即服务或托管服务实施。例如，它们可以是内部或云中的Kubernetes或Cloudera CDH，或者云中的Cloudera CDP或Amazon EMR。全面部署<a id="_idIndexMarker116"/>的可能性在<a href="B16721_12_Final_SK_ePub.xhtml#_idTextAnchor226"> <em class="italic">第12章</em> </a>、<em class="italic">企业架构师和安全视图</em>中有更详细的讨论。</p>
			<p class="callout-heading">H2O平台选择</p>
			<p class="callout">在本书中，H2O在规模技术被称为包括:H2O企业蒸汽+ H2O核心(H2O-3，H2O苏打水)+ H2O MOJO。大规模H2O集成了用于模型构建的企业服务器集群和用于模型部署的企业评分环境。</p>
			<p class="callout">仅用上述组件就可以实现大规模H2O。或者，大规模H2O可以作为更大的H2O机器学习平台和称为H2O人工智能云的能力集的子集来实现。H2O人工智能云平台在<em class="italic">第5节——拓宽视野——H2O人工智能云平台的人工智能应用数据中有更详细的描述</em>。</p>
			<h2 id="_idParaDest-40"><a id="_idTextAnchor039"/>苏打水允许用户在H2O编码，无缝火花</h2>
			<p>下面的代码显示了一个简单的例子，火花和H2O集成在同一个H2O代码<a id="_idIndexMarker117"/>使用H2O苏打水:</p>
			<pre class="source-code"># import data</pre>
			<pre class="source-code">loans_spark = spark.read.load("loans.csv", format="csv", sep=",", inferSchema="true", header="true")</pre>
			<pre class="source-code"># Spark data engineering code</pre>
			<pre class="source-code">loans_spark = # any Spark SQL or Spark DataFrame code</pre>
			<pre class="source-code"># Convert Spark DataFrame to H2O Frame</pre>
			<pre class="source-code">loans = h2oContext.asH2OFrame(loans_spark)</pre>
			<pre class="source-code"># Continue with H2O model building steps as in previous code example</pre>
			<pre class="source-code">loans.describe()</pre>
			<p><a id="_idIndexMarker118"/>代码显示火花导入数据，保存为<a id="_idIndexMarker119"/>一个<strong class="bold">火花数据帧</strong>。<strong class="bold"> Spark SQL </strong>或<strong class="bold"> Spark DataFrame </strong> API用于将该数据设计成新的数据帧，然后该Spark DataFrame <a id="_idIndexMarker120"/>被转换成<a id="_idIndexMarker121"/>an<strong class="bold">h2of frame</strong>，从该数据帧执行H2O模型构建。因此，用户在相同的API语言和IDE中无缝地从Spark迭代到H2O代码。</p>
			<p>H2O集团的想法对于苏打水仍然是基本正确的。它现在表达了Spark框架内的H2O集群架构。该架构的细节在第12章 、<em class="italic">企业架构师和安全视图</em>中进行了阐述。</p>
			<h2 id="_idParaDest-41"><a id="_idTextAnchor040"/>mojo导出为DevOps友好的工件</h2>
			<p>数据科学家<a id="_idIndexMarker122"/>构建模型，但最终目标是将模型投入到生产环境中，在商业环境中进行预测。MOJOs使这最后一英里的部署变得简单。MOJOs由一行代码导出。例如，无论模型是使用Python、R构建的，还是使用广义线性模型、XGBoost模型或stacked ensemble构建的，从DevOps的角度来看，所有的MOJOs都是相同的。这使得模型部署是可重复的，因此，能够适应整个组织中使用的现有自动化CI/CD管道。</p>
			<h1 id="_idParaDest-42"><a id="_idTextAnchor041"/>总结</h1>
			<p>在这一章中，我们为大规模理解H2O机器学习奠定了基础。我们首先回顾了一个最简单的<em class="italic"> Hello World </em>代码示例，并讨论了围绕它的规模问题。然后，我们介绍了H2O核心、企业Steam和MOJO技术组件，以及这些组件如何克服规模问题。最后，我们从这些技术中提取了一组关键概念来加深我们的理解。</p>
			<p>在下一章中，我们将利用这种理解开始我们的旅程，学习如何大规模地构建和部署世界级的模型。开始编码吧！</p>
		</div>
	

</body></html>