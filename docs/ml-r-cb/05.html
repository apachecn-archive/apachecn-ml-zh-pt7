<html><head/><body>
<html>
  <head>
    <title>Chapter 5. Classification (I) – Tree, Lazy, and Probabilistic</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0">第五章。分类(I)-树型、惰性和概率型</h1></div></div></div><p class="calibre7">在本章中，我们将介绍以下配方:</p><div><ul class="itemizedlist"><li class="listitem">准备训练和测试数据集</li><li class="listitem">用递归划分树建立分类模型</li><li class="listitem">可视化递归划分树</li><li class="listitem">测量递归划分树的预测性能</li><li class="listitem">修剪递归分区树</li><li class="listitem">用条件推理树建立分类模型</li><li class="listitem">可视化条件推理树</li><li class="listitem">测量条件推理树的预测性能</li><li class="listitem">用 k-最近邻分类器对数据进行分类</li><li class="listitem">用逻辑回归对数据进行分类</li><li class="listitem">使用朴素贝叶斯分类器分类数据</li></ul></div></div></body></html>


<html>
  <head>
    <title>Chapter 5. Classification (I) – Tree, Lazy, and Probabilistic</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h1 class="title" id="calibre_pb_1"><a id="ch05lvl1sec54" class="calibre1"/>简介</h1></div></div></div><p class="calibre7">分类用于根据从训练数据集构建的<a id="id431" class="calibre1"/>分类模型来识别新观察值(测试数据集)的类别，其中类别是已知的。与回归类似，分类被归类为监督学习方法，因为它采用训练数据集的已知答案(标签)来<a id="id432" class="calibre1"/>预测测试<a id="id433" class="calibre1"/>数据集的答案(标签)。回归和分类的主要区别在于，回归用于预测连续值。</p><p class="calibre7">与此相反，分类用于识别给定观察的类别。例如，可以根据历史价格使用回归来预测给定股票的未来价格。但是，我们应该使用分类方法来预测股价是上涨还是下跌。</p><p class="calibre7">在这一章中，我们将说明如何使用 R 来执行分类。我们首先从流失数据集构建训练数据集和测试数据集，然后应用不同的分类方法对流失数据集进行分类。在下面的配方中，我们将介绍使用传统分类树和条件推理树的基于树的分类方法、基于懒惰的算法以及使用训练数据集建立分类模型的基于概率的方法，然后使用该模型来预测测试数据集的类别(类标签)。我们还将使用混淆矩阵来衡量性能。</p></div></div></body></html>


<html>
  <head>
    <title>Preparing the training and testing datasets</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec55" class="calibre1"/>准备训练和测试数据集</h1></div></div></div><p class="calibre7">建立<a id="id434" class="calibre1"/>分类模型需要<a id="id435" class="calibre1"/>训练数据集来训练分类模型，然后需要测试数据来验证预测性能。在下面的食谱中，我们将演示如何将电信客户流失数据集分别拆分为训练数据集和测试数据集。</p></div></body></html>


<html>
  <head>
    <title>Preparing the training and testing datasets</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec177" class="calibre1"/>准备就绪</h2></div></div></div><p class="calibre7">在这个菜谱中，我们将使用电信客户流失数据集作为输入数据源，并将数据分成训练和测试数据集。</p></div></div></body></html>


<html>
  <head>
    <title>Preparing the training and testing datasets</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec178" class="calibre1"/>怎么做...</h2></div></div></div><p class="calibre7">执行以下步骤将流失数据集分为训练数据集和测试数据集:</p><div><ol class="orderedlist"><li class="listitem" value="1">您可以从<code class="email">C50</code>包中检索流失数据集:<div> <pre class="programlisting"> <strong class="calibre2">&gt; install.packages("C50")</strong> <strong class="calibre2">&gt; library(C50)</strong> <strong class="calibre2">&gt; data(churn)</strong> </pre> </div></li><li class="listitem" value="2">使用<code class="email">str</code>读取数据集的结构:<div> <pre class="programlisting"> <strong class="calibre2">&gt; str(churnTrain)</strong> </pre> </div></li><li class="listitem" value="3">我们可以去掉<code class="email">state</code>、<code class="email">area_code</code>、<code class="email">account_length</code>属性，这些属性不适合分类特征:<div> <pre class="programlisting"> <strong class="calibre2">&gt; churnTrain = churnTrain[,! names(churnTrain) %in% c("state", "area_code", "account_length") ]</strong> </pre> </div></li><li class="listitem" value="4">然后，将 70%的数据分成训练数据集，30%的数据分成测试数据集:<div> <pre class="programlisting"> <strong class="calibre2">&gt; set.seed(2)</strong> <strong class="calibre2">&gt; ind = sample(2, nrow(churnTrain), replace = TRUE, prob=c(0.7, 0.3))</strong> <strong class="calibre2">&gt; trainset = churnTrain[ind == 1,]</strong> <strong class="calibre2">&gt; testset = churnTrain[ind == 2,]</strong> </pre> </div></li><li class="listitem" value="5">最后，使用<code class="email">dim</code>探索训练和测试数据集的维度:<div> <pre class="programlisting"> <strong class="calibre2">&gt; dim(trainset)</strong> <strong class="calibre2">[1] 2315   17</strong> <strong class="calibre2">&gt; dim(testset)</strong> <strong class="calibre2">[1] 1018   17</strong> </pre> </div></li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Preparing the training and testing datasets</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3">它是如何工作的...</h2></div></div></div><p class="calibre7">在这个<a id="id436" class="calibre1"/>配方中，我们使用电信客户流失<a id="id437" class="calibre1"/>数据集作为我们的示例数据源。数据集包含 20 个变量和 3333 个观察值。我们希望建立一个分类模型来预测客户是否会流失，这对电信公司来说非常重要，因为获得一个新客户的成本远远高于留住一个客户的成本。</p><p class="calibre7">在建立分类模型之前，我们需要首先对数据进行预处理。因此，我们将来自<code class="email">C50</code>包的流失数据加载到 R 会话中，变量名为<code class="email">churn</code>。当我们确定属性如<code class="email">state</code>、<code class="email">area_code</code>和<code class="email">account_length</code>对于建立分类模型不是有用的特征时，我们移除这些属性。</p><p class="calibre7">在对数据进行预处理后，我们将其分别分成训练数据集和测试数据集。然后，我们使用一个样本函数随机生成一个序列，该序列包含 70%的训练数据集和 30%的测试数据集，其大小等于观察值的数量。然后，我们使用生成的序列将流失数据集分成训练数据集<code class="email">trainset</code>和测试数据集<code class="email">testset</code>。最后，通过使用<code class="email">dim</code>函数，我们发现 3333 个观察值中的 2315 个被归类到训练数据集<code class="email">trainset</code>，而另外 1018 个被归类到测试数据集<code class="email">testset</code>。</p></div></div></body></html>


<html>
  <head>
    <title>Preparing the training and testing datasets</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch05lvl2sec180" class="calibre1"/>还有更多...</h2></div></div></div><p class="calibre7">您可以将训练和测试数据集的拆分过程合并到<code class="email">split.data</code>函数中。因此，通过调用此函数并在参数中指定比例和种子，您可以轻松地将数据分成两个数据集:</p><div><pre class="programlisting">
<strong class="calibre2">&gt; split.data = function(data, p = 0.7, s = 666){</strong>
<strong class="calibre2">+   set.seed(s)</strong>
<strong class="calibre2">+   index = sample(1:dim(data)[1])</strong>
<strong class="calibre2">+   train = data[index[1:floor(dim(data)[1] * p)], ]</strong>
<strong class="calibre2">+   test = data[index[((ceiling(dim(data)[1] * p)) + 1):dim(data)[1]], ]</strong>
<strong class="calibre2">+   return(list(train = train, test = test))</strong>
<strong class="calibre2">+ } </strong>
</pre></div></div></div></body></html>


<html>
  <head>
    <title>Building a classification model with recursive partitioning trees</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec56" class="calibre1"/>用递归分割树建立分类模型</h1></div></div></div><p class="calibre7">分类树基于一个或多个输入<a id="id438" class="calibre1"/>变量使用分裂条件来预测分类标签。<a id="id439" class="calibre1"/>分类过程从树的根节点开始；在每个节点，该过程将检查输入值是否应该根据分裂条件递归地继续到右边或左边的子分支，并且当遇到决策树的任何叶(终端)节点时停止。在这个菜谱中，我们将介绍如何对客户流失数据集应用递归分区树。</p></div></body></html>


<html>
  <head>
    <title>Building a classification model with recursive partitioning trees</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1">准备就绪</h2></div></div></div><p class="calibre7">您需要通过将客户流失数据集分为训练数据集(<code class="email">trainset</code>)和测试数据集(<code class="email">testset</code>)来完成前面的配方，每个数据集应该正好包含 17 个变量。</p></div></div></body></html>


<html>
  <head>
    <title>Building a classification model with recursive partitioning trees</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec182" class="calibre1"/>怎么做...</h2></div></div></div><p class="calibre7">执行以下步骤将流失数据集分为训练数据集和测试数据集:</p><div><ol class="orderedlist"><li class="listitem" value="1">加载<code class="email">rpart</code>包:<div> <pre class="programlisting"> <strong class="calibre2">&gt; library(rpart)</strong> </pre> </div></li><li class="listitem" value="2">使用<code class="email">rpart</code>函数构建分类树模型:<div> <pre class="programlisting"> <strong class="calibre2">&gt; churn.rp = rpart(churn ~ ., data=trainset)</strong> </pre> </div></li><li class="listitem" value="3">键入<code class="email">churn.rp</code>检索分类树的节点明细:<div> <pre class="programlisting"> <strong class="calibre2">&gt; churn.rp </strong> </pre> </div></li><li class="listitem" value="4">接下来，使用<a id="id440" class="calibre1"/><code class="email">printcp</code>函数检查复杂度参数:<div> <pre class="programlisting"> <strong class="calibre2">&gt; printcp(churn.rp)</strong>  <strong class="calibre2">Classification tree:</strong> <strong class="calibre2">rpart(formula = churn ~ ., data = trainset)</strong>  <strong class="calibre2">Variables actually used in tree construction:</strong> <strong class="calibre2">[1] international_plan            number_customer_service_calls</strong> <strong class="calibre2">[3] total_day_minutes             total_eve_minutes            </strong> <strong class="calibre2">[5] total_intl_calls              total_intl_minutes           </strong> <strong class="calibre2">[7] voice_mail_plan              </strong>  <strong class="calibre2">Root node error: 342/2315 = 0.14773</strong>  <strong class="calibre2">n= 2315 </strong>  <strong class="calibre2">        CP nsplit rel error  xerror     xstd</strong> <strong class="calibre2">1 0.076023      0   1.00000 1.00000 0.049920</strong> <strong class="calibre2">2 0.074561      2   0.84795 0.99708 0.049860</strong> <strong class="calibre2">3 0.055556      4   0.69883 0.76023 0.044421</strong> <strong class="calibre2">4 0.026316      7   0.49415 0.52632 0.037673</strong> <strong class="calibre2">5 0.023392      8   0.46784 0.52047 0.037481</strong> <strong class="calibre2">6 0.020468     10   0.42105 0.50877 0.037092</strong> <strong class="calibre2">7 0.017544     11   0.40058 0.47076 0.035788</strong> <strong class="calibre2">8 0.010000     12   0.38304 0.47661 0.035993</strong> </pre> </div></li><li class="listitem" value="5">Next, use <a id="id441" class="calibre1"/>the <code class="email">plotcp</code> function to plot the cost complexity parameters:<div><pre class="programlisting">
<strong class="calibre2">&gt; plotcp(churn.rp)</strong>
</pre></div><div><img src="img/00101.jpeg" alt="How to do it..." class="calibre9"/><div><p class="calibre12">图 1:成本复杂性参数图</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="6">最后，使用<code class="email">summary</code>函数来检查构建好的模型:<div> <pre class="programlisting"> <strong class="calibre2">&gt; summary(churn.rp)</strong> </pre> </div></li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Building a classification model with recursive partitioning trees</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec183" class="calibre1"/>工作原理...</h2></div></div></div><p class="calibre7">在这个<a id="id442" class="calibre1"/>方法中，我们使用来自<code class="email">rpart</code>包的<a id="id443" class="calibre1"/>递归分区树来构建一个基于树的分类模型。递归划分树包括两个过程:递归和划分。在决策归纳过程中，我们必须考虑一个统计评估问题(或简单的是/否问题),根据评估结果将数据划分到不同的分区。然后，由于我们已经确定了子节点，我们可以重复执行分割，直到满足停止标准。</p><p class="calibre7">例如，对于<strong class="calibre2"> f1 </strong>是否小于<strong class="calibre2"> X </strong>的问题，根节点中的数据(如下图所示)可以分为两组。如果是这样，数据被划分到左侧。否则，它将被拆分到右侧。然后，我们可以用<strong class="calibre2"> f2 </strong>是否小于<strong class="calibre2"> Y </strong>的问题继续划分左侧数据:</p><div><img src="img/00102.jpeg" alt="How it works..." class="calibre9"/><div><p class="calibre12">图 2:递归划分树</p></div></div><p class="calibre10"> </p><p class="calibre7">在<a id="id444" class="calibre1"/>的第一步中，我们用<code class="email">library</code>函数加载<a id="id445" class="calibre1"/>的<code class="email">rpart</code>包。接下来，我们使用<code class="email">churn</code>变量作为分类类别(类标签)并使用剩余变量作为输入特征来构建分类模型。</p><p class="calibre7">在构建模型之后，您可以键入构建模型的变量名<code class="email">churn.rp</code>，以显示树节点的详细信息。在打印的节点明细中，<code class="email">n</code>表示样本大小，<code class="email">loss</code>表示误分类成本，<code class="email">yval</code>表示分类隶属度(在本例中为<code class="email">no</code>或<code class="email">yes</code>)，而<code class="email">yprob</code>表示两个类别的概率(左边的值表示概率到达标签<code class="email">no</code>，右边的值表示概率到达标签<code class="email">yes</code>)。</p><p class="calibre7">然后，我们使用<code class="email">printcp</code>函数打印所构建的树模型的复杂度参数。从<code class="email">printcp</code>的输出中，应该可以找到复杂度参数 CP 的值，该值作为控制树的大小的惩罚。简而言之，CP 值越大，分裂次数越少(<code class="email">nsplit</code>)。输出值(<code class="email">rel</code>错误)代表当前树的平均偏差除以空树的平均偏差。<code class="email">xerror</code>值表示由 10 倍分类估计的相对误差。<code class="email">xstd</code>代表相对误差的标准误差。</p><p class="calibre7">为了使<a id="id446" class="calibre1"/><strong class="calibre2">CP</strong>(<strong class="calibre2">成本复杂度参数</strong>)表更具可读性，我们使用<code class="email">plotcp</code>生成 CP 表的信息图。根据截图(步骤 5)，底部的 x 轴表示<code class="email">cp</code>值，y 轴表示相对误差，上部的 x 轴显示树的大小。虚线表示标准偏差的上限。从截图中，我们可以确定当树的大小为 12 时，交叉验证错误最小。</p><p class="calibre7">我们<a id="id447" class="calibre1"/>也可以使用<code class="email">summary</code>函数来显示函数调用，拟合<a id="id448" class="calibre1"/>树模型的复杂度参数表，变量重要性，这有助于识别对树分类最重要的变量(总计 100)，以及每个节点的详细信息。</p><p class="calibre7">使用决策树的优点是它非常灵活并且易于解释。它既能处理分类和回归问题，还能处理更多问题；它是非参数的。因此，人们不必担心数据是否是线性可分的。至于使用决策树的缺点，就是容易有偏差和过拟合。但是，您可以通过使用条件推理树来克服偏差问题，并通过随机森林方法或树修剪来解决过拟合问题。</p></div></div></body></html>


<html>
  <head>
    <title>Building a classification model with recursive partitioning trees</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch05lvl2sec184" class="calibre1"/>参见</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">关于<code class="email">rpart</code>、<code class="email">printcp</code>和<code class="email">summary</code>功能的更多信息，请使用<code class="email">help</code>功能:<div> <pre class="programlisting"> <strong class="calibre2">&gt; ?rpart</strong> <strong class="calibre2">&gt; ?printcp</strong> <strong class="calibre2">&gt; ?summary.rpart</strong> </pre> </div></li><li class="listitem"><code class="email">C50</code>是另一个<a id="id449" class="calibre1"/>包，它提供了决策树和基于规则的<a id="id450" class="calibre1"/>模型。如果你对这个包感兴趣，你可以在<a class="calibre1" href="http://cran.r-project.org/web/packages/C50/C50.pdf">http://cran.r-project.org/web/packages/C50/C50.pdf</a>查阅这个文件。</li></ul></div></div></div></body></html>


<html>
  <head>
    <title>Visualizing a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec57" class="calibre1"/>可视化递归分割树</h1></div></div></div><p class="calibre7">从<a id="id451" class="calibre1"/>最后一个配方中，我们学习了如何以文本格式打印分类树。为了使树更具可读性，我们可以使用<code class="email">plot</code>函数来获得构建的分类树的图形显示。</p></div></body></html>


<html>
  <head>
    <title>Visualizing a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1">做好准备</h2></div></div></div><p class="calibre7">需要通过生成一个分类模型来完成之前的配方，并将该模型分配到<code class="email">churn.rp</code>变量中。</p></div></div></body></html>


<html>
  <head>
    <title>Visualizing a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2">如何做到这一点...</h2></div></div></div><p class="calibre7">执行<a id="id452" class="calibre1"/>以下步骤来可视化分类树:</p><div><ol class="orderedlist"><li class="listitem" value="1">Use the <code class="email">plot</code> function and the <code class="email">text</code> function to plot the classification tree:<div><pre class="programlisting">
<strong class="calibre2">&gt; plot(churn.rp, margin= 0.1)</strong>
<strong class="calibre2">&gt; text(churn.rp, all=TRUE, use.n = TRUE)</strong>
</pre></div><div><img src="img/00103.jpeg" alt="How to do it..." class="calibre9"/><div><p class="calibre12">图 3:分类树的图形显示</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="2">You can also specify the <code class="email">uniform</code>, <code class="email">branch</code>, and <code class="email">margin</code> parameter to adjust the layout:<div><pre class="programlisting">
<strong class="calibre2">&gt; plot(churn.rp, uniform=TRUE, branch=0.6, margin=0.1)</strong>
<strong class="calibre2">&gt; text(churn.rp, all=TRUE, use.n = TRUE)</strong>
</pre></div><div><img src="img/00104.jpeg" alt="How to do it..." class="calibre9"/><div><p class="calibre12">图 4:调整分类树的布局</p></div></div><p class="calibre13"> </p></li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Visualizing a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec187" class="calibre1"/>工作原理...</h2></div></div></div><p class="calibre7">在这里，我们<a id="id453" class="calibre1"/>演示如何使用<code class="email">plot</code>函数以图形方式显示分类树。<code class="email">plot</code>函数可以简单地可视化分类树，然后您可以使用<code class="email">text</code>函数向图中添加文本。</p><p class="calibre7">在<em class="calibre8">图 3 </em>中，我们指定 margin = 0.1 作为参数，在边框周围添加额外的空白，以防止显示的文本被边距截断。它表明分支的长度显示了偏差下降的相对幅度。然后，我们使用 text 函数为节点和分支添加标签。默认情况下，text 函数会在每次拆分时添加一个拆分条件，并在每个终端节点中添加一个类别标签。为了在树形图中添加额外的信息，我们将参数设置为 all 等于<code class="email">TRUE</code>，以便为所有节点添加一个标签。除此之外，我们通过指定<code class="email">use.n = TRUE</code>来添加一个参数，以添加额外的信息，这表明实际的观察数量属于两个不同的类别(否和是)。</p><p class="calibre7">在图 4 的<em class="calibre8">中，我们将选项分支设置为 0.6，为每个绘制的分支添加一个肩部。除此之外，为了显示等长的分支，而不是偏差下降的相对幅度，我们将选项 uniform 设置为<code class="email">TRUE</code>。结果，<em class="calibre8">图 4 </em>显示了一个短肩和等长分支的分类树。</em></p></div></div></body></html>


<html>
  <head>
    <title>Visualizing a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch05lvl2sec188" class="calibre1"/>亦见</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">你可以使用<code class="email">?plot.rpart</code>阅读更多关于分类树的绘制。本文档还包括如何指定<a id="id454" class="calibre1"/>参数、<code class="email">uniform</code>、<code class="email">branch</code>、<code class="email">compress</code>、<code class="email">nspace</code>、<code class="email">margin</code>和<code class="email">minbranch</code>来调整分类树布局的信息。</li></ul></div></div></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec58" class="calibre1"/>测量递归分割树的预测性能</h1></div></div></div><p class="calibre7">由于我们已经在前面的食谱中建立了一个分类树，我们可以用它来预测新观察值的<a id="id455" class="calibre1"/>类别(类标签)。在进行预测之前，我们首先验证分类树的预测能力，这可以通过在测试数据集上生成分类表来完成。在本菜谱中，我们将介绍如何使用<code class="email">predict</code>函数和<code class="email">table</code>函数生成预测标签和真实标签表，并解释如何生成混淆矩阵来衡量性能。</p></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1"><a id="ch05lvl2sec189" class="calibre1"/>做好准备</h2></div></div></div><p class="calibre7">您需要通过生成分类模型<code class="email">churn.rp</code>来完成之前的配方。除此之外，您还必须准备本章第一个菜谱中生成的训练数据集<code class="email">trainset</code>和测试数据集<code class="email">testset</code>。</p></div></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec190" class="calibre1"/>怎么做...</h2></div></div></div><p class="calibre7">执行以下步骤来验证分类树的预测性能:</p><div><ol class="orderedlist"><li class="listitem" value="1">您可以使用<code class="email">predict</code>函数生成测试数据集的预测标签:<div> <pre class="programlisting"> <strong class="calibre2">&gt; predictions = predict(churn.rp, testset, type="class")</strong> </pre> </div></li><li class="listitem" value="2">使用<code class="email">table</code>函数生成测试数据集的分类表:<div> <pre class="programlisting"> <strong class="calibre2">&gt; table(testset$churn, predictions)</strong> <strong class="calibre2">     predictions</strong> <strong class="calibre2">      yes  no</strong> <strong class="calibre2">  yes 100  41</strong> <strong class="calibre2">  no   18 859</strong> </pre> </div></li><li class="listitem" value="3">可以使用<code class="email">caret</code>包中提供的<code class="email">confusionMatrix</code>函数进一步生成混淆矩阵:<div> <pre class="programlisting"> <strong class="calibre2">&gt; library(caret)</strong> <strong class="calibre2">&gt; confusionMatrix(table(predictions, testset$churn))</strong> <strong class="calibre2">Confusion Matrix and Statistics</strong>  <strong class="calibre2">           </strong> <strong class="calibre2">predictions yes  no</strong> <strong class="calibre2">        yes 100  18</strong> <strong class="calibre2">        no   41 859</strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">               Accuracy : 0.942           </strong> <strong class="calibre2">                 95% CI : (0.9259, 0.9556)</strong> <strong class="calibre2">    No Information Rate : 0.8615          </strong> <strong class="calibre2">    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">                  Kappa : 0.7393          </strong> <strong class="calibre2"> Mcnemar's Test P-Value : 0.004181        </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">            Sensitivity : 0.70922         </strong> <strong class="calibre2">            Specificity : 0.97948         </strong> <strong class="calibre2">         Pos Pred Value : 0.84746         </strong> <strong class="calibre2">         Neg Pred Value : 0.95444         </strong> <strong class="calibre2">             Prevalence : 0.13851         </strong> <strong class="calibre2">         Detection Rate : 0.09823         </strong> <strong class="calibre2">   Detection Prevalence : 0.11591         </strong> <strong class="calibre2">      Balanced Accuracy : 0.84435         </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">       'Positive' Class : yes             </strong> </pre> </div></li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec191" class="calibre1"/>工作原理...</h2></div></div></div><p class="calibre7">在这个<a id="id456" class="calibre1"/>方案中，我们使用一个<code class="email">predict</code>函数并建立分类模型<code class="email">churn.rp</code>，来预测测试数据集<code class="email">testset</code>的可能类别标签。预测类别(分类标签)编码为“否”或“是”。然后，我们使用<code class="email">table</code>函数在测试数据集上生成一个分类表。从表中，我们发现有 859 个被正确预测为否，而 18 个被错误分类为是。100 个“是”预测被正确预测，但是 41 个观察值被错误分类为“否”。此外，我们使用<code class="email">caret</code>包中的<code class="email">confusionMatrix</code>函数来产生分类模型的测量值。</p></div></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch05lvl2sec192" class="calibre1"/>参见</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">您<a id="id457" class="calibre1"/>可以使用<code class="email">?confusionMatrix</code>阅读更多关于使用混淆矩阵进行绩效评估的信息</li><li class="listitem">对混淆矩阵输出的定义感兴趣的人，请<a id="id458" class="calibre1"/>参考维基百科词条，<strong class="calibre2">混淆 _ 矩阵</strong>(<a class="calibre1" href="http://en.wikipedia.org/wiki/Confusion_matrix">http://en.wikipedia.org/wiki/Confusion_matrix</a>)</li></ul></div></div></div></body></html>


<html>
  <head>
    <title>Pruning a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec59" class="calibre1"/>修剪递归分割树</h1></div></div></div><p class="calibre7">在之前的菜谱中，我们已经为流失数据集构建了一个复杂的决策树。然而，有时我们不得不删除在分类实例<a id="id459" class="calibre1"/>中不强大的部分，以避免过度拟合，并提高预测精度。因此，在该方法中，我们引入了成本复杂度修剪方法来修剪分类树。</p></div></body></html>


<html>
  <head>
    <title>Pruning a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1">准备就绪</h2></div></div></div><p class="calibre7">您需要通过生成一个分类模型来完成前面的配方，并将该模型分配到<code class="email">churn.rp</code>变量中。</p></div></div></body></html>


<html>
  <head>
    <title>Pruning a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec194" class="calibre1"/>怎么做...</h2></div></div></div><p class="calibre7">执行以下步骤来修剪分类树:</p><div><ol class="orderedlist"><li class="listitem" value="1">求分类树模型的最小交叉验证误差:<div> <pre class="programlisting"> <strong class="calibre2">&gt; min(churn.rp$cptable[,"xerror"])</strong> <strong class="calibre2">[1] 0.4707602</strong> </pre> </div></li><li class="listitem" value="2">定位交叉验证误差最小的记录:<div> <pre class="programlisting"> <strong class="calibre2">&gt; which.min(churn.rp$cptable[,"xerror"])</strong> <strong class="calibre2">7 </strong> </pre> </div></li><li class="listitem" value="3">得到交叉验证误差最小的记录的成本复杂度参数:<div> <pre class="programlisting"> <strong class="calibre2">&gt; churn.cp = churn.rp$cptable[7,"CP"]</strong> <strong class="calibre2">&gt; churn.cp</strong> <strong class="calibre2">[1] 0.01754386</strong> </pre> </div></li><li class="listitem" value="4">通过将<code class="email">cp</code>参数设置为交叉验证误差最小的记录的 CP 值来修剪树:<div> <pre class="programlisting"> <strong class="calibre2">&gt; prune.tree = prune(churn.rp, cp= churn.cp)</strong> </pre> </div></li><li class="listitem" value="5">Visualize <a id="id460" class="calibre1"/>the classification tree by using the <code class="email">plot</code> and <code class="email">text</code> function:<div><pre class="programlisting">
<strong class="calibre2">&gt; plot(prune.tree, margin= 0.1)</strong>
<strong class="calibre2">&gt; text(prune.tree, all=TRUE , use.n=TRUE)</strong>
</pre></div><div><img src="img/00105.jpeg" alt="How to do it..." class="calibre9"/><div><p class="calibre12">图 5:修剪后的分类树</p></div></div><p class="calibre13"> </p></li><li class="listitem" value="6">接下来，您可以基于修剪后的分类树模型生成分类表:<div> <pre class="programlisting"> <strong class="calibre2">&gt; predictions = predict(prune.tree, testset, type="class")</strong> <strong class="calibre2">&gt; table(testset$churn, predictions)</strong> <strong class="calibre2">     predictions</strong> <strong class="calibre2">      yes  no</strong> <strong class="calibre2">  yes  95  46</strong> <strong class="calibre2">  no   14 863</strong> </pre> </div></li><li class="listitem" value="7">最后，您可以根据分类表生成混淆矩阵:<div> <pre class="programlisting"> <strong class="calibre2">&gt; confusionMatrix(table(predictions, testset$churn))</strong> <strong class="calibre2">Confusion Matrix and Statistics</strong>  <strong class="calibre2">   </strong> <strong class="calibre2">        </strong> <strong class="calibre2">predictions yes  no</strong> <strong class="calibre2">        yes  95  14</strong> <strong class="calibre2">        no   46 863</strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">               Accuracy : 0.9411          </strong> <strong class="calibre2">                 95% CI : (0.9248, 0.9547)</strong> <strong class="calibre2">    No Information Rate : 0.8615          </strong> <strong class="calibre2">    P-Value [Acc &gt; NIR] : 2.786e-16       </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">                  Kappa : 0.727           </strong> <strong class="calibre2"> Mcnemar's Test P-Value : 6.279e-05       </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">            Sensitivity : 0.67376         </strong> <strong class="calibre2">            Specificity : 0.98404         </strong> <strong class="calibre2">         Pos Pred Value : 0.87156         </strong> <strong class="calibre2">         Neg Pred Value : 0.94939         </strong> <strong class="calibre2">             Prevalence : 0.13851         </strong> <strong class="calibre2">         Detection Rate : 0.09332         </strong> <strong class="calibre2">   Detection Prevalence : 0.10707         </strong> <strong class="calibre2">      Balanced Accuracy : 0.82890         </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">       'Positive' Class : yes             </strong> </pre> </div></li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Pruning a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><a id="ch05lvl2sec195" class="calibre1"/>工作原理...</h2></div></div></div><p class="calibre7">在这个<a id="id461" class="calibre1"/>配方中，我们讨论了修剪分类树以避免过度拟合并产生更健壮的分类模型。我们首先在<code class="email">cptable</code>中找到交叉验证错误最少的记录，然后提取记录的 CP 并将值赋给<code class="email">churn.cp</code>。接下来，我们使用<code class="email">prune</code>函数以<code class="email">churn.cp</code>为参数修剪分类树。然后，通过使用<code class="email">plot</code>函数，我们图形化地显示了修剪后的分类树。从<em class="calibre8">图 5 </em>可以明显看出，该树的分裂小于原分类树(<em class="calibre8">图 3 </em>)。最后，我们制作了一个分类表，并使用混淆矩阵来验证剪枝树的性能。结果显示准确度(0.9411)略低于原始模型(0.942)，并且还表明修剪后的树可能不会比原始分类树表现得更好，因为我们已经修剪了一些分裂条件(仍然应该检查灵敏度和特异性的变化)。然而，修剪树模型更健壮，因为它去除了可能导致过拟合的一些分裂条件。</p></div></div></body></html>


<html>
  <head>
    <title>Pruning a recursive partitioning tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch05lvl2sec196" class="calibre1"/>参见</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">对于<a id="id462" class="calibre1"/>那些想了解更多<a id="id463" class="calibre1"/>关于成本复杂性修剪的人，请参考维基百科的文章<strong class="calibre2">修剪(决策树)</strong>:<a class="calibre1" href="http://en.wikipedia.org/wiki/Pruning_(decision_trees">http://en . Wikipedia . org/wiki/Pruning _(决策树</a></li></ul></div></div></div></body></html>


<html>
  <head>
    <title>Building a classification model with a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec60" class="calibre1"/>用条件推理树建立分类模型</h1></div></div></div><p class="calibre7">除了传统的决策树(<code class="email">rpart</code>)，条件推理树(<code class="email">ctree</code>)是另一种<a id="id464" class="calibre1"/>流行的基于树的<a id="id465" class="calibre1"/>分类方法。与传统的决策树类似，条件推理树也通过对因变量执行单变量分割来递归地划分数据。然而，条件推理树与传统决策树的不同之处在于，条件推理树采用显著性测试过程来选择变量，而不是通过最大化信息度量来选择变量(<code class="email">rpart</code>采用基尼系数)。在本菜谱中，我们将介绍如何采用条件推理树来构建分类模型。</p></div></body></html>


<html>
  <head>
    <title>Building a classification model with a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1">做好准备</h2></div></div></div><p class="calibre7">您需要通过生成训练数据集<code class="email">trainset</code>和测试数据集<code class="email">testset</code>来完成第一个配方。</p></div></div></body></html>


<html>
  <head>
    <title>Building a classification model with a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec198" class="calibre1"/>怎么做...</h2></div></div></div><p class="calibre7">执行以下步骤来构建条件推理树:</p><div><ol class="orderedlist"><li class="listitem" value="1">首先，我们使用<code class="email">party</code>包中的<code class="email">ctree</code>来构建分类模型:<div> <pre class="programlisting"> <strong class="calibre2">&gt; library(party)</strong> <strong class="calibre2">&gt; ctree.model = ctree(churn ~ . , data = trainset)</strong> </pre> </div></li><li class="listitem" value="2">然后，我们考察建树模型:<div> <pre class="programlisting"> <strong class="calibre2">&gt; ctree.model</strong> </pre> </div></li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Building a classification model with a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3">它是如何工作的...</h2></div></div></div><p class="calibre7">在这个菜谱中，我们使用了一个条件推理树来构建一个分类树。<code class="email">ctree</code>的用法与<code class="email">rpart</code>类似。因此，在面临分类问题时，您可以使用传统的决策树或条件推理树轻松测试分类能力。接下来，我们通过检查构建的模型来获得分类树的节点细节。在模型中，我们发现<code class="email">ctree</code>提供了类似于分割<a id="id467" class="calibre1"/>条件的信息<a id="id466" class="calibre1"/>、标准(1–p 值)、统计(测试统计)和权重(对应于节点的案例权重)。然而，它不像<code class="email">rpart</code>通过使用<code class="email">summary</code>函数提供那么多信息。</p></div></div></body></html>


<html>
  <head>
    <title>Building a classification model with a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch05lvl2sec200" class="calibre1"/>亦见</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">您可以<a id="id468" class="calibre1"/>使用<code class="email">help</code>函数来引用<strong class="calibre2">二叉树</strong> <strong class="calibre2">树</strong> <strong class="calibre2">类</strong>的定义，并阅读更多关于二叉树的属性:<div> <pre class="programlisting"> <strong class="calibre2"> &gt; help("BinaryTree-class")</strong> </pre> </div></li></ul></div></div></div></body></html>


<html>
  <head>
    <title>Visualizing a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><a id="ch05lvl1sec61" class="calibre1"/>可视化条件推理树</h1></div></div></div><p class="calibre7">与<code class="email">rpart</code>类似，<code class="email">party</code>包也为用户提供了绘制<a id="id469" class="calibre1"/>条件推理树的可视化方法。在下面的菜谱中，我们将介绍如何使用<code class="email">plot</code>函数来可视化条件推理树。</p></div></body></html>


<html>
  <head>
    <title>Visualizing a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1">正在准备中</h2></div></div></div><p class="calibre7">您需要通过生成条件推理树模型<code class="email">ctree.model</code>来完成第一个配方。除此之外，您还需要在一个 R 会话中加载<code class="email">trainset</code>和<code class="email">testset</code>。</p></div></div></body></html>


<html>
  <head>
    <title>Visualizing a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2"><a id="ch05lvl2sec202" class="calibre1"/>怎么做...</h2></div></div></div><p class="calibre7">执行以下步骤来可视化条件推理树:</p><div><ol class="orderedlist"><li class="listitem" value="1">Use the <code class="email">plot</code> function to plot <code class="email">ctree.model</code> built in the last recipe:<div><pre class="programlisting">
<strong class="calibre2">&gt; plot(ctree.model)</strong>
</pre></div><div><img src="img/00106.jpeg" alt="How to do it..." class="calibre9"/><div><p class="calibre12">图 6:流失数据的条件推理树</p></div></div><p class="calibre13">图 7:使用 total_day_charge 变量作为唯一分割条件的条件推理树</p></li><li class="listitem" value="2">To obtain<a id="id470" class="calibre1"/> a simple conditional inference tree, one can reduce the built model with less input features, and redraw the classification tree:<div><pre class="programlisting">
<strong class="calibre2">&gt; daycharge.model = ctree(churn ~ total_day_charge, data = trainset)</strong>
<strong class="calibre2">&gt; plot(daycharge.model)</strong>
</pre></div><div><img src="img/00107.jpeg" alt="How to do it..." class="calibre9"/><div><p class="calibre12">Figure 7: A conditional inference tree using the total_day_charge variable as only split condition</p></div></div><p class="calibre13"><a id="ch05lvl2sec203" class="calibre1"/>工作原理...</p></li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Visualizing a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3">为了<a id="id471" class="calibre1"/>可视化条件推理树的节点细节，我们可以在构建的分类模型上应用<code class="email">plot</code>函数。输出图显示，每个中间节点都显示了因变量名称和 p 值。拆分条件显示在左右分支上。终端节点显示分类观察值的数量，<em class="calibre8"> n </em>，以及分类标签为 0 或 1 的概率。</h2></div></div></div><p class="calibre7">以<em class="calibre8">图 7 </em>为例，我们首先建立一个以<code class="email">total_day_charge</code>为唯一特征，以<code class="email">churn</code>为类别标签的分类模型。构建的分类树显示，当<code class="email">total_day_charge</code>高于 48.18 时，节点 9 中较浅的灰色区域大于较深的灰色区域，这表明日费超过 48.18 的客户流失的可能性较大(label = yes)。</p><p class="calibre7"><a id="ch05lvl2sec204" class="calibre1"/>参见</p></div></div></body></html>


<html>
  <head>
    <title>Visualizing a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4">条件推理树的可视化来自于<code class="email">plot.BinaryTree</code>函数。如果您有兴趣调整分类树的布局，您可以使用<code class="email">help</code>功能阅读以下文档:<div> <pre class="programlisting"> <strong class="calibre2">&gt; ?plot.BinaryTree</strong> </pre> </div></h2></div></div></div><div><ul class="itemizedlist"><li class="listitem"><a id="ch05lvl1sec62" class="calibre1"/>测量条件推理树的预测性能</li></ul></div></div></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0">在建立条件推理树作为分类模型之后，我们可以使用<code class="email">treeresponse</code>和<code class="email">predict</code>函数来预测测试数据集<code class="email">testset</code>的类别，并使用分类表和混淆矩阵<a id="id472" class="calibre1"/>进一步验证预测能力。</h1></div></div></div><p class="calibre7">做好准备</p></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1">您需要通过生成条件推理树模型<code class="email">ctree.model</code>来完成前面的配方。除此之外，您需要在 R 会话中加载<code class="email">trainset</code>和<code class="email">testset</code>。</h2></div></div></div><p class="calibre7"><a id="ch05lvl2sec206" class="calibre1"/>怎么做...</p></div></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2">执行以下步骤来测量条件推理树的预测性能:</h2></div></div></div><p class="calibre7">您可以使用<code class="email">predict</code>函数来预测测试数据集的类别，<code class="email">testset</code> : <div> <pre class="programlisting"> <strong class="calibre2">&gt; ctree.predict = predict(ctree.model ,testset)</strong> <strong class="calibre2">&gt; table(ctree.predict, testset$churn)</strong> <strong class="calibre2">             </strong> <strong class="calibre2">ctree.predict yes  no</strong> <strong class="calibre2">          yes  99  15</strong> <strong class="calibre2">          no   42 862</strong> </pre> </div></p><div><ol class="orderedlist"><li class="listitem" value="1">此外，您可以使用 caret 包中的<code class="email">confusionMatrix</code>来生成预测结果的性能度量:<div> <pre class="programlisting"> <strong class="calibre2">&gt; confusionMatrix(table(ctree.predict, testset$churn))</strong> <strong class="calibre2">Confusion Matrix and Statistics</strong>  <strong class="calibre2">             </strong> <strong class="calibre2">ctree.predict yes  no</strong> <strong class="calibre2">          yes  99  15</strong> <strong class="calibre2">          no   42 862</strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">               Accuracy : 0.944           </strong> <strong class="calibre2">                 95% CI : (0.9281, 0.9573)</strong> <strong class="calibre2">    No Information Rate : 0.8615          </strong> <strong class="calibre2">    P-Value [Acc &gt; NIR] : &lt; 2.2e-16       </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">                  Kappa : 0.7449          </strong> <strong class="calibre2"> Mcnemar's Test P-Value : 0.0005736       </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">            Sensitivity : 0.70213         </strong> <strong class="calibre2">            Specificity : 0.98290         </strong> <strong class="calibre2">         Pos Pred Value : 0.86842         </strong> <strong class="calibre2">         Neg Pred Value : 0.95354         </strong> <strong class="calibre2">             Prevalence : 0.13851         </strong> <strong class="calibre2">         Detection Rate : 0.09725         </strong> <strong class="calibre2">   Detection Prevalence : 0.11198         </strong> <strong class="calibre2">      Balanced Accuracy : 0.84251         </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">       'Positive' Class : yes             </strong> </pre> </div></li><li class="listitem" value="2">你<a id="id473" class="calibre1"/>也可以使用<code class="email">treeresponse</code>函数，它会告诉你类概率列表:<div> <pre class="programlisting"> <strong class="calibre2">&gt; tr = treeresponse(ctree.model, newdata = testset[1:5,])</strong> <strong class="calibre2">&gt; tr</strong> <strong class="calibre2">[[1]]</strong> <strong class="calibre2">[1] 0.03497409 0.96502591</strong>  <strong class="calibre2">[[2]]</strong> <strong class="calibre2">[1] 0.02586207 0.97413793</strong>  <strong class="calibre2">[[3]]</strong> <strong class="calibre2">[1] 0.02586207 0.97413793</strong>  <strong class="calibre2">[[4]]</strong> <strong class="calibre2">[1] 0.02586207 0.97413793</strong>  <strong class="calibre2">[[5]]</strong> <strong class="calibre2">[1] 0.03497409 0.96502591</strong> </pre> </div></li><li class="listitem" value="3"><a id="ch05lvl2sec207" class="calibre1"/>工作原理...</li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3">在这个方法中，我们首先展示了可以使用<code class="email">prediction</code>函数来预测测试数据集<code class="email">testset</code>的<a id="id474" class="calibre1"/>类别(类标签)，然后使用<code class="email">table</code>函数来生成分类表。接下来，您可以使用 caret 包中内置的<code class="email">confusionMatrix</code>函数来确定性能度量。</h2></div></div></div><p class="calibre7">除了<code class="email">predict</code>功能之外，<code class="email">treeresponse</code>还能够估计分类概率，这通常会以较高的概率对标签进行分类。在这个例子中，我们演示了如何使用测试数据集<code class="email">testset</code>的前五个记录来获得估计的类概率。<code class="email">treeresponse</code>函数返回五种概率的列表。您可以使用列表来确定实例的标签。</p><p class="calibre7"><a id="ch05lvl2sec208" class="calibre1"/>亦见</p></div></div></body></html>


<html>
  <head>
    <title>Measuring the prediction performance of a conditional inference tree</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4">对于<code class="email">predict</code>功能，您可以将类型指定为<code class="email">response</code>、<code class="email">prob</code>或<code class="email">node</code>。如果在使用<code class="email">predict</code>函数时将类型指定为<code class="email">prob</code>(例如<code class="email">predict(… type="prob")</code>，将会得到与<code class="email">treeresponse</code>返回的结果完全相同的结果。</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem"><a id="ch05lvl1sec63" class="calibre1"/>用 k 近邻分类器对数据进行分类</li></ul></div></div></div></body></html>


<html>
  <head>
    <title>Classifying data with the k-nearest neighbor classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0"><strong class="calibre2"> K 近邻</strong> ( <strong class="calibre2"> knn </strong>)是一种<a id="id475" class="calibre1"/>非参数的懒惰学习方法。从非参数的角度来看，它没有对数据分布做任何假设<a id="id476" class="calibre1"/>。就懒惰学习而言，它不需要明确的学习阶段来进行概括。下面的食谱将介绍如何在客户流失数据集上应用 k-最近邻算法<a id="id477" class="calibre1"/>。</h1></div></div></div><p class="calibre7">做好准备</p></div></body></html>


<html>
  <head>
    <title>Classifying data with the k-nearest neighbor classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1">您需要通过生成训练和测试数据集来完成前面的配方。</h2></div></div></div><p class="calibre7"><a id="ch05lvl2sec210" class="calibre1"/>怎么做...</p></div></div></body></html>


<html>
  <head>
    <title>Classifying data with the k-nearest neighbor classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2">执行以下步骤，使用 k-最近邻算法对流失数据进行分类:</h2></div></div></div><p class="calibre7">首先，必须安装<code class="email">class</code>包并在 R 会话中加载它:<div> <pre class="programlisting"> <strong class="calibre2">&gt; install.packages("class")</strong> <strong class="calibre2">&gt; library(class)</strong> </pre> </div></p><div><ol class="orderedlist"><li class="listitem" value="1">将<a id="id479" class="calibre1"/>训练数据集和测试数据集中<code class="email">voice_mail_plan</code>和<code class="email">international_plan</code>属性<a id="id478" class="calibre1"/>的<code class="email">yes</code>和<code class="email">no</code>替换为 1 和 0: <div> <pre class="programlisting"> <strong class="calibre2">&gt; levels(trainset$international_plan) = list("0"="no", "1"="yes")</strong> <strong class="calibre2">&gt; levels(trainset$voice_mail_plan) = list("0"="no", "1"="yes")</strong> <strong class="calibre2">&gt; levels(testset$international_plan) = list("0"="no", "1"="yes")</strong> <strong class="calibre2">&gt; levels(testset$voice_mail_plan) = list("0"="no", "1"="yes")</strong> </pre> </div></li><li class="listitem" value="2">对训练数据集和测试数据集使用<code class="email">knn</code>分类方法:<div> <pre class="programlisting"> <strong class="calibre2">&gt; churn.knn  = knn(trainset[,! names(trainset) %in% c("churn")], testset[,! names(testset) %in% c("churn")], trainset$churn, k=3)</strong> </pre> </div></li><li class="listitem" value="3">然后，您可以使用<code class="email">summary</code>函数来检索预测标签的数量:<div> <pre class="programlisting"> <strong class="calibre2">&gt; summary(churn.knn)</strong> <strong class="calibre2">yes  no</strong> <strong class="calibre2"> 77 941</strong> </pre> </div></li><li class="listitem" value="4">接下来，您可以使用<code class="email">table</code>函数生成分类矩阵:<div> <pre class="programlisting"> <strong class="calibre2">&gt; table(testset$churn, churn.knn)</strong> <strong class="calibre2">     churn.knn</strong> <strong class="calibre2">      yes  no</strong> <strong class="calibre2">  yes  44  97</strong> <strong class="calibre2">  no   33 844</strong> </pre> </div></li><li class="listitem" value="5">最后，您可以使用<code class="email">confusionMatrix</code>函数生成混淆矩阵:<div> <pre class="programlisting"> <strong class="calibre2">&gt; confusionMatrix(table(testset$churn, churn.knn))</strong> <strong class="calibre2">Confusion Matrix and Statistics</strong>  <strong class="calibre2">     churn.knn</strong> <strong class="calibre2">      yes  no</strong> <strong class="calibre2">  yes  44  97</strong> <strong class="calibre2">  no   33 844</strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">               Accuracy : 0.8723          </strong> <strong class="calibre2">                 95% CI : (0.8502, 0.8922)</strong> <strong class="calibre2">    No Information Rate : 0.9244          </strong> <strong class="calibre2">    P-Value [Acc &gt; NIR] : 1               </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">                  Kappa : 0.339           </strong> <strong class="calibre2"> Mcnemar's Test P-Value : 3.286e-08       </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">            Sensitivity : 0.57143         </strong> <strong class="calibre2">            Specificity : 0.89692         </strong> <strong class="calibre2">         Pos Pred Value : 0.31206         </strong> <strong class="calibre2">         Neg Pred Value : 0.96237         </strong> <strong class="calibre2">             Prevalence : 0.07564         </strong> <strong class="calibre2">         Detection Rate : 0.04322         </strong> <strong class="calibre2">   Detection Prevalence : 0.13851         </strong> <strong class="calibre2">      Balanced Accuracy : 0.73417         </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">       'Positive' Class : yes   </strong> </pre> </div></li><li class="listitem" value="6"><a id="ch05lvl2sec211" class="calibre1"/>工作原理...</li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Classifying data with the k-nearest neighbor classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3"><strong class="calibre2"> knn </strong>训练<a id="id480" class="calibre1"/>所有样本，并基于<a id="id482" class="calibre1"/>相似性(距离)度量对<a id="id481" class="calibre1"/>新实例进行分类。例如，相似性度量可以用公式表示如下:</h2></div></div></div><p class="calibre7"><strong class="calibre2">欧几里德距离</strong> : <img src="img/00108.jpeg" alt="How it works..." class="calibre24"/></p><div><ul class="itemizedlist"><li class="listitem"><strong class="calibre2">曼哈顿距离</strong> : <img src="img/00109.jpeg" alt="How it works..." class="calibre24"/></li><li class="listitem">在 knn 中，一个新的实例被分类到一个标签(类),该标签在 k 个最近的邻居中是公共的。如果<em class="calibre8"> k = 1 </em>，那么新的实例被分配给它最近的邻居所属的类。算法唯一需要的输入是 k，如果我们给一个小的 k 输入，可能会导致过拟合。另一方面，如果我们给定一个大的 k 输入，可能会导致欠拟合。为了选择合适的 k 值，可以依靠交叉验证。</li></ul></div><p class="calibre7">knn 的优势<a id="id483" class="calibre1"/>是:</p><p class="calibre7">学习过程的 T4 成本是零</p><div><ul class="itemizedlist"><li class="listitem">它是非参数的，这意味着你不必假设数据分布</li><li class="listitem">只要能找到给定实例的相似性度量，就可以对任何数据进行分类</li><li class="listitem">knn 的主要<a id="id486" class="calibre1"/>缺点是:</li></ul></div><p class="calibre7">分类结果很难解释。</p><div><ul class="itemizedlist"><li class="listitem">对于大型数据集来说，这是一种昂贵的计算。</li><li class="listitem">性能依赖于维数。因此，对于高维问题，您应该首先降低维度以提高流程性能。</li><li class="listitem">knn 的使用与前面提到的基于树的算法没有太大的不同。然而，虽然基于树的算法可以向您展示决策树模型，但是 knn 产生的输出仅揭示分类类别因素。但是，在构建分类模型之前，应该将字符串类型的属性替换为整数，因为 k-最近邻算法需要计算观察值之间的距离。然后，我们通过指定<em class="calibre8"> k=3 </em>来建立分类模型，这意味着选择三个最近的邻居。建立分类模型后，我们可以使用预测因子和测试数据集标签作为输入来生成分类表。最后，我们可以从分类表中生成一个混淆矩阵。混淆矩阵输出揭示了(0.8723)的准确度结果，这表明在先前配方中提到的两种基于树的方法在这种情况下都优于 k-最近邻分类方法的准确度。然而，我们不能仅仅依靠准确性来确定哪个模型更好，我们还应该检查输出的特异性和敏感性。</li></ul></div><p class="calibre7"><a id="ch05lvl2sec212" class="calibre1"/>亦见</p></div></div></body></html>


<html>
  <head>
    <title>Classifying data with the k-nearest neighbor classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4">还有一个名为<code class="email">kknn</code>的包，它提供了一个加权的 k 近邻分类、回归和聚类。你可以通过阅读这个文档来了解更多关于<a id="id487" class="calibre1"/>包的信息:<a class="calibre1" href="http://cran.r-project.org/web/packages/kknn/kknn.pdf">http://cran.r-project.org/web/packages/kknn/kknn.pdf</a>。</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem"><a id="ch05lvl1sec64" class="calibre1"/>用逻辑回归对数据进行分类</li></ul></div></div></div></body></html>


<html>
  <head>
    <title>Classifying data with logistic regression</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0">逻辑回归是概率统计分类模型的一种形式，可用于<a id="id488" class="calibre1"/>基于一个或<a id="id489" class="calibre1"/>多个特征预测类别标签。通过使用<code class="email">logit</code>函数估计结果概率来完成分类。在使用<code class="email">glm</code>函数时，可以通过将家庭指定为二项式来使用逻辑回归。在本食谱中，我们将介绍如何使用逻辑回归对数据进行分类。</h1></div></div></div><p class="calibre7"><a id="ch05lvl2sec213" class="calibre1"/>准备就绪</p></div></body></html>


<html>
  <head>
    <title>Classifying data with logistic regression</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1">您需要通过生成训练和测试数据集来完成第一个配方。</h2></div></div></div><p class="calibre7"><a id="ch05lvl2sec214" class="calibre1"/>怎么做...</p></div></div></body></html>


<html>
  <head>
    <title>Classifying data with logistic regression</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2">执行以下步骤，使用逻辑回归对流失数据进行分类:</h2></div></div></div><p class="calibre7">通过将家庭指定为二项式，我们对数据集<code class="email">trainset</code>应用<code class="email">glm</code>函数，使用 churn 作为类别标签，其余变量作为输入特征:<div> <pre class="programlisting"> <strong class="calibre2">&gt; fit = glm(churn ~ ., data = trainset, family=binomial)</strong> </pre> </div></p><div><ol class="orderedlist"><li class="listitem" value="1">使用<code class="email">summary</code>函数获取已建 logistic 回归模型的汇总信息:<div> <pre class="programlisting"> <strong class="calibre2">&gt; summary(fit)</strong>  <strong class="calibre2">Call:</strong> <strong class="calibre2">glm(formula = churn ~ ., family = binomial, data = trainset)</strong>  <strong class="calibre2">Deviance Residuals: </strong> <strong class="calibre2">    Min       1Q   Median       3Q      Max  </strong> <strong class="calibre2">-3.1519   0.1983   0.3460   0.5186   2.1284  </strong>  <strong class="calibre2">Coefficients:</strong> <strong class="calibre2">                                Estimate Std. Error z value Pr(&gt;|z|)</strong> <strong class="calibre2">(Intercept)                    8.3462866  0.8364914   9.978  &lt; 2e-16</strong> <strong class="calibre2">international_planyes         -2.0534243  0.1726694 -11.892  &lt; 2e-16</strong> <strong class="calibre2">voice_mail_planyes             1.3445887  0.6618905   2.031 0.042211</strong> <strong class="calibre2">number_vmail_messages         -0.0155101  0.0209220  -0.741 0.458496</strong> <strong class="calibre2">total_day_minutes              0.2398946  3.9168466   0.061 0.951163</strong> <strong class="calibre2">total_day_calls               -0.0014003  0.0032769  -0.427 0.669141</strong> <strong class="calibre2">total_day_charge              -1.4855284 23.0402950  -0.064 0.948592</strong> <strong class="calibre2">total_eve_minutes              0.3600678  1.9349825   0.186 0.852379</strong> <strong class="calibre2">total_eve_calls               -0.0028484  0.0033061  -0.862 0.388928</strong> <strong class="calibre2">total_eve_charge              -4.3204432 22.7644698  -0.190 0.849475</strong> <strong class="calibre2">total_night_minutes            0.4431210  1.0478105   0.423 0.672367</strong> <strong class="calibre2">total_night_calls              0.0003978  0.0033188   0.120 0.904588</strong> <strong class="calibre2">total_night_charge            -9.9162795 23.2836376  -0.426 0.670188</strong> <strong class="calibre2">total_intl_minutes             0.4587114  6.3524560   0.072 0.942435</strong> <strong class="calibre2">total_intl_calls               0.1065264  0.0304318   3.500 0.000464</strong> <strong class="calibre2">total_intl_charge             -2.0803428 23.5262100  -0.088 0.929538</strong> <strong class="calibre2">number_customer_service_calls -0.5109077  0.0476289 -10.727  &lt; 2e-16</strong> <strong class="calibre2">                                 </strong> <strong class="calibre2">(Intercept)                   ***</strong> <strong class="calibre2">international_planyes         ***</strong> <strong class="calibre2">voice_mail_planyes            *  </strong> <strong class="calibre2">number_vmail_messages            </strong> <strong class="calibre2">total_day_minutes                </strong> <strong class="calibre2">total_day_calls                  </strong> <strong class="calibre2">total_day_charge                 </strong> <strong class="calibre2">total_eve_minutes                </strong> <strong class="calibre2">total_eve_calls                  </strong> <strong class="calibre2">total_eve_charge                 </strong> <strong class="calibre2">total_night_minutes              </strong> <strong class="calibre2">total_night_calls                </strong> <strong class="calibre2">total_night_charge               </strong> <strong class="calibre2">total_intl_minutes               </strong> <strong class="calibre2">total_intl_calls              ***</strong> <strong class="calibre2">total_intl_charge                </strong> <strong class="calibre2">number_customer_service_calls ***</strong> <strong class="calibre2">---</strong> <strong class="calibre2">Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1</strong>  <strong class="calibre2">(Dispersion parameter for binomial family taken to be 1)</strong>  <strong class="calibre2">    Null deviance: 1938.8  on 2314  degrees of freedom</strong> <strong class="calibre2">Residual deviance: 1515.3  on 2298  degrees of freedom</strong> <strong class="calibre2">AIC: 1549.3</strong>  <strong class="calibre2">Number of Fisher Scoring iterations: 6</strong> </pre> </div></li><li class="listitem" value="2">然后，我们<a id="id490" class="calibre1"/>发现建立的模型<a id="id491" class="calibre1"/>包含无关紧要的变量，这将导致错误分类。因此，我们只使用显著变量来训练分类模型:<div> <pre class="programlisting"> <strong class="calibre2">&gt; fit = glm(churn ~ international_plan + voice_mail_plan+total_intl_calls+number_customer_service_calls, data = trainset, family=binomial)</strong> <strong class="calibre2">&gt; summary(fit)</strong>  <strong class="calibre2">Call:</strong> <strong class="calibre2">glm(formula = churn ~ international_plan + voice_mail_plan + </strong> <strong class="calibre2">    total_intl_calls + number_customer_service_calls, family = binomial, </strong> <strong class="calibre2">    data = trainset)</strong>  <strong class="calibre2">Deviance Residuals: </strong> <strong class="calibre2">    Min       1Q   Median       3Q      Max  </strong> <strong class="calibre2">-2.7308   0.3103   0.4196   0.5381   1.6716  </strong>  <strong class="calibre2">Coefficients:</strong> <strong class="calibre2">                              Estimate Std. Error z value</strong> <strong class="calibre2">(Intercept)                    2.32304    0.16770  13.852</strong> <strong class="calibre2">international_planyes         -2.00346    0.16096 -12.447</strong> <strong class="calibre2">voice_mail_planyes             0.79228    0.16380   4.837</strong> <strong class="calibre2">total_intl_calls               0.08414    0.02862   2.939</strong> <strong class="calibre2">number_customer_service_calls -0.44227    0.04451  -9.937</strong> <strong class="calibre2">                              Pr(&gt;|z|)    </strong> <strong class="calibre2">(Intercept)                    &lt; 2e-16 ***</strong> <strong class="calibre2">international_planyes          &lt; 2e-16 ***</strong> <strong class="calibre2">voice_mail_planyes            1.32e-06 ***</strong> <strong class="calibre2">total_intl_calls               0.00329 ** </strong> <strong class="calibre2">number_customer_service_calls  &lt; 2e-16 ***</strong> <strong class="calibre2">---</strong> <strong class="calibre2">Signif. codes:  </strong> <strong class="calibre2">0  es:    des:  **rvice_calls  &lt; '.  es:    de</strong>  <strong class="calibre2">(Dispersion parameter for binomial family taken to be 1)</strong>  <strong class="calibre2">    Null deviance: 1938.8  on 2314  degrees of freedom</strong> <strong class="calibre2">Residual deviance: 1669.4  on 2310  degrees of freedom</strong> <strong class="calibre2">AIC: 1679.4</strong>  <strong class="calibre2">Number of Fisher Scoring iterations: 5</strong> </pre> </div></li><li class="listitem" value="3">然后，你<a id="id492" class="calibre1"/>可以使用一个合适的<a id="id493" class="calibre1"/>模型<code class="email">fit</code>，来预测<code class="email">testset</code>的结果。也可以通过判断概率是否在 0.5 以上来确定阶层:<div> <pre class="programlisting"> <strong class="calibre2">&gt; pred = predict(fit,testset, type="response")</strong> <strong class="calibre2">&gt; Class = pred &gt;.5</strong> </pre> </div></li><li class="listitem" value="4">接下来，使用<code class="email">summary</code>函数将显示二进制结果计数，并显示概率是否高于 0.5: <div> <pre class="programlisting"> <strong class="calibre2">&gt; summary(Class)</strong> <strong class="calibre2">   Mode   FALSE    TRUE    NA's </strong> <strong class="calibre2">logical      29     989       0 </strong> </pre> </div></li><li class="listitem" value="5">您<a id="id494" class="calibre1"/>可以根据测试数据集标签和预测结果生成计数<a id="id495" class="calibre1"/>统计:<div> <pre class="programlisting"> <strong class="calibre2">&gt; tb = table(testset$churn,Class)</strong> <strong class="calibre2">&gt; tb      Class</strong> <strong class="calibre2">      FALSE TRUE</strong> <strong class="calibre2">  yes    18  123</strong> <strong class="calibre2">  no     11  866</strong> </pre> </div></li><li class="listitem" value="6">可以把上一步的统计变成分类表，然后生成混淆矩阵:<div> <pre class="programlisting"> <strong class="calibre2">&gt; churn.mod = ifelse(testset$churn == "yes", 1, 0)</strong> <strong class="calibre2">&gt; pred_class = churn.mod</strong> <strong class="calibre2">&gt; pred_class[pred&lt;=.5] = 1- pred_class[pred&lt;=.5]</strong> <strong class="calibre2">&gt; ctb = table(churn.mod, pred_class)</strong> <strong class="calibre2">&gt; ctb</strong> <strong class="calibre2">         pred_class</strong> <strong class="calibre2">churn.mod   0   1</strong> <strong class="calibre2">        0 866  11</strong> <strong class="calibre2">        1  18 123</strong> <strong class="calibre2">&gt; confusionMatrix(ctb)</strong> <strong class="calibre2">Confusion Matrix and Statistics</strong>  <strong class="calibre2">         pred_class</strong> <strong class="calibre2">churn.mod   0   1</strong> <strong class="calibre2">        0 866  11</strong> <strong class="calibre2">        1  18 123</strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">               Accuracy : 0.9715          </strong> <strong class="calibre2">                 95% CI : (0.9593, 0.9808)</strong> <strong class="calibre2">    No Information Rate : 0.8684          </strong> <strong class="calibre2">    P-Value [Acc &gt; NIR] : &lt;2e-16          </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">                  Kappa : 0.8781          </strong> <strong class="calibre2"> Mcnemar's Test P-Value : 0.2652          </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">            Sensitivity : 0.9796          </strong> <strong class="calibre2">            Specificity : 0.9179          </strong> <strong class="calibre2">         Pos Pred Value : 0.9875          </strong> <strong class="calibre2">         Neg Pred Value : 0.8723          </strong> <strong class="calibre2">             Prevalence : 0.8684          </strong> <strong class="calibre2">         Detection Rate : 0.8507          </strong> <strong class="calibre2">   Detection Prevalence : 0.8615          </strong> <strong class="calibre2">      Balanced Accuracy : 0.9488          </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">       'Positive' Class : 0  </strong> </pre> </div></li><li class="listitem" value="7"><a id="ch05lvl2sec215" class="calibre1"/>工作原理...</li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Classifying data with logistic regression</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3">逻辑回归与线性回归非常相似；主要区别在于，线性回归<a id="id497" class="calibre1"/>中的因变量<a id="id496" class="calibre1"/>是连续的，而逻辑回归中的因变量是二分的(或名义的)。逻辑回归的主要目标是使用 logit 得出与测量变量相关的名义变量的概率。我们可以用下面的等式来表示 logit:ln(P/(1-P))，其中 P 是某个事件发生的概率。</h2></div></div></div><p class="calibre7">逻辑回归的优点是易于解释，它指导模型逻辑概率，并为结果提供一个置信区间。与难以更新模型的决策树不同，您可以快速更新分类模型，以便在逻辑回归中合并新数据。该算法的主要缺点是存在多重共线性，因此解释变量必须是线性无关的。<code class="email">glm</code>提供广义线性回归模型，允许在选项族中指定模型。如果该系列被指定为二项式逻辑，则可以将该系列设置为二项式，以对类别的因变量进行分类。</p><p class="calibre7">分类过程从使用训练数据集生成逻辑回归模型开始，通过将<code class="email">Churn</code>指定为类标签，将其他变量指定为训练特征，并将族集指定为二项式。然后我们使用<code class="email">summary</code>函数来生成模型的概要信息。从汇总信息中，我们可能会发现一些无关紧要的变量(p 值&gt; 0.05)，这可能会导致错误分类。因此，我们应该只考虑模型的重要变量。</p><p class="calibre7">接下来，我们使用<code class="email">fit</code>函数来预测测试数据集的分类因变量<code class="email">testset</code>。<code class="email">fit</code>函数输出一个类标签的概率，结果等于 0.5 及以下，提示预测标签与测试<a id="id498" class="calibre1"/>数据集的标签不匹配，高于 0.5 的概率表示预测标签与测试数据集的标签匹配。此外，我们<a id="id499" class="calibre1"/>可以使用<code class="email">summary</code>函数来获得预测标签是否与测试数据集的标签相匹配的统计数据。最后，为了生成混淆矩阵，我们首先生成一个分类表，然后使用<code class="email">confusionMatrix</code>生成性能度量。</p><p class="calibre7"><a id="ch05lvl2sec216" class="calibre1"/>参见</p></div></div></body></html>


<html>
  <head>
    <title>Classifying data with logistic regression</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4">有关如何使用<code class="email">glm</code>函数的更多信息，请参考<a class="calibre1" title="Chapter 4. Understanding Regression Analysis" href="part0046_split_000.html#page">第 4 章</a>、<em class="calibre8">了解回归分析</em>，其中涵盖了如何解释<code class="email">glm</code>函数的输出</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem"><a id="ch05lvl1sec65" class="calibre1"/>使用朴素贝叶斯分类器对数据进行分类</li></ul></div></div></div></body></html>


<html>
  <head>
    <title>Classifying data with the Naïve Bayes classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div/><div><div><div><div><h1 class="title" id="calibre_pb_0">朴素贝叶斯分类器也是一种基于概率的分类器，它基于应用具有强<a id="id501" class="calibre1"/>独立假设的<a id="id500" class="calibre1"/>贝叶斯定理。在本菜谱中，我们将介绍如何使用朴素贝叶斯分类器对数据进行分类。</h1></div></div></div><p class="calibre7">准备就绪</p></div></body></html>


<html>
  <head>
    <title>Classifying data with the Naïve Bayes classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_1">您需要通过生成训练和测试数据集来完成第一个配方。</h2></div></div></div><p class="calibre7"><a id="ch05lvl2sec218" class="calibre1"/>怎么做...</p></div></div></body></html>


<html>
  <head>
    <title>Classifying data with the Naïve Bayes classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_2">执行以下步骤，使用朴素贝叶斯分类器对流失数据进行分类:</h2></div></div></div><p class="calibre7">加载<code class="email">e1071</code>库，使用<code class="email">naiveBayes</code>函数构建分类器:<div> <pre class="programlisting"> <strong class="calibre2">&gt; library(e1071) </strong> <strong class="calibre2">&gt; classifier=naiveBayes(trainset[, !names(trainset) %in% c("churn")], trainset$churn)</strong> </pre> </div></p><div><ol class="orderedlist"><li class="listitem" value="1">键入<code class="email">classifier</code>检查函数调用、先验概率和条件概率:<div> <pre class="programlisting"> <strong class="calibre2">&gt; classifier</strong>  <strong class="calibre2">Naive Bayes Classifier for Discrete Predictors</strong>  <strong class="calibre2">Call:</strong> <strong class="calibre2">naiveBayes.default(x = trainset[, !names(trainset) %in% c("churn")], </strong> <strong class="calibre2">    y = trainset$churn)</strong>  <strong class="calibre2">A-priori probabilities:</strong> <strong class="calibre2">trainset$churn</strong> <strong class="calibre2">      yes        no </strong> <strong class="calibre2">0.1477322 0.8522678 </strong>  <strong class="calibre2">Conditional probabilities:</strong> <strong class="calibre2">              international_plan</strong> <strong class="calibre2">trainset$churn         no        yes</strong> <strong class="calibre2">           yes 0.70467836 0.29532164</strong> <strong class="calibre2">           no  0.93512418 0.06487582</strong> </pre> </div></li><li class="listitem" value="2">接下来，您<a id="id502" class="calibre1"/>可以为测试数据集生成一个<a id="id503" class="calibre1"/>分类表:<div> <pre class="programlisting"> <strong class="calibre2">&gt; bayes.table = table(predict(classifier, testset[, !names(testset) %in% c("churn")]), testset$churn)</strong> <strong class="calibre2">&gt; bayes.table</strong> <strong class="calibre2">     </strong> <strong class="calibre2">      yes  no</strong> <strong class="calibre2">  yes  68  45</strong> <strong class="calibre2">  no   73 832</strong> </pre> </div></li><li class="listitem" value="3">最后，你可以从分类表中生成一个混淆矩阵:<div> <pre class="programlisting"> <strong class="calibre2">&gt; confusionMatrix(bayes.table)</strong> <strong class="calibre2">Confusion Matrix and Statistics</strong>  <strong class="calibre2">     </strong> <strong class="calibre2">      yes  no</strong> <strong class="calibre2">  yes  68  45</strong> <strong class="calibre2">  no   73 832</strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">               Accuracy : 0.8841          </strong> <strong class="calibre2">                 95% CI : (0.8628, 0.9031)</strong> <strong class="calibre2">    No Information Rate : 0.8615          </strong> <strong class="calibre2">    P-Value [Acc &gt; NIR] : 0.01880         </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">                  Kappa : 0.4701          </strong> <strong class="calibre2"> Mcnemar's Test P-Value : 0.01294         </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">            Sensitivity : 0.4823          </strong> <strong class="calibre2">            Specificity : 0.9487          </strong> <strong class="calibre2">         Pos Pred Value : 0.6018          </strong> <strong class="calibre2">         Neg Pred Value : 0.9193          </strong> <strong class="calibre2">             Prevalence : 0.1385          </strong> <strong class="calibre2">         Detection Rate : 0.0668          </strong> <strong class="calibre2">   Detection Prevalence : 0.1110          </strong> <strong class="calibre2">      Balanced Accuracy : 0.7155          </strong> <strong class="calibre2">                                          </strong> <strong class="calibre2">       'Positive' Class : yes    </strong> </pre> </div></li><li class="listitem" value="4"><a id="ch05lvl2sec219" class="calibre1"/>工作原理...</li></ol><div/></div></div></div></body></html>


<html>
  <head>
    <title>Classifying data with the Naïve Bayes classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_3">朴素贝叶斯<a id="id504" class="calibre1"/>假设特征是<a id="id505" class="calibre1"/>条件独立的，即预测因子(x)对类(c)的影响独立于其他预测因子对类(c)的影响。它计算后验概率<em class="calibre8"> P(c|x) </em>，如下公式:</h2></div></div></div><p class="calibre7">其中<em class="calibre8"> P(x|c) </em>称为似然，<em class="calibre8"> p(x) </em>称为边际似然，<em class="calibre8"> p(c) </em>称为先验概率。如果有许多预测值，我们可以用公式表示后验概率如下:</p><div><img src="img/00110.jpeg" alt="How it works..." class="calibre9"/></div><p class="calibre10"> </p><p class="calibre7">朴素贝叶斯的优点是使用起来相对简单明了。当训练集相对较小，并且可能包含一些噪声和丢失的数据时，它是合适的。此外，你可以很容易地获得预测的概率。朴素贝叶斯的缺点是，它假设所有的特征都是独立的、同等重要的，这在现实世界中是不太可能的。</p><div><img src="img/00111.jpeg" alt="How it works..." class="calibre9"/></div><p class="calibre10">在这个<a id="id506" class="calibre1"/>配方中，我们使用<code class="email">e1071</code>包中的朴素贝叶斯<a id="id507" class="calibre1"/>分类器来构建分类模型。首先，我们将所有变量(不包括<code class="email">churn</code>类标签)指定为第一个输入参数，并将<code class="email">churn</code>类标签指定为<code class="email">naiveBayes</code>函数调用中的第二个参数。接下来，我们将分类模型分配到变量分类器中。然后，我们打印变量分类器来获取信息，比如函数调用、先验概率和条件概率。我们还可以使用<code class="email">predict</code>函数获得预测结果，使用<code class="email">table</code>函数检索测试数据集的分类表。最后，我们使用混淆矩阵来计算分类模型的性能度量。</p><p class="calibre7">最后，我们在本章中列出了所有提到的算法的对照表:</p><p class="calibre7">算法</p><p class="calibre7">优势</p><div><table border="1" class="calibre15"><colgroup class="calibre16"><col class="calibre17"/><col class="calibre17"/><col class="calibre17"/></colgroup><thead class="calibre18"><tr class="calibre19"><th valign="bottom" class="calibre20">
<p class="calibre21">不足之处</p>
</th><th valign="bottom" class="calibre20">
<p class="calibre21">递归划分树</p>
</th><th valign="bottom" class="calibre20">
<p class="calibre21"><div> <ul class="itemizedlist2"> <li class="listitem1">非常<a id="id508" class="indexterm"/>灵活且易于解读</li> <li class="listitem1">对分类和回归问题都有效</li> <li class="listitem1">非参数</li> </ul> </div></p>
</th></tr></thead><tbody class="calibre22"><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">非常灵活且易于解释</p>
</td><td valign="top" class="calibre23">处理分类和回归问题</td><td valign="top" class="calibre23">条件推理树</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">非常灵活，易于解释</p>
</td><td valign="top" class="calibre23">分类和回归问题的作品<a id="id510" class="indexterm"/></td><td valign="top" class="calibre23">k 最近邻分类器</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">学习过程的成本是零</p>
</td><td valign="top" class="calibre23">非参数的</td><td valign="top" class="calibre23">对于大型数据集，计算成本很高</td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">容易理解</p>
</td><td valign="top" class="calibre23">提供<a id="id514" class="indexterm"/>模型逻辑概率</td><td valign="top" class="calibre23">不处理连续变量的缺失值<a id="id515" class="indexterm"/></td></tr><tr class="calibre19"><td valign="top" class="calibre23">
<p class="calibre21">使用起来相对简单明了</p>
</td><td valign="top" class="calibre23">当训练集相对较小时适用<a id="id516" class="indexterm"/></td><td valign="top" class="calibre23">当训练集数量增加时容易产生偏差</td></tr></tbody></table></div></div></div></body></html>


<html>
  <head>
    <title>Classifying data with the Naïve Bayes classifier</title>
    <meta name="generator" content="DocBook XSL Stylesheets V1.75.2"/>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8"/>
  

</head>
  <body id="page" class="calibre">
<div><div><div><div><div><h2 class="title1" id="calibre_pb_4"><a id="ch05lvl2sec220" class="calibre1"/>See also</h2></div></div></div><div><ul class="itemizedlist"><li class="listitem">To <a id="id518" class="calibre1"/>learn more about the Bayes<a id="id519" class="calibre1"/> theorem, you can refer to the<a id="id520" class="calibre1"/> following Wikipedia article: <a class="calibre1" href="http://en.wikipedia.org/wiki/Bayes'_theorem">http://en.wikipedia.org/wiki/Bayes'_theorem</a></li></ul></div></div></div></body></html>
</body></html>