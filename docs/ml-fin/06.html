<html><head/><body><html><head><title>Chapter 6. Using Generative Models</title><meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>

<meta content="urn:uuid:ee7bbf81-ee0c-427b-9574-49bd7094315d" name="Adept.expected.resource"/></head><body id="page"><div><div><div><div><h1 class="title"><a id="ch06"/>第六章。使用生成模型</h1></div></div></div><p>创成式模型生成新数据。在某种程度上，它们与我们在前几章讨论的模型完全相反。当图像分类器接收高维输入(图像)并输出低维输出(例如图像内容)时，生成模型以完全相反的方式处理事情。例如，它可以根据图片中内容的描述来绘制图片。</p><p>生成模型仍处于开发的实验阶段，目前主要用于图像应用。然而，它们是一个重要的模型，事实表明，已经有几个应用程序使用了生成模型，这在行业内引起了轩然大波。</p><p>2017年，所谓的<em> DeepFakes </em>开始在网络上出现。<strong>生成性对抗网络</strong> ( <strong> GANs </strong>)，我们<a class="indexterm" id="id443"/>将在本章稍后介绍，被用来生成以名人为主角的色情视频。前年，在2016年，研究人员展示了一个系统，他们可以生成政客们说研究人员希望他们说的任何话的视频，并配有逼真的嘴部动作和面部表情。这方面的一个例子可以从新闻网站BuzzFeed在2018年制作的美国前总统巴拉克·奥巴马的一篇虚假演讲中看出:<a class="ulink" href="https://youtu.be/cQ54GDm1eL0">https://youtu.be/cQ54GDm1eL0</a>。</p><p>这项技术并不完全是消极的，也有积极的应用，特别是如果生成模型的数据稀疏。如果是这种情况，生成模型可以生成真实的数据，然后其他模型可以对其进行训练。生成模型能够“翻译”图像，一个主要的例子是获取卫星图像并将它们转换成街道地图。再比如，生成式模型可以从网站截图生成代码。它们甚至可以用来对抗机器学习模型中的不公平和歧视，正如我们将在<a class="link" href="ch09.html" title="Chapter 9. Fighting Bias">第9章</a>、<em>对抗偏见</em>中看到的。</p><p>在金融领域，数据通常很少。回想一下<a class="link" href="ch02.html" title="Chapter 2. Applying Machine Learning to Structured Data">第2章</a>、<em>将机器学习应用于结构化数据、</em>中的欺诈案例，在该案例中，我们从交易元数据中对欺诈交易进行分类。我们发现在我们使用的数据集中没有太多欺诈发生，因此该模型很难检测出欺诈何时发生。通常，当这种情况发生时，工程师会做出假设并创建合成数据。然而，机器学习模型可以自己做到这一点，在这个过程中，它们甚至可能发现一些有助于欺诈检测的有用特征。</p><p>在算法交易中，数据经常在模拟器中产生。想知道你的算法在全球抛售中表现如何吗？幸运的是，全球抛售并不多，因此定量分析公司的工程师们花了大量时间创建抛售模拟。这些模拟器经常受到工程师的经验和他们对抛售应该是什么样子的感觉的影响。然而，如果模型可以了解抛售的基本情况，然后创建描述无限数量抛售的数据，会怎么样呢？</p><p>在这一章中，我们将关注两类生成模型:自动编码器和GANs。首先是一系列的<strong>自动编码器</strong>，目的是将数据压缩成一个低维的表示，然后忠实地重建数据。第二个家族是<strong> GANs </strong>，他们的目标是训练一个发生器，这样一个单独的鉴别器就不能分辨真假图像。</p><div><div><div><div><h1 class="title"><a id="ch06lvl1sec82"/>了解自动编码器</h1></div></div></div><p>从技术上来说，自动编码器<a class="indexterm" id="id444"/>不是生成型模型，因为它们不能创建全新类型的数据。然而，变分自动编码器，一个普通自动编码器的小调整，可以。因此，在添加生成元素之前，先理解自动编码器本身是有意义的。</p><p>自动编码器本身有一些有趣的属性，可以用于检测信用卡欺诈等应用，这对我们关注金融很有用。</p><p>给定输入<em> x </em>，自动编码器学习如何输出<em> x </em>。它的目标是找到一个函数，<em> f，</em>使得以下为真:</p><div><img alt="Understanding autoencoders" src="img/B10354_06_001.jpg"/></div><p>这可能听起来微不足道，但这里的技巧是自动编码器有一个瓶颈。中间隐藏层的大小小于输入的大小，<em> x </em>。因此，该模型必须学习一种压缩的表示，这种表示在一个更小的向量中捕获了<em> x </em>的所有重要元素。</p><p>下图最能说明这一点，其中我们可以看到自动编码器方案的压缩表示:</p><div><img alt="Understanding autoencoders" src="img/B10354_06_01.jpg"/><div><p>自动编码器方案</p></div></div><p>这种压缩的表示旨在捕捉输入的本质，这对我们很有用。例如，我们可能希望捕捉欺诈交易与真实交易的本质区别。普通的<a class="indexterm" id="id445"/>自动编码器通过类似于标准的<strong>主成分分析</strong> ( <strong> PCA </strong>)来完成这个任务。它们允许我们减少数据的维度，将<a class="indexterm" id="id446"/>的注意力集中在重要的事情上。但是与PCA相反，自动编码器可以被扩展以生成更多的某种类型的数据。例如，自动编码器可以更好地处理图像或视频数据，因为它们可以使用卷积层来利用数据的空间性。</p><p>在本节中，我们将构建两个自动编码器。第一个将用于MNIST数据集中的手写数字。生成模型对于视觉数据更容易调试和理解，因为人类直觉上擅长判断两幅图片是否显示相似的东西，但不太擅长判断抽象数据。第二个自动编码器用于欺诈检测任务，使用与MNIST数据集类似的方法。</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec77"/>MNIST自动编码器</h2></div></div></div><p>让我们从一个简单的手写数字MNIST数据集的自动编码器开始。MNIST图像为28x28像素，可以展平为784个元素的向量，等于28x28。我们将使用自动编码器将这个<a class="indexterm" id="id447"/>数据压缩成一个只有32个元素的向量。</p><p>在深入研究这里描述的代码之前，请确保您已经在正确的路径上保存了MNIST数据集，成功导入了NumPy和Matplotlib库，并设置了一个随机种子以确保您的实验是可重复的。</p><div><div><h3 class="title"><a id="note22"/>注意</h3><p><strong>注</strong>:您可以在以下网址<a class="ulink" href="https://www.kaggle.com/jannesklaas/mnist-autoencoder-vae.">https://www.kaggle.com/jannesklaas/mnist-autoencoder-vae.</a>下找到<a class="indexterm" id="id448"/> MNIST自动编码器和变型自动编码器的代码</p></div></div><p>我们现在要设置编码维度超参数，以便以后使用:</p><div><pre class="programlisting">encoding_dim = 32</pre></div><p>然后，我们使用Keras functional API构建自动编码器。虽然可以使用顺序API构建一个简单的自动编码器，但这对于我们了解函数式API如何工作是一个很好的复习。</p><p>首先，我们导入了<code class="literal">Model</code>类，它允许我们创建功能API模型。我们还需要导入<code class="literal">Input</code>和<code class="literal">Dense</code>层。您会记得在前面的章节中，函数式API需要一个单独的输入层，而顺序式API不需要。要导入这两个层，我们需要运行以下命令:</p><div><pre class="programlisting">from keras.models import Model

from keras.layers import Input, Dense</pre></div><p>现在我们把自动编码器的层连接起来:一个<code class="literal">Input</code>层后面跟着一个<code class="literal">Dense</code>层，它把图像编码成一个更小的图像。</p><p>随后是<code class="literal">Dense</code>解码层，旨在重建原始图像:</p><div><pre class="programlisting">input_img = Input(shape=(784,))



encoded = Dense(encoding_dim, activation='relu')(input_img)



decoded = Dense(784, activation='sigmoid')(encoded)</pre></div><p>在我们创建并链接这些层之后，我们就能够创建一个从输入映射到解码图像的模型:</p><div><pre class="programlisting">autoencoder = Model(input_img, decoded)</pre></div><p>为了更好地理解正在发生的事情，我们可以用下面的代码绘制一个可视化的自动编码器模型:</p><div><pre class="programlisting">from keras.utils import plot_model

plot_model(autoencoder, to_file='model.png', show_shapes=True) plt.figure(figsize=(10,10))

plt.imshow(plt.imread('model.png'))</pre></div><p>你可以看到我们的自动编码器如下:</p><div><img alt="Autoencoder for MNIST" src="img/B10354_06_02.jpg"/><div><p>自动编码器模型</p></div></div><p>我们可以用它来编译:</p><div><pre class="programlisting">autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')</pre></div><p>为了训练这个自动编码器，我们使用<em> X </em>值作为输入和输出:</p><div><pre class="programlisting">autoencoder.fit(X_train_flat, X_train_flat,epochs=50,batch_size=256,shuffle=True,validation_data=(X_test_flat, X_test_flat))</pre></div><p>在我们训练这个自动编码器之后，这将花费一到两分钟的时间，我们可以直观地检查它做得有多好。为此，我们首先<a class="indexterm" id="id449"/>从测试集中提取单个图像，然后向图像添加一个批量维度，以便在模型中运行它，这就是我们使用<code class="literal">np.expand_dims</code>的目的:</p><div><pre class="programlisting">original = np.expand_dims(X_test_flat[0],0)</pre></div><p>现在我们将通过自动编码器运行原始图像。你应该记得，原始的MNIST图像显示的是数字7，所以我们希望我们的自动编码器的输出也显示7:</p><div><pre class="programlisting">seven = autoencoder.predict(original)</pre></div><p>接下来，我们将把自动编码器输出和原始图像重新整形为28x28像素的图像:</p><div><pre class="programlisting">seven = seven.reshape(1,28,28)

original = original.reshape(1,28,28)</pre></div><p>然后，我们将原始图像和重建图像相邻绘制。<code class="literal">matplotlib</code>不允许图像有批次维度，因此我们需要传递一个没有批次维度的数组。通过用<code class="literal">[0,:,:]</code>索引图像，我们将只通过所有像素的第一个项目。</p><p>第一个项目现在不再有批次维度:</p><div><pre class="programlisting">fig = plt.figure(figsize=(7, 10))

a=fig.add_subplot(1,2,1)

a.set_title('Original')

imgplot = plt.imshow(original[0,:,:])



b=fig.add_subplot(1,2,2)

b.set_title('Autoencoder')

imgplot = plt.imshow(seven[0,:,:])</pre></div><p>运行完这段代码后，您会发现我们的希望已经实现了！与原始图像(左)相比，我们的自动编码器图像(右)也显示一个7！：</p><div><img alt="Autoencoder for MNIST" src="img/B10354_06_03.jpg"/><div><p>自动编码器结果</p></div></div><p>正如你在前面的截图中看到的，<a class="indexterm" id="id450"/>重建的七仍然是七，所以自动编码器能够捕捉到七是什么的大致想法。虽然它并不完美，但你可以看到它的边缘有点模糊，尤其是在左上角。看起来，虽然自动编码器不确定线的长度，但它确实知道7中有两条线，并且它知道它们遵循的大致方向。</p><p>像这样的自动编码器执行非线性PCA。它知道哪些成分对7成为7最重要。能够学习这种表达的用处不仅仅是图像。在信用卡欺诈检测中，这种主要成分将构成另一个分类器能够使用的良好特征。</p><p>在下一节中，我们将应用一个自动编码器来解决信用卡欺诈问题。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec78"/>信用卡自动编码器</h2></div></div></div><p>在本节中，我们将再次讨论信用卡欺诈问题。这一次，我们将使用与第2章、<em>将机器学习应用于结构化数据</em>中略有不同的数据集。</p><p>这个新的数据集包含具有匿名特征的实际信用卡交易的<a class="indexterm" id="id451"/>记录；然而，它并不太适合于特征工程。因此，我们将不得不依靠端到端的学习方法来构建一个良好的欺诈检测器。</p><div><div><h3 class="title"><a id="note23"/>注意</h3><p><strong>注意</strong>:你可以在<a class="ulink" href="https://www.kaggle.com/mlg-ulb/creditcardfraud">https://www.kaggle.com/mlg-ulb/creditcardfraud</a>找到数据集，在<a class="ulink" href="https://www.kaggle.com/jannesklaas/credit-vae">https://www.kaggle.com/jannesklaas/credit-vae</a>找到实现了自动编码器和变型自动编码器的笔记本。</p></div></div><p>像往常一样，我们首先加载数据。<code class="literal">Time</code>特性显示了事务的绝对时间，这使得这里的数据有点难以处理。因此，我们将删除它，我们可以通过运行:</p><div><pre class="programlisting">df = pd.read_csv('../input/creditcard.csv')

df = df.drop('Time',axis=1)</pre></div><p>然后，我们将交易的<code class="literal">X</code>数据从交易的分类中分离出来，并提取熊猫数据帧下面的NumPy数组:</p><div><pre class="programlisting">X = df.drop('Class',axis=1).values

y = df['Class'].values</pre></div><p>现在我们需要缩放特征。特征缩放使我们的模型更容易学习数据的良好表示。这一次，我们将采用与之前略有不同的功能缩放方法。我们会将所有要素缩放到0到1之间，而不是平均值为0，标准差为1。通过这样做，我们可以确保数据集中既没有非常高的值，也没有非常低的值。</p><p>我们必须意识到这种方法容易受到影响结果的异常值的影响。对于每一列，我们首先减去最小值，这样新的最小值就变为零。接下来，我们除以最大值，使新的最大值变为1。</p><p>通过指定<code class="literal">axis=0</code>，我们按列执行缩放:</p><div><pre class="programlisting">X -= X.min(axis=0)

X /= X.max(axis=0)</pre></div><p>最后，我们分割数据:</p><div><pre class="programlisting">from sklearn.model_selection import train_test_split

X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.1)</pre></div><p>然后，我们创建与之前完全相同的自动编码器；然而，这一次，我们用不同的维度来做。我们的输入现在有29个维度，我们将其压缩到12个维度，然后再恢复原来的29个维度的输出。</p><p>虽然在这里选择12维有些武断，但它提供了足够的容量来捕获所有相关信息，同时还能显著压缩数据:</p><div><pre class="programlisting">from keras.models import Model

from keras.layers import Input, Dense</pre></div><p>我们将对解码数据使用sigmoid激活函数。这是唯一可能的，因为我们已经将数据调整为0到1之间的值。我们还在编码层中使用了tanh激活。这只是一种风格选择，在实验中运行良好，并确保编码值都在-1和1之间。也就是说，你可以根据自己的需要使用不同的激活功能。</p><p>如果你正在处理图像或者更深层次的网络，重新激活通常是一个好的选择。但是，如果您使用的是较浅的网络，就像我们在这里所做的一样，那么tanh激活通常可以很好地工作:</p><div><pre class="programlisting">data_in = Input(shape=(29,))

encoded = Dense(12,activation='tanh')(data_in)

decoded = Dense(29,activation='sigmoid')(encoded)

autoencoder = Model(data_in,decoded)</pre></div><p>在本例中，我们使用了均方误差损失。这似乎是一个有点不寻常的选择，首先使用一个均方误差损失的sigmoid激活，但它是有意义的。大多数人认为sigmoid激活必须与交叉熵损失一起使用，但是交叉熵损失鼓励值为0或1，这对于这种情况下的分类任务很有效。</p><p>在我们的信用卡示例中，大多数值大约为0.5。我们可以在下面的代码中看到实现的均方误差，更好地处理目标不是二进制而是频谱的值。二元交叉熵迫使值接近零和一，这不是我们一直想要的:</p><div><pre class="programlisting">autoencoder.compile(optimizer='adam',loss='mean_squared_error')</pre></div><p>经过大约两分钟的训练后，自动编码器收敛到低损耗状态:</p><div><pre class="programlisting">autoencoder.fit(X_train,X_train,epochs = 20,batch_size=128,validation_data=(X_test,X_test))</pre></div><p>重建损失低，但我们如何知道我们的自动编码器是否工作良好？再一次，目视检查可以解决问题。正如我们之前解释过的，人类非常擅长视觉判断事物，但不太擅长判断抽象的数字。</p><p>要进行目视检查，首先我们必须进行一些<a class="indexterm" id="id453"/>预测，其中我们将通过自动编码器运行测试集的一个子集:</p><div><pre class="programlisting">pred = autoencoder.predict(X_test[0:10])</pre></div><p>然后我们必须能够绘制单个样本。以下代码生成一个重叠的条形图，比较原始事务数据和重建的事务数据:</p><div><pre class="programlisting">import matplotlib.pyplot as plt

import numpy as np



width = 0.8



prediction   = pred[9]

true_value    = X_test[9]



indices = np.arange(len(prediction))



fig = plt.figure(figsize=(10,7))



plt.bar(indices, prediction, width=width, color='b', label='Predicted Value')



plt.bar([i+0.25*width for i in indices], true_value, width=0.5*width, color='r', alpha=0.5, label='True Value')



plt.xticks(indices+width/2., ['V{}'.format(i) for i in range(len(prediction))] )



plt.legend()



plt.show()</pre></div><p>这段代码将为我们提供以下图表:</p><div><img alt="Autoencoder for credit cards" src="img/B10354_06_04.jpg"/><div><p>自动编码器重构与原始数据</p></div></div><p>如您所见，我们的<a class="indexterm" id="id454"/>模型在重建原始值方面做得很好。重构的值通常与真实值相匹配，如果不匹配，那么它们只会有很小的偏差。如你所见，目测比看抽象的数字更有洞察力。</p></div></div></div></body></html>
<html><head><title>Visualizing latent spaces with t-SNE</title><meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>

<meta content="urn:uuid:ee7bbf81-ee0c-427b-9574-49bd7094315d" name="Adept.expected.resource"/></head><body id="page"><div><div><div><div><h1 class="title"><a id="ch06lvl1sec83"/>用t-SNE可视化潜在空间</h1></div></div></div><p>我们现在有了一个自动编码器<a class="indexterm" id="id455"/>，它接收信用卡交易，并输出看起来差不多一样的信用卡交易。然而，这不是我们<a class="indexterm" id="id456"/>建造自动编码器的原因。autoencoder的主要优点是，我们现在可以将事务编码到一个较低维度的表示中，以捕获事务的主要元素。</p><p>要创建编码器模型，我们所要做的就是定义一个新的Keras模型，它从输入映射到编码状态:</p><div><pre class="programlisting">encoder = Model(data_in,encoded)</pre></div><p>注意，你不需要再次训练这个模型。这些层保持来自先前训练的自动编码器的权重。</p><p>为了对数据进行编码，我们现在使用编码器模型:</p><div><pre class="programlisting">enc = encoder.predict(X_test)</pre></div><p>但是我们如何知道这些编码是否包含任何关于欺诈的有意义的信息呢？同样，视觉表现是关键。虽然我们的编码比输入数据的维数少，但它们仍然有12维。人类不可能想到12维空间，所以我们需要在更低维的空间中绘制我们的编码，同时仍然保留我们关心的特征。</p><p>在我们的例子中，我们关心的特征是<em>接近度</em>。我们希望12维空间中彼此靠近的点在2维图中彼此靠近。更<a class="indexterm" id="id457"/>准确地说，我们关心邻里。我们希望高维空间中彼此最接近的点在低维空间中也彼此最接近。</p><p>保护邻居很重要，因为我们想找到欺诈的聚集地。如果我们发现欺诈性交易在我们的高维编码中形成一个簇，那么我们可以使用一个简单的检查，如果一个新的交易落入欺诈性簇，将该交易标记为欺诈性的。一种将高维数据投影到低维图中同时保留邻域的流行方法被称为<strong>t-分布式随机邻域嵌入、</strong>或<strong> t-SNE </strong>。</p><p>简而言之，t-SNE旨在忠实地表示所有点的随机样本中两个点相邻的概率。也就是说，它试图找到数据的低维表示，其中随机样本中的点与高维数据中的点具有相同的最近邻概率:</p><div><img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_05.jpg"/><div><p>SNE霸王龙如何测量相似度</p></div></div><p>t-SNE算法遵循以下步骤:</p><div><ol class="orderedlist arabic"><li class="listitem">Calculate the<a class="indexterm" id="id459"/> Gaussian similarity between all points. This is done by calculating the Euclidean (spatial) distance<a class="indexterm" id="id460"/> between points and then calculating the value of a Gaussian curve at that distance, as you can see in the preceding diagram. The Gaussian similarity for all points, <em>j,</em> from point <em>i</em> can be calculated as follows:<div><img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_002.jpg"/></div><p>在上式中，<img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_003.jpg"/> 2是高斯分布的方差。我们将在本章的后面讨论如何确定这个方差。注意，由于点<em> i </em>和<em> j </em>之间的相似度是由<em> i </em>和所有其他点之间的距离之和(表示为<em> k </em>)来衡量的，因此<em> i </em>和<em> j </em>、<img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_004.jpg"/>之间的相似度可以不同于<em> j </em>和<em> i </em>、<img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_005.jpg"/>之间的相似度。因此，我们对这两个相似性进行平均，以获得我们将继续使用的最终相似性:</p><div><img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_006.jpg"/></div><p>在上式中，<em> n </em>是数据点的个数。</p></li><li class="listitem">在低维空间中随机定位数据点。</li><li class="listitem">计算低维空间中所有点之间的<em>t-相似度</em>:<div><img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_007.jpg"/></div></li><li class="listitem">就像训练<a class="indexterm" id="id461"/>神经网络一样，我们将通过<a class="indexterm" id="id462"/>遵循损失函数的梯度来优化数据点在低维空间中的位置。在这种情况下，损失函数是更高和更低维度空间中相似性之间的<strong>kull back–lei bler</strong>(<strong>KL</strong>)散度。我们将在<a class="indexterm" id="id463"/>变型自动编码器一节中对KL发散进行更仔细的观察。现在，就把它看作是一种测量两个分布之间差异的方法。损失函数相对于低维空间中数据点<em> i </em>的位置<em>y<sub>I</sub>T10】的导数如下:<div> <img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_008.jpg"/> </div></em></li><li class="listitem">通过使用梯度下降来调整低维空间中的数据点，将高维数据中靠近的点移动得更近，将彼此远离的点移动得更远:<div> <img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_009.jpg"/> </div></li><li class="listitem">你会认识到这是一种有动量的梯度下降，因为先前的梯度被合并到更新的位置。</li></ol></div><p>使用的t分布总是有一个自由度。这种自由导致更简单的公式以及一些漂亮的数字属性，从而导致更快的计算和更有用的图表。</p><p>高斯分布的标准偏差<a class="indexterm" id="id464"/>可受用户使用<em>困惑</em>超参数的影响。困惑可以解释为我们期望一个点有多少个邻居。低困惑值<a class="indexterm" id="id465"/>强调局部邻近，而高困惑值强调全局困惑值。从数学上来说，困惑度可以计算如下:</p><div><img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_010.jpg"/></div><p>这里<em>P<sub>I</sub>T26】是数据集中所有数据点位置的概率分布，<img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_011.jpg"/>是该分布的Shanon熵，计算如下:</em></p><div><img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_012.jpg"/></div><p>虽然该公式的细节与使用t-SNE并不十分相关，但重要的是要知道t-SNE对标准偏差值<img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_013.jpg"/>执行搜索，以便找到全局分布<em> P <sub> i </sub>，</em>，对于该分布，我们数据上的熵是我们想要的困惑。换句话说，您需要手动指定困惑，但是这个困惑对您的数据集意味着什么也取决于数据集本身。</p><p>t-SNE的发明者劳伦斯·范·马尔滕和杰弗里·辛顿报告说，该算法对5到50之间的困惑选择相对稳健。大多数库中的默认值是30，对于大多数数据集来说这是一个很好的值。然而，如果您发现您的可视化不令人满意，那么调整困惑值可能是您想要做的第一件事。</p><p>对于所有涉及的数学，使用SNE霸王龙出奇的简单。Scikit-learn有一个方便的t-SNE实现，我们<a class="indexterm" id="id466"/>可以像使用scikit-learn中的任何算法一样使用它。</p><p>我们首先导入<code class="literal">TSNE</code>类，然后我们可以创建一个新的<code class="literal">TSNE</code>实例。我们定义要训练5000个纪元，使用默认的困惑度30，默认的学习率200。我们还指定我们将在培训过程中<a class="indexterm" id="id467"/>喜欢输出。然后我们调用<code class="literal">fit_transform</code>，它将我们的12种编码转换成二维投影:</p><div><pre class="programlisting">from sklearn.manifold import TSNE

tsne = TSNE(verbose=1,n_iter=5000)

res = tsne.fit_transform(enc)</pre></div><p>作为一个警告，t-SNE非常慢，因为它需要计算所有点之间的距离。默认情况下，scikit-learn使用更快的t-SNE版本，称为Barnes Hut近似。虽然没有那么精确，但速度明显更快。</p><p>还有一个更快的t-SNE的Python实现，可以作为scikit-learn实现的替代。然而，这并没有被很好地记录，包含的特性也较少，因此我们不会在本书中涉及它。</p><div><div><h3 class="title"><a id="note24"/>注意</h3><p><strong>注意</strong>:你可以在下面的网址<a class="ulink" href="https://github.com/DmitryUlyanov/Multicore-TSNE">https://github.com/DmitryUlyanov/Multicore-TSNE</a>找到更快的实现和安装说明。</p></div></div><p>然后，我们可以将t-SNE结果绘制成散点图。举例来说，我们将通过颜色区分欺诈和非欺诈，欺诈用红色标出，非欺诈用蓝色标出。由于t-SNE的实际值无关紧要，我们将隐藏坐标轴:</p><div><pre class="programlisting">fig = plt.figure(figsize=(10,7))

scatter =plt.scatter(res[:,0],res[:,1],c=y_test, cmap='coolwarm', s=0.6)

scatter.axes.get_xaxis().set_visible(False)

scatter.axes.get_yaxis().set_visible(False)</pre></div><p>现在让我们看看，输出图表将会是什么样子:</p><div><img alt="Visualizing latent spaces with t-SNE" src="img/B10354_06_06.jpg"/><div><p>t-SNE结果以散点图的形式出现</p></div></div><p>为了更容易识别，对于那些阅读印刷版的人来说，包含最多欺诈的<a class="indexterm" id="id468"/>簇，那些被标记为红色的，已经用圆圈标记。你可以看到欺诈和其他真实的交易很好的分开了，蓝色部分。很明显，我们的autoencoder已经找到了一种方法，可以在没有标签的情况下区分欺诈和真实交易。这是一种无监督学习的形式。</p><p>事实上，普通的<a class="indexterm" id="id469"/>自动编码器执行PCA的近似，这对于无监督学习是有用的。在输出图表中，您可以看到还有几个明显独立于其他事务的聚类，但这些都不是欺诈。使用自动编码器和无监督学习，有可能以我们以前从未想到的方式分离和分组我们的数据。例如，我们可以根据购买类型对交易进行分类。</p><p>使用我们的自动编码器，我们现在可以使用编码信息作为分类器的特征。然而，更好的是，只需对autoencoder稍加修改，我们就可以生成更多具有欺诈案例的<a class="indexterm" id="id470"/>潜在属性的数据，同时具有不同的特征。这是通过一个可变的自动编码器完成的，这将是下一节的重点。</p></div></body></html>
<html><head><title>Variational autoencoders</title><meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>

<meta content="urn:uuid:ee7bbf81-ee0c-427b-9574-49bd7094315d" name="Adept.expected.resource"/></head><body id="page"><div><div><div><div><h1 class="title"><a id="ch06lvl1sec84"/>变分自动编码器</h1></div></div></div><p>自动编码器基本上是PCA的近似。但是，它们可以扩展成为生成模型。给定一个输入，<strong>变分自动编码器</strong> ( <strong> VAEs </strong>)可以创建编码<em>分布</em>。这意味着对于<a class="indexterm" id="id471"/>一个欺诈案例，编码器将产生一个可能编码的分布，这些编码都代表交易的最重要特征。然后，解码器会将所有编码转换回原始事务。</p><p>这很有用，因为它允许我们生成有关交易的数据。我们之前发现的欺诈检测的一个问题是，欺诈交易并不多。因此，通过使用VAE，我们可以对任意数量的交易编码进行采样，并用更多欺诈性交易数据来训练我们的分类器。</p><p>那么，VAEs是怎么做的呢？VAE不是只有一个压缩表示向量，而是有两个:一个用于均值编码<img alt="Variational autoencoders" src="img/B10354_06_014.jpg"/>，一个用于该编码的标准偏差<img alt="Variational autoencoders" src="img/B10354_06_015.jpg"/>:</p><div><img alt="Variational autoencoders" src="img/B10354_06_07.jpg"/><div><p>VAE计划</p></div></div><p>均值和标准差都是向量，就像我们用于标准自动编码器的编码向量一样。然而，为了创建实际的编码，我们只需要将带有<a class="indexterm" id="id472"/>标准偏差的随机噪声<img alt="Variational autoencoders" src="img/B10354_06_016.jpg"/>添加到我们的编码向量中。</p><p>为了实现值的广泛分布，我们的网络使用两种损失的组合进行训练:重建损失，这可以从普通的自动编码器中得知；以及编码分布和标准高斯分布之间的KL发散损失，标准高斯分布的标准偏差为1。</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec79"/> MNIST的例子</h2></div></div></div><p>现在开始我们的第一首VAE。该VAE将处理MNIST数据集，并让您更好地了解VAEs的工作原理。在下一节中，我们将为信用卡欺诈检测构建相同的VAE。</p><p>首先，我们需要导入几个元素，只需运行:</p><div><pre class="programlisting">from keras.models import Model

from keras.layers import Input, Dense, Lambda

from keras import backend as K

from keras import metrics</pre></div><p>注意两个新的导入，<code class="literal">Lambda</code>层和<code class="literal">metrics</code>模块。<code class="literal">metrics</code>模块提供了度量标准，比如交叉熵损失，我们将使用它来构建自定义的损失函数。同时，<code class="literal">Lambda</code>层允许我们使用Python函数作为层，我们将使用它从编码分布中对<a class="indexterm" id="id474"/>进行采样。我们将会看到<code class="literal">Lambda</code>层是如何工作的，但是首先，我们需要建立神经网络的其余部分。</p><p>我们需要做的第一件事是定义几个超参数。我们的数据具有784的原始维度，我们将其压缩成32维的潜在向量。我们的网络在输入和潜在向量之间有一个中间层，它有256个维度。我们将训练50个纪元，批次大小为100:</p><div><pre class="programlisting">batch_size = 100

original_dim = 784

latent_dim = 32

intermediate_dim = 256

epochs = 50</pre></div><p>出于计算原因，学习标准差的对数比标准差本身更容易。为此，我们创建了网络的前半部分，其中的输入<code class="literal">x,</code>映射到中间层<code class="literal">h</code>。从这一层开始，我们的网络分裂为<code class="literal">z_mean</code>，表示<img alt="MNIST example" src="img/B10354_06_017.jpg"/>和<code class="literal">z_log_var</code>，表示<img alt="MNIST example" src="img/B10354_06_018.jpg"/>:</p><div><pre class="programlisting">x = Input(shape=(original_dim,))

h = Dense(intermediate_dim, activation='relu')(x)

z_mean = Dense(latent_dim)(h)

z_log_var = Dense(latent_dim)(h)</pre></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec80"/>使用λ层</h2></div></div></div><p><code class="literal">Lambda</code>层将任意表达式，即Python函数，包装成Keras层。然而，要做到这一点，还有一些要求。为了使<a class="indexterm" id="id475"/>反向传播有效，函数需要可微分。毕竟，我们希望通过损失的梯度来更新网络权重。幸运的是，Keras在其<code class="literal">backend</code>模块中提供了许多函数，这些函数都是可微分的，简单的Python数学，例如<em> y = x + 4 </em>，也很好。</p><p>此外，<code class="literal">Lambda</code>函数只能接受一个输入参数。在我们想要创建的层中，输入只是前一层的输出张量。在这种情况下，我们想要创建一个有两个输入的层，<img alt="Using the Lambda layer" src="img/B10354_06_019.jpg"/>和<img alt="Using the Lambda layer" src="img/B10354_06_20.jpg"/>。因此，我们将把这两个输入包装成一个元组，然后我们可以把它拆开。</p><p>您可以在下面看到<a class="indexterm" id="id476"/>采样功能:</p><div><pre class="programlisting">def sampling(args):

    z_mean, z_log_var = args                                  #1

    epsilon = K.random_normal(shape=(K.shape(z_mean)[0], latent_dim), mean=0.,stddev=1.0)                     #2

    return z_mean + K.exp(z_log_var / 2) * epsilon            #3</pre></div><p>让我们花点时间来分解这个函数:</p><div><ol class="orderedlist arabic"><li class="listitem">我们把输入元组拆开，得到两个输入张量。</li><li class="listitem">我们创建一个张量，它包含随机的、正态分布的噪声，平均值为零，标准差为一。张量的形状为我们的输入张量(<code class="literal">batch_size</code>，<code class="literal">latent_dim</code>)。</li><li class="listitem">最后，我们将随机噪声乘以我们的标准偏差，得到学习的标准偏差，并加上学习的平均值。由于我们正在学习对数标准差，我们必须将指数函数应用于我们学习的张量。</li></ol></div><p>所有这些操作都是可区分的，因为我们使用的是Keras后端函数。现在我们可以把这个函数变成一个层，用一条线把它和前面两层连接起来:</p><div><pre class="programlisting">z = Lambda(sampling)([z_mean, z_log_var])</pre></div><p>瞧！我们现在有了一个自定义图层，它从两个张量描述的正态分布中采样。Keras可以通过该层自动反向传播，并训练之前各层的权重。</p><p>既然我们已经对数据进行了编码，我们还需要对其进行解码。我们可以用两个<code class="literal">Dense</code>层来做到这一点:</p><div><pre class="programlisting">decoder_h = Dense(intermediate_dim, activation='relu')(z)

x_decoded = Dense(original_dim, activation='sigmoid')decoder_mean(h_decoded)</pre></div><p>我们的网络现在已经完成。该网络将把任何MNIST图像编码成平均值和标准偏差张量，解码部分然后从该张量重建图像。唯一缺少的是定制损耗，它激励网络重建图像并在其编码中产生正态高斯分布。让我们现在解决这个问题。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec81"/>库尔贝克-莱布勒散度</h2></div></div></div><p>要为我们的VAE创建自定义损失，我们需要一个自定义损失函数。这个损失函数将基于<strong>库尔贝克-莱布勒</strong>(<strong>k1</strong>)散度。</p><p>KL散度，是机器学习从<a class="indexterm" id="id477"/>信息论继承的度量之一，就像交叉熵一样。虽然它经常被使用，但是当你试图理解它的时候会遇到很多困难。</p><p>在其核心，KL散度测量当分布<em> p </em>接近分布<em> q </em>时有多少信息丢失。</p><p>假设您正在开发一个金融模型，并且已经收集了一项证券投资的回报数据。你的金融建模工具都假设收益是正态分布的。下图显示了回报率的实际分布与使用正态分布模型的近似值。为了这个例子，让我们假设只有离散的回报。在我们继续之前，请确保我们将在后面讨论连续发行版:</p><div><img alt="Kullback–Leibler divergence" src="img/B10354_06_08.jpg"/><div><p>近似值与实际值</p></div></div><p>当然，数据中的回报并不完全是正态分布的。那么，如果你失去了近似值，你会失去多少关于回报的信息呢？这正是KL散度所测量的:</p><div><img alt="Kullback–Leibler divergence" src="img/B10354_06_021.jpg"/></div><p>这里的<img alt="Kullback–Leibler divergence" src="img/B10354_06_022.jpg"/>和<img alt="Kullback–Leibler divergence" src="img/B10354_06_023.jpg"/>是<em> x </em>的概率，在这种情况下，回报具有某个值<em> i </em>，比如说5%。前面的公式<a class="indexterm" id="id478"/>有效地表达了分布<em> p </em>和<em> q </em>的概率对数的期望差:</p><div><img alt="Kullback–Leibler divergence" src="img/B10354_06_024.jpg"/></div><p>如果用分布<em> q </em>来近似分布<em> p </em>，对数概率的预期差异与平均信息损失相同。请参见以下内容:</p><div><img alt="Kullback–Leibler divergence" src="img/B10354_06_025.jpg"/></div><p>假设KL散度通常被写出如下:</p><div><img alt="Kullback–Leibler divergence" src="img/B10354_06_026.jpg"/></div><p>它也可以以连续形式写成:</p><div><img alt="Kullback–Leibler divergence" src="img/B10354_06_027.jpg"/></div><p>对于VAEs，我们希望编码的分布是正态高斯分布，均值为零，标准差为一。</p><p>当<em> p </em>被正态高斯分布<img alt="Kullback–Leibler divergence" src="img/B10354_06_028.jpg"/>代替，近似<em> q </em>是一个均值为<img alt="Kullback–Leibler divergence" src="img/B10354_06_029.jpg"/>标准差为<img alt="Kullback–Leibler divergence" src="img/B10354_06_30.jpg"/><img alt="Kullback–Leibler divergence" src="img/B10354_06_031.jpg"/>的<a class="indexterm" id="id479"/>正态分布时，KL散度简化为:</p><div><img alt="Kullback–Leibler divergence" src="img/B10354_06_032.jpg"/></div><p>因此，我们的均值和标准差向量的偏导数如下:</p><div><img alt="Kullback–Leibler divergence" src="img/B10354_06_033.jpg"/></div><p>另一个是:</p><div><img alt="Kullback–Leibler divergence" src="img/B10354_06_034.jpg"/></div><p>你可以看到，如果<img alt="Kullback–Leibler divergence" src="img/B10354_06_036.jpg"/>是零，相对于<img alt="Kullback–Leibler divergence" src="img/B10354_06_035.jpg"/>的导数是零，如果<img alt="Kullback–Leibler divergence" src="img/B10354_06_038.jpg"/>是一，相对于<img alt="Kullback–Leibler divergence" src="img/B10354_06_037.jpg"/>的导数也是零。这个损失项被加到重建损失中。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec82"/>创建自定义亏损</h2></div></div></div><p>VAE损失是两个损失的组合:激励模型重构其输入井的重构损失，以及激励模型用其编码逼近正态高斯<a class="indexterm" id="id480"/>分布的KL散度损失。要创建这个组合损失，我们必须先分别计算两个损失部分，然后再将它们组合起来。</p><p>重建损失与我们应用于普通自动编码器的损失相同。二值交叉熵对于MNIST重建是一个合适的损失。由于Keras的二进制交叉熵损失的实现已经取了整个批次的平均值，这是我们稍后才想做的操作，我们必须将损失按比例放大，以便我们可以将其除以输出维度:</p><div><pre class="programlisting">reconstruction_loss = original_dim * metrics.binary_crossentropy(x, x_decoded)</pre></div><p>KL散度损失是KL散度的简化形式，我们在前面的KL散度部分讨论过:</p><div><img alt="Creating a custom loss" src="img/B10354_06_039.jpg"/></div><p>用Python表示，KL散度损失如下所示:</p><div><pre class="programlisting">kl_loss = - 0.5 * K.sum(1 + z_log_var - K.square(z_mean) - K.exp(z_log_var), axis=-1)</pre></div><p>我们的最终损失是重建损失和KL发散损失之和的平均值:</p><div><pre class="programlisting">vae_loss = K.mean(reconstruction_loss + kl_loss)</pre></div><p>由于我们在所有计算中都使用了Keras后端，因此产生的损失是一个可以自动微分的张量。现在我们可以像往常一样创建我们的模型:</p><div><pre class="programlisting">vae = Model(x, x_decoded)</pre></div><p>由于我们使用的是自定义损耗，因此我们有单独的损耗，我们不能只将其添加到<code class="literal">compile</code>语句中:</p><div><pre class="programlisting">vae.add_loss(vae_loss)</pre></div><p>现在我们将编译模型。由于我们的模型已经有一个损失，我们只需指定优化器:</p><div><pre class="programlisting">vae.compile(optimizer='rmsprop')</pre></div><p>自定义丢失的另一个副作用是，它将VAE的<em>输出</em>与VAE的<em>输入</em>进行比较，这使得<a class="indexterm" id="id481"/>有意义，因为我们想要重构输入。因此，我们不必指定<em> y </em>值，因为只指定一个输入就足够了:</p><div><pre class="programlisting">

		vae.fit(X_train_flat,

			shuffle=True,

			epochs=epochs,

			batch_size=batch_size,

			validation_data=(X_test_flat, None))



</pre></div><p>在下一节中，我们将了解如何使用VAE生成数据。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec83"/>使用VAE生成数据</h2></div></div></div><p>我们已经有了自动编码器，但是我们如何生成更多的数据呢？嗯，我们输入一个，比如说，一张7的图片，然后通过自动编码器运行多次。由于autoencoder是从一个分布中随机抽样的，所以每次运行时输出都会略有不同。</p><p>为了展示这一点，根据我们的测试数据，我们将采用7:</p><div><pre class="programlisting">one_seven = X_test_flat[0]</pre></div><p>然后，我们添加一个批处理维度，并在批处理中重复七次。之后，我们现在有一批四个相同的7:</p><div><pre class="programlisting">one_seven = np.expand_dims(one_seven,0)

one_seven = one_seven.repeat(4,axis=0)</pre></div><p>然后，我们可以对该批次进行预测，在这种情况下，我们会得到重构的7:</p><div><pre class="programlisting">s = vae.predict(one_seven)</pre></div><p>下一步分为两部分。首先，我们要把所有的7重塑成图像形式:</p><div><pre class="programlisting">s= s.reshape(4,28,28)</pre></div><p>然后我们将绘制它们:</p><div><pre class="programlisting">fig=plt.figure(figsize=(8, 8))

columns = 2

rows = 2

for i in range(1, columns*rows +1):

    img = s[i-1]

    fig.add_subplot(rows, columns, i)

    plt.imshow(img)

plt.show()</pre></div><p>作为运行我们刚刚走过的代码的结果，我们将看到下面的屏幕截图，显示我们的输出是四个7:</p><div><img alt="Using a VAE to generate data" src="img/B10354_06_09.jpg"/><div><p>七的集合</p></div></div><p>如你所见，所有的图像<a class="indexterm" id="id483"/>都显示一个7。虽然它们看起来很相似，但如果你仔细观察，你会发现有几个明显的不同之处。左上方的7比左下方的7笔画不明显。同时，右下方的7在末端有一个瞄准镜。</p><p>我们刚刚见证的是VAE成功创造了新的数据。虽然使用这些数据进行更多的训练不如使用全新的真实世界数据好，但它仍然非常有用。虽然像这样的生成模型看起来不错，但我们现在将讨论如何将这种技术用于信用卡欺诈检测。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec84"/>端到端欺诈检测系统的VAEs</h2></div></div></div><p>为了将VAE从MNIST的例子转移到真实的欺诈检测问题，我们所要做的就是改变三个<a class="indexterm" id="id484"/>超参数:VAE信用卡的输入、中间和潜在维度，它们都比MNIST VAE的要小。其他一切都将保持不变:</p><div><pre class="programlisting">original_dim = 29

latent_dim = 6

intermediate_dim = 16</pre></div><p>以下可视化显示了生成的VAE，包括输入和输出形状:</p><div><img alt="VAEs for an end-to-end fraud detection system" src="img/B10354_06_10.jpg"/><div><p>信用卡VAE概览</p></div></div><p>有了可以编码并生成信用卡数据的VAE，我们现在可以处理端到端欺诈检测系统的任务了。这可以减少预测中的偏差，因为我们可以直接从数据中学习复杂的规则。</p><p>我们使用自动编码器的编码部分作为特征提取器以及一个<a class="indexterm" id="id486"/>方法，在我们需要的地方给我们更多的数据。具体如何工作将在关于主动学习的章节中讨论，但是现在，让我们绕一点弯子，看看vae如何为时间序列工作。</p></div></div></body></html>
<html><head><title>VAEs for time series</title><meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>

<meta content="urn:uuid:ee7bbf81-ee0c-427b-9574-49bd7094315d" name="Adept.expected.resource"/></head><body id="page"><div><div><div><div><h1 class="title"><a id="ch06lvl1sec85"/>时间序列的VAEs</h1></div></div></div><p>本节涵盖了时间序列值的如何<a class="indexterm" id="id487"/>和为什么，并给出了它们被使用的几个例子。时间序列是金融领域的一个大话题，第四章<a class="link" href="ch04.html" title="Chapter 4. Understanding Time Series"/>、<em>、理解时间序列、</em>都非常关注它。</p><p>自动编码器已经发现了与时间序列相关的应用，因为它们能够将长时间序列编码成单个描述性向量。举例来说，这一向量然后可用于有效地将一个时间序列与另一个时间序列进行比较，例如，基于无法用简单的相关性捕捉到的特定和复杂的模式。</p><p>想想2010年的“闪电崩盘”。2010年5月6日，从02:32开始，美国市场出现了重大价值损失。道琼斯工业平均指数下跌了约9%，这相当于约一万亿美元的价值在几分钟内化为乌有。36分钟后，崩盘结束了，大部分失去的价值重新获得，人们开始想知道到底发生了什么。</p><p>五年后，一个名叫纳文德尔·辛格·萨劳的人因部分导致闪电崩盘并在此过程中赚了4000万美元而被捕。Sarao从事了一种被称为“欺骗”的做法，即他使用一个自动化的机器人发出大量的销售订单，这些订单无法在市场上得到满足，但会压低价格。</p><p>在取消订单之前，机器人只会将订单保留在证券交易所的订单簿中很短的一段时间。同时，Sarao会以新的低价买进股票，然后在取消销售订单后股票开始反弹时获利。虽然Sarao肯定不是唯一对闪电崩盘负责的人，但欺骗等做法现在是非法的，纳斯达克(美国)、东京(日本)和孟买(印度)证券交易所等交易所现在必须监控和标记此类案件。</p><p>如果你深究一下关于高频交易的旧博客帖子，比如彭博的<em>欺骗者保持市场诚实</em>，你可以在<a class="ulink" href="https://www.bloomberg.com/opinion/articles/2015-01-23/high-frequency-trading-spoofers-and-front-running">https://www . Bloomberg . com/opinion/articles/2015-01-23/high-frequency-trading-Spoofers-and-front-running</a>查看，然后你会发现一些在大公司工作的交易员公开推荐欺骗或抢先操作大订单，但那是另一个故事了。</p><p>当有人进行欺骗时，我们如何检测？一种方法是使用自动编码器。通过使用大量的订单簿信息，我们可以训练一个自动编码器来重建“正常”的交易行为。对于交易模式偏离正常交易很多的交易者来说，训练好的自动编码器对于交易的重建损失会相当高。</p><p>另一种选择是在不同种类的模式上训练自动编码器，无论这些模式是否非法，然后在潜在空间中聚集模式，就像我们对欺诈性信用卡交易所做的那样。</p><p>默认情况下，递归神经网络(RNNs)接受一个时间序列并输出一个向量。如果Keras的<code class="literal">return_sequences</code>参数设置为<code class="literal">True</code>，它们也可以输出序列。使用递归神经网络(如LSTMs ),可以使用以下代码构建时间序列的自动编码器:</p><div><pre class="programlisting">from keras.models import Sequential

from keras.layers import LSTM, RepeatVector



model = Sequential()                                            #1

model.add(LSTM(latent_dim, input_shape=(maxlen, nb_features)))  #2

model.add(RepeatVector(maxlen))                                 #3

model.add(LSTM(nb_features, return_sequences=True))             #4</pre></div><p>让我们暂停一下，分解一下我们刚刚编写的代码。如您所见，这段代码有四个关键要素:</p><div><ol class="orderedlist arabic"><li class="listitem">使用顺序API构建了一个简单的自动编码器。</li><li class="listitem">我们首先将我们的序列长度<code class="literal">maxlen</code>，以及等于<code class="literal">nb_features</code>的特征数量输入到一个LSTM中。LSTM只会返回它最后的输出，一个维度为<code class="literal">latent_dim</code>的单一向量。这个向量是我们序列的编码。</li><li class="listitem">为了解码向量，我们需要在时间序列的长度上重复它。这是由<code class="literal">RepeatVector</code>层完成的。</li><li class="listitem">现在，我们将重复编码的序列输入解码LSTM，这次它返回完整的序列。</li></ol></div><p>VAEs也能找到交易的途径。它们可以通过生成新的、不可见的测试数据来增强回溯测试。同样，我们可以使用VAEs来生成关于缺失数据的合同的数据。</p><p>有理由认为，仅仅因为两个交易日看起来有点不同，同样的力量可能在起作用。数学上，我们可以假设市场数据<img alt="VAEs for time series" src="img/B10354_06_040.jpg"/>是从一个概率分布中取样的，<em>p(x)</em>带有少量潜在变量，<em> h </em>。使用自动编码器，我们可以近似计算出<em> p(h|x) </em>，即给定<em> x </em>时<em> h </em>的分布。这将允许我们分析市场中的驱动力。</p><p>这解决了用于这类问题的标准最大似然模型在计算上难以处理的问题。执行相同任务的另外两种方法是<em>马尔可夫链蒙特卡罗</em>和<em>汉密尔顿蒙特卡罗</em>方法。虽然这两者都不会在这里深入讨论，虽然它们将在后面的章节中介绍，但值得理解的是，vae以一种可计算的方式解决了数学金融中长期存在的问题。</p><p>生成模型也可以用来解决超出传统方法范围的问题。金融市场从根本上来说是一个敌对的环境，投资者试图实现总体上不可能实现的目标:高于平均水平的回报。知道一家公司做得很好是不够的:如果每个人都知道这家公司做得很好，那么股价就会很高，回报就会很低。关键是知道一家公司做得很好，而其他人都认为它做得很差。市场是一个零和博弈的环境。gan利用这些动态生成真实数据。</p></div></body></html>
<html><head><title>GANs</title><meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>

<meta content="urn:uuid:ee7bbf81-ee0c-427b-9574-49bd7094315d" name="Adept.expected.resource"/></head><body id="page"><div><div><div><div><h1 class="title"><a id="ch06lvl1sec86"/>甘斯</h1></div></div></div><p>甘斯的工作很像艺术品伪造者和博物馆馆长。艺术品伪造者每天都试图向博物馆出售一些假艺术品，馆长每天都试图区分某件作品是真是假。伪造者从失败中吸取教训。通过试图愚弄馆长，观察什么导致成功和失败，他们成为一个更好的伪造者。但是馆长也在学习。通过努力领先于伪造者，他们成为了更好的策展人。久而久之，伪造品越来越好，辨别过程也越来越好。经过多年的斗争，艺术品伪造者是一个可以画得和毕加索一样好的专家，而馆长是一个可以通过微小的细节来辨别一幅真正的画的专家。</p><p>从技术上讲，GAN由两个神经网络组成:一个<em>生成器，</em>，它从随机潜在向量中产生数据；一个<em>鉴别器，</em>，它将数据分类为“真实的”，即来自训练集，或者“虚假的”，即来自生成器。</p><p>我们可以想象一个GAN方案，如下图所示:</p><div><img alt="GANs" src="img/B10354_06_11.jpg"/><div><p>GAN方案</p></div></div><p>同样，生成模型在生成图像时更容易理解，因此在本节中，我们将查看图像数据，尽管各种数据都可以使用。</p><p><a class="indexterm" id="id493"/> GAN的训练过程如下:</p><div><ol class="orderedlist arabic"><li class="listitem">创建包含随机数的潜在向量。</li><li class="listitem">潜在向量被输入生成器，生成图像。</li><li class="listitem">来自生成器的一组伪图像与来自训练集的一组真实图像混合。鉴别器接受真假数据的二进制分类训练。</li><li class="listitem">在鉴别器被训练一段时间后，我们再次输入假图像。这一次，我们将假图像的标签设置为“真实”我们通过鉴频器反向传播，并获得相对于鉴频器的<em>输入</em>的损耗梯度。我们<em>而不是</em>基于这个信息更新鉴别器的权重。</li><li class="listitem">我们现在有了梯度来描述我们必须如何改变我们的假图像，以便鉴别器将它归类为真实图像。我们使用这些梯度反向传播和训练生成器。</li><li class="listitem">使用我们新改进的生成器，我们再次创建假图像，这些假图像与真实图像混合，以便训练鉴别器，鉴别器的梯度用于再次训练生成器。</li></ol></div><div><div><h3 class="title"><a id="note25"/>注意</h3><p><strong>注意</strong> : GAN训练与我们在<a class="link" href="ch03.html" title="Chapter 3. Utilizing Computer Vision">第3章</a>、<em>中讨论的利用计算机视觉</em>的网络层可视化有很多相似之处，只是这次我们不只是创建一个<a class="indexterm" id="id494"/>最大化激活功能的图像，而是创建一个专门最大化另一个网络的激活功能的生成网络。</p></div></div><p>数学上，生成器<em> G </em>和鉴别器<em> D </em>用价值函数<em> V(G，D) </em>玩一个mini-max双人游戏:</p><div><img alt="GANs" src="img/B10354_06_041.jpg"/></div><p>在这个公式中<em> x </em>是从真实数据的分布中抽取的一项，<img alt="GANs" src="img/B10354_06_042.jpg"/>z是从潜在向量空间中抽取的潜在向量，<em> p <sub> z </sub> </em>。</p><p>发电机的输出分配记为<em>p<sub>g</sub>T32】。可以证明这个博弈的全局最优是</em></p><div><img alt="GANs" src="img/B10354_06_043.jpg"/></div><p>即，如果生成数据的分布等于实际数据的分布。</p><p>gan按照博弈论的价值函数进行优化。用深度学习解决这种类型的优化问题是一个活跃的研究领域，我们将在第8章、<em>隐私、调试和推出您的产品、</em>中再次讨论这个领域，在那里我们将讨论强化学习。深度学习可用于解决极大极小游戏的事实对于金融和经济学领域来说是一个令人兴奋的消息，该领域存在许多这样的问题。</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec85"/>一个甘</h2></div></div></div><p>现在让我们实现一个GAN来生成MNIST字符。在我们开始之前，我们需要做一些进口。gan是大型模型，在本节中，您将看到如何将顺序API模型和功能API模型结合起来，以简化模型构建:</p><div><pre class="programlisting">from keras.models import Model, Sequential</pre></div><p>在本例中，我们将使用一些新的图层类型:</p><div><pre class="programlisting">from keras.layers import Input, Dense, Dropout, Flatten

from keras.layers import LeakyReLU, Reshape

from keras.layers import Conv2D, UpSampling2D</pre></div><p>让我们来看看一些关键要素:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">LeakyReLU</code>就像ReLU，除了激活允许小的负值。此<a class="indexterm" id="id495"/>防止梯度变为零。这个激活函数对GANs很有效，我们将在下一节讨论:</li></ul></div><div><img alt="A MNIST GAN" src="img/B10354_06_12.jpg"/><div><p>泄漏ReLU</p></div></div><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><code class="literal">Reshape</code>的作用与<code class="literal">np.reshape</code>相同:它将张量转化为一种新的形式。</li><li class="listitem" style="list-style-type: disc"><code class="literal">UpSampling2D</code>例如，通过重复特征地图中的所有数字，将2D特征地图放大两倍。</li></ul></div><p>我们将像往常一样使用<code class="literal">Adam</code>优化器:</p><div><pre class="programlisting">from keras.optimizers import Adam</pre></div><p>神经网络层被随机初始化。通常，随机数是从一个<a class="indexterm" id="id496"/>很好地支持学习的分布中抽取的。对于GANs，正态高斯分布是更好的选择:</p><div><pre class="programlisting">from keras.initializers import RandomNormal</pre></div><p>现在，我们将构建发电机模型:</p><div><pre class="programlisting">generator = Sequential()                                       #1 



generator.add(Dense(128*7*7, input_dim=latent_dim, kernel_initializer=RandomNormal(stddev=0.02)))   #2



generator.add(LeakyReLU(0.2))                                  #3

generator.add(Reshape((128, 7, 7)))                            #4

generator.add(UpSampling2D(size=(2, 2)))                       #5



generator.add(Conv2D(64,kernel_size=(5, 5),padding='same'))    #6



generator.add(LeakyReLU(0.2))                                  #7

generator.add(UpSampling2D(size=(2, 2)))                       #8



generator.add(Conv2D(1, kernel_size=(5, 5),padding='same', activation='tanh'))                    #9



adam = Adam(lr=0.0002, beta_1=0.5)

generator.compile(loss='binary_crossentropy', optimizer=adam) #10</pre></div><p>同样，让我们看看生成器模型代码，它由10个关键步骤组成:</p><div><ol class="orderedlist arabic"><li class="listitem">我们将生成器构建为一个序列模型。</li><li class="listitem">第一层获取随机潜在向量，并将其映射到一个维度为<em>128 * 7 * 7 = 6272</em>的向量。它已经大大扩展了我们生成的数据的维度。对于这种完全连接的图层，从标准偏差相对较小的正态高斯分布初始化权重非常重要。与均匀分布相反，高斯分布将具有更少的极值，这将使训练更容易。</li><li class="listitem">第一层的激活功能是<code class="literal">LeakyReLU</code>。我们需要指定负输入的斜率有多陡；在这种情况下，负输入乘以0.2。</li><li class="listitem">现在，我们将平面向量重塑成一个3D张量。这与使用<code class="literal">Flatten</code>层相反，我们在<a class="link" href="ch03.html" title="Chapter 3. Utilizing Computer Vision">第3章</a>、<em>中使用了</em>计算机视觉<a class="indexterm" id="id497"/>。我们现在有一个7x7像素图像或特征图中的128个通道的张量。</li><li class="listitem">使用<code class="literal">UpSampling2D</code>，我们把这个图像放大到14x14像素。<code class="literal">size</code>参数指定了宽度和高度的乘数因子。</li><li class="listitem">现在我们可以应用一个标准的<code class="literal">Conv2D</code>层。与大多数图像分类器的情况相反，我们使用5x5像素的相对较大的核大小。</li><li class="listitem">在<code class="literal">Conv2D</code>层之后的激活是另一个<code class="literal">LeakyReLU</code>。</li><li class="listitem">我们再次上采样，使图像达到28x28像素，与MNIST图像的尺寸相同。</li><li class="listitem">我们生成器的最终卷积层只输出单通道图像，因为MNIST图像只有黑白。注意最后一层的激活是一个<code class="literal">tanh</code>激活。<code class="literal">Tanh</code>将所有值压缩到负1和1之间。这可能是意料之外的，因为图像数据通常不包含任何低于零的值。然而，从经验上来看，<code class="literal">tanh</code>激活比<code class="literal">sigmoid</code>激活对GANs更有效。</li><li class="listitem">最后，我们编译生成器，用<code class="literal">Adam</code>优化器以非常小的学习速率和比通常更小的动量进行训练。</li></ol></div><p>鉴别器是一个相对标准的图像分类器，它将图像分为真假。只有一些针对GAN的修改:</p><div><pre class="programlisting">#Discriminator

discriminator = Sequential()

discriminator.add(Conv2D(64, kernel_size=(5, 5), strides=(2, 2), padding='same', input_shape=(1, 28, 28),kernel_initializer=RandomNormal(stddev=0.02)))                                               #1



discriminator.add(LeakyReLU(0.2))

discriminator.add(Dropout(0.3))

discriminator.add(Conv2D(128, kernel_size=(5, 5), strides=(2, 2), padding='same'))

discriminator.add(LeakyReLU(0.2))

discriminator.add(Dropout(0.3))                          #2

discriminator.add(Flatten())

discriminator.add(Dense(1, activation='sigmoid'))

discriminator.compile(loss='binary_crossentropy', optimizer=adam)</pre></div><p>这里有两个关键因素:</p><div><ol class="orderedlist arabic"><li class="listitem">与生成器一样，鉴别器的第一层应该从高斯分布中随机初始化。</li><li class="listitem">图像分类器中通常使用Dropout。对于GANs，也应在最后一层之前使用。</li></ol></div><p>现在我们有了一个生成器和一个鉴别器。为了训练生成器，我们必须从鉴别器获得梯度，以反向传播并训练生成器。这就是<a class="indexterm" id="id498"/> Keras模块化设计发挥威力的地方。</p><div><div><h3 class="title"><a id="note26"/>注意</h3><p><strong>注意</strong> : Keras模型可以像Keras层一样处理。</p></div></div><p>以下代码创建了一个GAN模型，可用于根据鉴频器梯度训练生成器:</p><div><pre class="programlisting">discriminator.trainable = False                         #1

ganInput = Input(shape=(latent_dim,))                   #2

x = generator(ganInput)                                 #3

ganOutput = discriminator(x)                            #4

gan = Model(inputs=ganInput, outputs=ganOutput)         #5

gan.compile(loss='binary_crossentropy', optimizer=adam) #6</pre></div><p>在该准则中，有六个关键阶段:</p><div><ol class="orderedlist arabic"><li class="listitem">训练发电机时，我们不想训练<code class="literal">discriminator</code>。当将<code class="literal">discriminator</code>设置为不可训练时，只有使用不可训练重量编译的型号的重量才会被冻结。也就是说，我们仍然可以单独训练<code class="literal">discriminator</code>模型，但是一旦它成为再次编译的GAN模型的一部分，它的权重就被冻结了。</li><li class="listitem">我们为GAN创建一个新的输入，它接受随机的潜在向量。</li><li class="listitem">我们将发电机模型连接到<code class="literal">ganInput</code>层。该模型可以像功能API下的层一样使用。</li><li class="listitem">我们现在将带有冻结砝码的鉴频器连接到发生器。同样，我们调用模型的方式与我们在函数式API中使用层的方式相同。</li><li class="listitem">我们创建一个模型，将输入映射到鉴别器的输出。</li><li class="listitem">我们编译我们的GAN模型。因为我们在这里称之为<code class="literal">compile</code>，只要鉴别器模型是GAN模型的一部分，它们的权重就被冻结。Keras将在训练时间抛出一个警告，说明权重没有被实际的鉴别器模型冻结。</li></ol></div><p>训练我们的GAN需要对训练过程进行一些定制，还需要一些特定于GAN的技巧。更具体地说，我们必须编写自己的训练循环，这将通过以下代码来实现:</p><div><pre class="programlisting">epochs=50

batchSize=128

batchCount = X_train.shape[0] // batchSize                     #1



for e in range(1, epochs+1):                                   #2

    print('-'*15, 'Epoch %d' % e, '-'*15)

    for _ in tqdm(range(batchCount)):                          #3

      

        noise = np.random.normal(0, 1, size=[batchSize, latent_dim]) #4

        imageBatch = X_train[np.random.randint(0, X_train.shape[0],size=batchSize)] #5



        

        generatedImages = generator.predict(noise)             #6

        X = np.concatenate([imageBatch, generatedImages])      #7



        yDis = np.zeros(2*batchSize)                           #8

        yDis[:batchSize] = 0.9 

        

        labelNoise = np.random.random(yDis.shape)              #9

        yDis += 0.05 * labelNoise + 0.05



        

        discriminator.trainable = True                         #10

        dloss = discriminator.train_on_batch(X, yDis)          #11



        

        noise = np.random.normal(0, 1, size=[batchSize, latent_dim]) #12

        yGen = np.ones(batchSize)                              #13

        discriminator.trainable = False                        #14

        gloss = gan.train_on_batch(noise, yGen)                #15



    dLosses.append(dloss)                                      #16

    gLosses.append(gloss)</pre></div><p>我们刚刚引入了很多代码。因此，让我们花一分钟时间来思考一下这16个关键步骤:</p><div><ol class="orderedlist arabic"><li class="listitem">我们必须编写一个定制的<a class="indexterm" id="id499"/>循环来遍历批处理。要知道有多少批，我们需要用数据集大小除以批大小。</li><li class="listitem">在外部循环中，我们迭代我们想要训练的历元数。</li><li class="listitem">在内部循环中，我们迭代每个时期中我们想要训练的批次数量。<code class="literal">tqdm</code>工具帮助我们跟踪批次内的进度。</li><li class="listitem">我们创建了一批随机潜在向量。</li><li class="listitem">我们随机抽取了一批真实的MNIST图像。</li><li class="listitem">我们用生成器生成一批假的MNIST图像。</li><li class="listitem">我们把真的和假的MNIST图像叠在一起。</li><li class="listitem">我们为我们的鉴别器创建目标。假图像用0编码，真图像用0.9编码。这种技术被称为软标签。代替硬标签(0和1)，我们使用一些更软的东西，以便不要过于激进地训练GAN。这种技术已经被证明可以使GAN训练更加稳定。</li><li class="listitem">在使用<a class="indexterm" id="id500"/>软标签的基础上，我们给标签添加了一些噪声。这将再次使训练更加稳定。</li><li class="listitem">我们确保鉴别器是可训练的。</li><li class="listitem">我们用一批真假数据训练鉴别器。</li><li class="listitem">我们创建一些更随机的潜在向量来训练生成器。</li><li class="listitem">发电机培训的目标始终是一个。我们希望鉴别器能给我们梯度，让假图像看起来像真图像。</li><li class="listitem">为了确保安全，我们将鉴别器设置为不可训练的，这样我们就不会意外破坏任何东西。</li><li class="listitem">我们训练GAN模型。我们输入一批随机潜在向量，并训练GAN的生成器部分，以便鉴别器部分将生成的图像分类为真实图像。</li><li class="listitem">我们节省了训练的损失。</li></ol></div><p>在下图中，您可以看到一些生成的MNIST字符:</p><div><img alt="A MNIST GAN" src="img/B10354_06_13.jpg"/><div><p>GAN生成的MNIST字符</p></div></div><p>这些字符中的大多数看起来像是可识别的数字，尽管有些，比如左下方和右下方的那些，看起来有点不对。</p><p>我们编写和探索的代码现在输出在下面的图表中，向我们展示了越来越多的纪元的区分和生成损失。</p><div><img alt="A MNIST GAN" src="img/B10354_06_14.jpg"/><div><p>甘训练进度</p></div></div><p>请注意，GAN <a class="indexterm" id="id502"/>训练中的损失是不可解释的，因为它是监督学习。即使GAN有所进展，GAN的损失也不会减少。</p><p>发生器和鉴别器的损耗取决于另一个模型的性能。如果发电机在愚弄鉴频器方面变得更好，那么鉴频器损耗将保持高水平。如果其中一个损失变为零，这意味着另一个模型输掉了比赛，不能再欺骗或正确区分另一个模型。</p><p>这也是GAN训练这么辛苦的原因之一:<strong>GAN不收敛到低损解</strong>；它们收敛到一个<em>均衡</em>，在这个均衡中，发生器不是一直愚弄鉴别器，而是很多次。这种平衡并不总是稳定的。标签和网络本身增加了如此多的噪声，部分原因是它增加了平衡的稳定性。</p><p>由于GAN不稳定且困难，但很有用，随着时间的推移，许多技巧被开发出来，使GAN训练更加稳定。了解这些技巧可以帮助你完成GAN <a class="indexterm" id="id503"/>构建过程，并节省你无数的时间，尽管这些技巧通常没有理论上的原因。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec86"/>了解GAN潜在传播媒介</h2></div></div></div><p>对于自动编码器，潜在的<a class="indexterm" id="id504"/>空间是PCA的一个相对简单的近似。VAEs创建了一个潜在的分布空间，这是有用的，但仍然很容易被看作是一种PCA形式。那么，如果我们只是在训练过程中从GAN中随机抽取样本，那么GAN的潜在空间是什么呢？事实证明，甘斯自我构建了潜在空间。使用GAN的潜在空间，你仍然可以通过显示的字符对MNIST图像进行聚类。</p><p>研究表明，GANs的潜在空间通常具有一些令人惊讶的特征，例如“微笑向量”，它根据人的微笑宽度排列面部图像。研究人员还表明，GANs可以用于潜在空间代数，其中添加不同对象的潜在表示可以创建现实的新对象。然而，对甘斯潜在空间的研究仍处于起步阶段，从潜在空间表征中得出关于世界的结论是一个活跃的研究领域。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec87"/>甘训练的招数</h2></div></div></div><p>甘人很难训练。它们可能会以多种不同的方式崩溃、分化或失败。研究人员和从业者已经想出了一些让GANs更好工作的技巧。虽然这看起来很奇怪，但不知道为什么会这样，但对我们来说重要的是它们在实践中有所帮助:</p><div><ul class="itemizedlist"><li class="listitem" style="list-style-type: disc"><strong>归一化输入</strong>:gan不适合极端值，所以确保你总是有介于-1和1之间的归一化输入。这也是为什么你应该使用双曲正切函数作为你的发电机输出。</li><li class="listitem" style="list-style-type: disc"><strong>Don't use the theoretical correct loss function</strong>: If you read papers on GANs, you will find that they give the generator optimization goal as the following formula:<div><img alt="GAN training tricks" src="img/B10354_06_044.jpg"/></div><p>在这个公式中，<em> D </em>是鉴频器输出。实际上，如果生成器的目标是这样的，效果会更好:</p><div><img alt="GAN training tricks" src="img/B10354_06_044-1.jpg"/></div><p>换句话说，与其最小化负鉴频器输出，不如最大化鉴频器输出。原因在于，在GAN训练过程的开始，第一目标通常具有消失梯度。</p></li><li class="listitem" style="list-style-type: disc"><strong>从正态高斯分布</strong>采样:从正态<a class="indexterm" id="id506"/>分布而不是均匀分布采样有两个原因。第一，GANs不太适合极值，正态分布的极值比均匀分布少。此外，已经证明，如果从正态分布中采样潜在向量，则潜在空间变成球体。这个球体中的潜在向量之间的关系比立方体空间中的潜在向量更容易描述。</li><li class="listitem" style="list-style-type: disc"><strong>使用批量标准化</strong>:我们已经看到，gan不适合极端值，因为它们非常脆弱。减少极值的另一种方法是使用批量标准化，正如我们在第3章、<em>中讨论的利用计算机视觉</em>。</li><li class="listitem" style="list-style-type: disc"><strong>对真实数据和虚假数据使用不同的批次</strong>:在这个过程的开始，真实数据和虚假数据可能有非常不同的分布。由于batch norm使用批次的平均值和标准偏差对批次进行标准化，因此最好将真实数据和虚假数据分开。虽然这确实会导致梯度估计的精确度稍低，但从更少的极值中获得的收益是很大的。</li><li class="listitem" style="list-style-type: disc"><strong>使用柔软且有噪音的标签</strong> : GANs易碎；软标签的使用降低了梯度并防止梯度翻转。给标签添加一些随机噪声也有助于稳定系统。</li><li class="listitem" style="list-style-type: disc"><strong>使用基本的GAN</strong>:现在有很多种GAN型号。他们中的许多人声称性能得到了极大的提高，但实际上，与简单的<strong>深度卷积生成对抗网络、</strong>或<strong> DCGAN </strong>相比，他们并没有工作得更好，甚至常常更差。这并不意味着它们没有存在的理由，但是对于大部分的任务来说，更基本的GANs会表现得更好。另一个工作良好的GAN是对抗性自动编码器，它通过在鉴别器的梯度上训练自动编码器，将VAE与GAN结合起来。</li><li class="listitem" style="list-style-type: disc"><strong>避免ReLU和MaxPool </strong> : ReLU激活和MaxPool层经常用于深度学习，但它们有产生“稀疏梯度”的缺点。对于负输入，ReLU激活将不具有任何梯度，对于不是最大输入的所有输入，MaxPool层将不具有任何梯度。因为梯度是生成器被训练的对象，稀疏梯度会损害生成器的训练。</li><li class="listitem" style="list-style-type: disc"><strong>使用Adam优化器</strong>:这个优化器已经被证明可以很好地处理GANs，而许多其他优化器却不能很好地处理它们。</li><li class="listitem" style="list-style-type: disc"><strong>Track failures early</strong>: Sometimes, GANs can fail for random reasons. Just choosing the "wrong" random seed could set your training run up for failure. Usually, it is possible to see whether a GAN goes completely off track by observing outputs. They should slowly become more like real data.<p>例如，如果生成器完全偏离轨道，只生成零，你将能够在<a class="indexterm" id="id507"/>花费数天的GPU时间进行无处可去的训练之前看到它。</p></li><li class="listitem" style="list-style-type: disc"><strong>不要通过统计平衡损耗</strong>:保持发生器和鉴别器之间的平衡是一项微妙的任务。因此，许多从业者试图通过根据统计对生成器或鉴别器进行更多的培训来帮助平衡。通常，这不起作用。GANs是非常违反直觉的，试图用直觉的方法帮助他们通常会使事情变得更糟。这并不是说没有办法帮助达到GAN平衡，但是这种帮助应该源于一种原则性的方法，例如“在发电机损耗高于<em> X </em>时训练发电机。”</li><li class="listitem" style="list-style-type: disc"><strong>如果你有标签，使用它们</strong>:一个稍微复杂一点的GAN鉴别器不仅可以将数据分类为真或假，还可以将数据分类。在MNIST的例子中，鉴别器有11个输出:10个实数的输出和一个伪数的输出。这使得我们可以创建一个可以显示更多特定图像的GAN。这在半监督学习领域很有用，我们将在下一节中介绍。</li><li class="listitem" style="list-style-type: disc"><strong>增加输入噪声，随时间降低噪声</strong>:噪声增加了GAN训练的稳定性，因此噪声输入有所帮助也就不足为奇了，尤其是在训练GAN的早期不稳定阶段。然而，后来，它可以混淆太多，并阻止GAN生成逼真的图像。因此，随着时间的推移，我们应该降低施加于输入端的噪声。</li><li class="listitem" style="list-style-type: disc"><strong>在训练和测试阶段都使用G中的漏失</strong>:一些研究人员发现在推理时间使用漏失会导致生成数据的更好结果。为什么会这样仍然是一个未解决的问题。</li><li class="listitem" style="list-style-type: disc"><strong>历史平均值</strong>:甘倾向于“摆动”，在训练中他们的体重在一个平均值附近快速移动。历史平均惩罚那些离历史平均值太远的权重，减少波动。因此，它增加了GAN训练的稳定性。</li><li class="listitem" style="list-style-type: disc"><strong>重放缓冲区</strong>:重放缓冲区保存了大量旧的生成图像，因此它们可以重新用于训练鉴别器。这与历史平均具有相似的效果，减少了振荡并增加了稳定性。它还减少了相关性和测试数据。</li><li class="listitem" style="list-style-type: disc"><strong>目标网络</strong>:另一个“反振荡”技巧是使用目标网络。也就是说，创建生成器和鉴别器的副本，然后用鉴别器的冻结副本训练生成器<a class="indexterm" id="id508"/>，用生成器的冻结副本训练鉴别器。</li><li class="listitem" style="list-style-type: disc"><strong>熵正则化</strong>:熵正则化是指奖励网络输出更多不同的值。这可以防止发生器网络决定产生几样东西，比如说，只产生数字7。这是一种正则化方法，因为它可以防止过度拟合。</li><li class="listitem" style="list-style-type: disc"><strong>使用漏失层或噪声层</strong>:噪声对GANs有好处。Keras不仅具有脱落层，而且还具有许多噪声层，这些噪声层向网络中的激活添加不同种类的噪声。您可以阅读这些层的文档，看看它们是否对您的特定GAN应用有所帮助:<a class="ulink" href="https://keras.io/layers/noise/">https://keras.io/layers/noise/</a>。</li></ul></div></div></div></body></html>
<html><head><title>Using less data – active learning</title><meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>

<meta content="urn:uuid:ee7bbf81-ee0c-427b-9574-49bd7094315d" name="Adept.expected.resource"/></head><body id="page"><div><div><div><div><h1 class="title"><a id="ch06lvl1sec87"/>使用更少的数据——主动学习</h1></div></div></div><p>无论是GANs还是VAEs，生成模型的部分动机总是让我们能够生成数据，因此需要更少的数据。由于数据天生稀少，尤其是在金融领域，而且我们永远也不会有足够的数据，生成模型似乎是经济学家警告我们的免费午餐。然而，即使是最好的GAN在没有数据的情况下也能工作。在这一节中，我们将看看使用尽可能少的数据来引导模型的不同<a class="indexterm" id="id509"/>方法。这种方法也被称为主动学习或半监督学习。</p><p><strong>无监督学习</strong>使用<a class="indexterm" id="id510"/>未标记数据以不同方式对数据进行聚类。一个例子是自动编码器，其中图像可以被转换成学习和潜在的向量，然后可以被聚类而不需要描述图像的标签。</p><p><strong>监督学习</strong>使用带标签的数据<a class="indexterm" id="id511"/>。一个例子是我们在<a class="link" href="ch03.html" title="Chapter 3. Utilizing Computer Vision">第3章</a>、<em>中利用计算机视觉、</em>或我们在本书中构建的大多数其他模型构建的图像分类器。</p><p><strong>半监督学习</strong>旨在<a class="indexterm" id="id512"/>执行通常由监督模型完成的任务，但手头的数据较少，并且使用非监督或生成方法。有三种方法可以做到这一点:首先，更聪明地利用人类；第二，通过更好地利用未标记的数据，第三，通过使用生成模型。</p><div><div><div><div><h2 class="title"><a id="ch06lvl2sec88"/>有效使用标签预算</h2></div></div></div><p>对于所有关于人工智能取代人类的讨论，需要大量的人类来训练人工智能系统。虽然数字不清楚，但可以肯定的是，亚马逊的MTurk服务上有50万到75万注册的“机械土耳其人”。</p><p>MTurk是一个亚马逊网站，根据它自己的网站，提供“通过API的人类智能”在实践中，这意味着公司和研究人员发布简单的工作，如填写调查问卷或对图像进行分类，世界各地的人都在执行这些任务，每项任务只收取几分钱。为了让AI学习，人类需要提供标记的数据。如果任务是大规模的，那么许多公司将雇用MTurk用户，以便让人类做标记。如果是小任务，你会经常发现公司自己的工作人员在标注数据。</p><p>令人惊讶的是，很少有人考虑这些人的标签。并非所有的标签都同样有用。下图显示了一个线性分类器。如您所见，靠近两个类之间边界的边界点决定了决策边界的位置，而后面的点则不相关:</p><div><img alt="Using labeling budgets efficiently" src="img/B10354_06_15.jpg"/><div><p>边境点更有价值</p></div></div><p>因此，边界点比远离决策边界的点更有价值。通过执行以下操作，可以使用较少的数据进行训练:</p><div><ol class="orderedlist arabic"><li class="listitem">仅标记一些图像</li><li class="listitem">训练弱模型</li><li class="listitem">让弱模型对一些未标记的图像进行预测</li><li class="listitem">标记模型最不确定的图像，并将它们添加到您的训练集中</li><li class="listitem">重复这个过程</li></ol></div><p>这种标注数据的过程比随机标注数据要有效得多，可以大大加快您的工作速度。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec89"/>利用机器进行人工标记</h2></div></div></div><p>在贴标方面，很多公司<a class="indexterm" id="id514"/>依赖微软Excel。他们让贴标签的人看着要贴标签的东西，比如一张图片或一段文字，然后那个人将标签输入Excel电子表格。虽然这非常低效且容易出错，但这是一种常见的做法。一些稍微高级一点的标记操作包括构建一些简单的web应用程序，让用户看到要标记的项目并直接单击标签或按热键。这可以大大加快贴标过程。然而，如果有大量的标签类别，这仍然不是最佳的。</p><p>另一种方法是再次标记一些图像并预训练弱模型。在贴标签的地方，计算机向贴标签机显示数据和标签。贴标签机只需要决定这个标签是否正确。这可以很容易地用热键来完成，而且标记一件商品所花的时间也大大减少了。如果标签是错误的，标签界面可以调出一个可能选项的列表，按照模型分配给它们的概率进行排序，或者只是将项目放回堆栈，并在下一次显示下一个最可能的标签。</p><p>这种技术的一个很好的实现是“Prodigy”，这是一个由spaCy公司开发的标记工具，我们在<a class="link" href="ch05.html" title="Chapter 5. Parsing Textual Data with Natural Language Processing">第5章</a>、<em>用自然语言处理解析文本数据</em>中了解过，我们可以在下面的截图中看到Prodigy工具的一个例子:</p><div><img alt="Leveraging machines for human labeling" src="img/B10354_06_16.jpg"/><div><p>Prodigy标签工具的屏幕截图</p></div></div><p>Prodigy是一个利用机器的标签<a class="indexterm" id="id515"/>工具，你可以通过阅读它的官方文档了解更多信息:<a class="ulink" href="https://prodi.gy/">https://prodi.gy/</a>。</p><div><div><h3 class="title"><a id="note27"/>注意</h3><p><strong>注</strong>:更好的用户界面设计和弱模型的智能实现，可以大大加快贴标的速度和质量。</p></div></div></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec90"/>未标记数据的伪标记</h2></div></div></div><p>通常有大量的<a class="indexterm" id="id516"/>未标记的数据可用，但是只有少量的数据已经被标记。未标记的数据仍然可以使用。首先，根据已有的标记数据训练一个模型。然后你让这个模型对你的未标注数据进行预测。您将这些预测视为真正的标注，并在完整的伪标注数据集上训练您的模型。然而，真正的真实标签应该比伪标签更常用。</p><p>伪标签的精确采样率<a class="indexterm" id="id517"/>可能因不同情况而异。这在误差是随机的条件下是可行的。如果他们有偏见，你的模型也会有偏见。这种简单的方法非常有效，可以大大减少标记工作。</p></div><div><div><div><div><h2 class="title"><a id="ch06lvl2sec91"/>使用生成模型</h2></div></div></div><p>事实证明，GANs <a class="indexterm" id="id518"/>很自然地延伸到半监督训练。通过给鉴别器两个输出，我们可以把它训练成一个分类器。</p><p><a class="indexterm" id="id519"/>鉴别器的第一个输出仅将数据分类为真或假，就像之前对GAN所做的那样。第二个输出按照类别对数据进行分类，例如，图像代表的数字，或者一个额外的“is fake”类别。在MNIST的例子中，分类输出将有11个类，10个数字加上“是假的”类。诀窍在于，生成器是一个模型，只有输出(即最后一层)是不同的。这迫使“真实与否”分类与“哪个数字”分类器共享权重。</p><p>这个想法是，为了确定一个图像是真是假，分类器必须弄清楚它是否能把这个图像归为一类。如果可以，图像很可能是真实的。这种方法被称为<strong>半监督生成对抗网络</strong> ( <strong> SGAN </strong>)，已经被证明能够<a class="indexterm" id="id520"/>生成更真实的数据，并在有限的数据上提供比标准监督学习更好的结果。当然，GANs不仅仅可以应用于图像。</p><p>在下一节中，我们将把它们应用到我们的欺诈检测任务中。</p></div></div></body></html>
<html><head><title>SGANs for fraud detection</title><meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>

<meta content="urn:uuid:ee7bbf81-ee0c-427b-9574-49bd7094315d" name="Adept.expected.resource"/></head><body id="page"><div><div><div><div><h1 class="title"><a id="ch06lvl1sec88"/>用于欺诈检测的SGANs</h1></div></div></div><p>作为本章最后应用的项目<a class="indexterm" id="id521"/>，我们再来<a class="indexterm" id="id522"/>考虑一下信用卡的问题。在本节中，我们将创建一个SGAN，如下所示:</p><div><img alt="SGANs for fraud detection" src="img/B10354_06_17.jpg"/><div><p>SGAN方案</p></div></div><p>我们将在不到1，000笔交易上训练这个<a class="indexterm" id="id523"/>模型，但仍然会得到一个不错的欺诈检测器。</p><div><div><h3 class="title"><a id="note28"/>注意</h3><p><strong>注</strong>:您可以在此链接下找到Kaggle上<a class="indexterm" id="id524"/> SGAN的代码:<a class="ulink" href="https://www.kaggle.com/jannesklaas/semi-supervised-gan-for-fraud-detection/code">https://www . ka ggle . com/jannesklaas/semi-supervised-gan-for-fraud-detection/code</a>。</p></div></div><p>在这种情况下，我们的数据有29个<a class="indexterm" id="id525"/>维度。我们设定我们的潜在向量有10个维度:</p><div><pre class="programlisting">latent_dim=10

data_dim=29</pre></div><p>生成器模型被构建为一个具有<code class="literal">LeakyReLU</code>激活和批量标准化的全连接网络。输出激活是一个<code class="literal">tanh</code>激活:</p><div><pre class="programlisting">model = Sequential()

model.add(Dense(16, input_dim=latent_dim))

model.add(LeakyReLU(alpha=0.2))

model.add(BatchNormalization(momentum=0.8))

model.add(Dense(32, input_dim=latent_dim))

model.add(LeakyReLU(alpha=0.2))

model.add(BatchNormalization(momentum=0.8))

model.add(Dense(data_dim,activation='tanh'))</pre></div><p>为了更好地使用生成器模型，我们将我们创建的模型包装到一个功能API模型中，该模型将noise <a class="indexterm" id="id526"/>向量映射到一个生成的事务记录。因为大多数甘文献都是关于图像的，而“交易记录”又有点拗口，所以我们就把我们的交易记录命名为“图像”:</p><div><pre class="programlisting">noise = Input(shape=(latent_dim,))

img = model(noise)

        

generator = Model(noise, img)</pre></div><p>正如我们对生成器所做的那样，我们在顺序API中构建鉴别器。鉴别器有两个输出:一个用于类别，一个用于假冒或不假冒。我们首先只构建模型的基础:</p><div><pre class="programlisting">model = Sequential()

model.add(Dense(31,input_dim=data_dim))

model.add(LeakyReLU(alpha=0.2))

model.add(BatchNormalization(momentum=0.8))

model.add(Dropout(0.25))

model.add(Dense(16,input_dim=data_dim))

model.add(LeakyReLU(alpha=0.2))</pre></div><p>现在，我们将使用函数式API将鉴别器的输入映射到它的两个头:</p><div><pre class="programlisting">img = Input(shape=(data_dim,))                               #1

features = model(img)                                        #2

valid = Dense(1, activation="sigmoid")(features)             #3

label = Dense(num_classes+1, activation="softmax")(features) #4



discriminator = Model(img, [valid, label])                   #5</pre></div><p>让我们花点时间来看看前面代码的五个关键方面:</p><div><ol class="orderedlist arabic"><li class="listitem">我们为噪声向量创建一个输入占位符</li><li class="listitem">我们从鉴别器基本模型中得到特征张量</li><li class="listitem">我们创建一个<code class="literal">Dense</code>层，用于将交易分类为真实或不真实，并将其映射到特征向量</li><li class="listitem">我们创建第二个<code class="literal">Dense</code>层，用于将交易分类为真实或虚假</li><li class="listitem">我们创建一个将输入映射到两个头的模型</li></ol></div><p>为了编译双头鉴别器，我们需要使用一些高级的模型编译技巧:</p><div><pre class="programlisting">

		optimizer = Adam(0.0002, 0.5) #1

		discriminator.compile(loss=['binary_crossentropy',

									'categorical_crossentropy'], #2

									loss_weights=[0.5, 0.5], #3

									optimizer=optimizer, #4

									metrics=['accuracy']) #5

</pre></div><p>分解这些代码，我们可以看到五个关键要素:</p><div><ol class="orderedlist arabic"><li class="listitem">我们定义一个<code class="literal">Adam</code>优化器，其学习速率为<code class="literal">0.0002</code>，动量为<code class="literal">0.5</code>。</li><li class="listitem">由于我们有两个模型头，我们可以指定两个损失。我们的真假头是一个二元分类器，所以我们用<code class="literal">binary_crossentropy</code>来表示它。我们的分类头是一个多级分类器，所以我们使用<code class="literal">categorical_crossentropy</code>作为第二个分类头。</li><li class="listitem">我们可以指定如何对两种不同的损失进行加权。在这种情况下，我们给所有损失50%的权重。</li><li class="listitem">我们优化我们预定义的<code class="literal">Adam</code>优化器。</li><li class="listitem">只要我们<a class="indexterm" id="id528"/>没有使用软标签，我们就可以使用准确性度量来跟踪进展。</li></ol></div><p>最后，我们<a class="indexterm" id="id529"/>创建我们的组合GAN模型:</p><div><pre class="programlisting">noise = Input(shape=(latent_dim,))               #1

img = generator(noise)                           #2

discriminator.trainable = False                  #3

valid,_ = discriminator(img)                     #4

combined = Model(noise , valid)                  #5

combined.compile(loss=['binary_crossentropy'],optimizer=optimizer)</pre></div><p>再次查看代码，我们可以看到以下要点:</p><div><ol class="orderedlist arabic"><li class="listitem">我们为噪声向量输入创建一个占位符。</li><li class="listitem">我们通过将生成器映射到噪声占位符来获得表示生成图像的张量。</li><li class="listitem">我们确保不会通过将鉴别器设置为不可训练来破坏它。</li><li class="listitem">我们只希望鉴别器相信生成的事务是真实的，因此我们可以丢弃分类输出张量。</li><li class="listitem">我们将噪声输入映射到鉴别器的“假或非假”输出。</li></ol></div><p>对于训练，我们定义了一个<code class="literal">train</code>函数，它为我们处理所有的训练:</p><div><pre class="programlisting">

	def train(X_train,y_train,

				X_test,y_test,

				generator,discriminator,

				combined,

				num_classes,

				epochs,

				batch_size=128):

    

    f1_progress = []                                             #1

    half_batch = int(batch_size / 2)                             #2



    cw1 = {0: 1, 1: 1}                                           #3

    cw2 = {i: num_classes / half_batch for i in range(num_classes)}

    cw2[num_classes] = 1 / half_batch



    for epoch in range(epochs):

      

        idx = np.random.randint(0, X_train.shape[0], half_batch) #4

        imgs = X_train[idx]



        noise = np.random.normal(0, 1, (half_batch, 10))         #5

        gen_imgs = generator.predict(noise)

        

        valid = np.ones((half_batch, 1))                           #6

        fake = np.zeros((half_batch, 1))

        

        labels = to_categorical(y_train[idx], num_classes=num_classes+1)                                         #7

        

        fake_labels = np.full((half_batch, 1),num_classes)         #8

        fake_labels = to_categorical(fake_labels,num_classes=num_classes+1)

        d_loss_real = discriminator.train_on_batch(imgs, [valid, labels],class_weight=[cw1, cw2])  #9

        d_loss_fake = discriminator.train_on_batch(gen_imgs, [fake, fake_labels],class_weight=[cw1, cw2])  #10

        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)            #11



        noise = np.random.normal(0, 1, (batch_size, 10))           #12

        validity = np.ones((batch_size, 1))

        g_loss = combined.train_on_batch(noise, validity, class_weight=[cw1, cw2]) #13



        print ("%d [D loss: %f] [G loss: %f]" % (epoch, g_loss))  #14

        

        if epoch % 10 == 0:                                       #15

            _,y_pred = discriminator.predict(X_test,batch_size=batch_size)

            y_pred = np.argmax(y_pred[:,:-1],axis=1)

            

            f1 = f1_score(y_test,y_pred)

            print('Epoch: {}, F1: {:.5f}'.format(epoch,f1))

            f1_progress.append(f1)

            

    return f1_progress</pre></div><p>暂停一分钟:这是一个非常长且复杂的函数代码。在总结本章之前，让我们先来看看该准则的15个关键要素:</p><div><ol class="orderedlist arabic"><li class="listitem">我们创建一个空数组来监控测试集上鉴别器的F1分数。</li><li class="listitem">由于我们对真实数据和虚假数据使用<a class="indexterm" id="id530"/>单独的批量训练步骤，我们实际上对每个训练步骤使用了半个批量。</li><li class="listitem">鉴别器的<a class="indexterm" id="id531"/>分类头有一个“这是假的”的分类标签由于一半的图像是假的，我们想给这个类一个更高的权重。</li><li class="listitem">我们现在抽取真实数据的随机样本。</li><li class="listitem">我们生成一些随机噪声向量，并使用生成器创建一些假数据。</li><li class="listitem">对于“假的还是假的”头像，我们创建标签。所有真实图像都有标签<code class="literal">1</code>(真实)，而所有虚假图像都有标签<code class="literal">0</code>(虚假)。</li><li class="listitem">我们对真实数据的标签进行一次性编码。通过指定我们的数据比它实际拥有的多一个类，我们为“is fake”类留出了空间。</li><li class="listitem">我们的假数据都被贴上了“是假的”标签。我们创建了这些标签的向量，并对它们进行一次性编码。</li><li class="listitem">首先，我们在真实数据上训练鉴别器。</li><li class="listitem">然后我们用假数据训练鉴别器。</li><li class="listitem">该时期鉴别器的总损失是真实和虚假数据损失的平均值。</li><li class="listitem">现在我们训练<a class="indexterm" id="id532"/>发电机。我们生成了一批噪声向量和一批标签，上面写着“这是真实数据”</li><li class="listitem">有了这些数据，我们就可以训练发电机。</li><li class="listitem">为了跟踪正在发生的事情，我们打印出进度。请记住，我们不希望损失下降；我们希望它们大致保持不变。如果发生器或鉴别器中的任何一个开始比另一个表现好得多，那么平衡就被打破了。</li><li class="listitem">最后，我们计算并输出使用鉴别器作为数据欺诈检测分类器的F1分数。这一次，我们只关心分类数据，丢弃“真假”头。我们根据最高值对交易进行分类，最高值不是分类器的“真实”类。</li></ol></div><p>现在我们已经设置好了一切，我们将训练我们的SGAN 5000个纪元。这在GPU上大约需要5分钟，但如果您没有GPU，可能需要更长时间:</p><div><pre class="programlisting">f1_p = train(X_res,y_res,X_test,y_test,generator,discriminator,combined,num_classes=2,epochs=5000, batch_size=128)</pre></div><p>最后，我们绘制半监督欺诈分类器随时间变化的F1分数:</p><div><pre class="programlisting">fig = plt.figure(figsize=(10,7))

plt.plot(f1_p)

plt.xlabel('10 Epochs')

plt.ylabel('F1 Score Validation')</pre></div><p>这将输出如下图所示:</p><div><img alt="SGANs for fraud detection" src="img/B10354_06_18.jpg"/><div><p>SGAN进展</p></div></div><p>正如你所看到的，模型<a class="indexterm" id="id533"/>一开始学得很快，但是随着F1分数变为零，它就崩溃了。这是GAN坍塌的典型例子。如前所述，gan是不稳定的。如果发生器和鉴别器之间的微妙平衡被打破，性能<a class="indexterm" id="id534"/>会迅速下降。</p><p>使GANs更稳定是一个活跃的研究领域。到目前为止，许多从业者只是试图尝试用不同的超参数和随机种子进行多次运行，以期获得好运。另一种流行的方法是每隔一段时间保存一次模型。该模型在150年左右似乎是一个相当不错的欺诈检测器，尽管在不到1000次交易中接受了训练。</p></div></body></html>
<html><head><title>Exercises</title><meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>

<meta content="urn:uuid:ee7bbf81-ee0c-427b-9574-49bd7094315d" name="Adept.expected.resource"/></head><body id="page"><div><div><div><div><h1 class="title"><a id="ch06lvl1sec89"/>练习题</h1></div></div></div><p>要更好地使用创成式模型，请尝试以下练习:</p><div><ol class="orderedlist arabic"><li class="listitem">创建SGAN以训练MNIST图像分类器。使用几幅图像就能达到90%以上的分类准确率？</li><li class="listitem">使用LSTMs，您可以为股票价格变动构建一个自动编码器。使用数据集，如DJIA股票价格，构建一个编码股票走势的自动编码器。然后想象当你穿过潜在空间时，输出会发生什么。可以在这里找到数据集:<a class="ulink" href="https://www.kaggle.com/szrlee/stock-time-series-20050101-to-20171231">https://www . ka ggle . com/szrlee/stock-time-series-2005 01 01-to-2017 12 31</a>。</li></ol></div></div></body></html>
<html><head><title>Summary</title><meta content="DocBook XSL Stylesheets V1.75.2" name="generator"/>

<meta content="urn:uuid:ee7bbf81-ee0c-427b-9574-49bd7094315d" name="Adept.expected.resource"/></head><body id="page"><div><div><div><div><h1 class="title"><a id="ch06lvl1sec90"/>总结</h1></div></div></div><p>在这一章中，你已经学习了两种最重要的生成模型:自动编码器和GANs。我们首先为MNIST图像开发了一个自动编码器。然后，我们使用类似的架构来编码信用卡数据和检测欺诈。之后，我们将自动编码器扩展为VAE。这使我们能够了解编码的分布，并生成可用于训练的新数据。</p><p>后来，我们又了解了甘斯，首先是在MNIST图像的背景下，然后是在信用卡欺诈的背景下。我们使用SGAN来减少训练欺诈检测器所需的数据量。我们使用模型输出，通过主动学习和更智能的标签界面来减少必要的标签数量。</p><p>我们还讨论并了解了潜在空间及其在财务分析中的用途。我们看到了t-SNE算法，以及如何使用它来可视化更高维度(潜在的)数据。你也对机器学习如何解决博弈论优化问题有了第一印象。gan解决了一个极大极小问题，这个问题在经济学和金融学中经常出现。</p><p>在下一章中，我们将在讨论强化学习时深入探讨这种类型的优化。</p></div></body></html></body></html>