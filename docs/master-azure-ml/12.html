<html><head/><body>


    
        <title>Distributed Machine Learning on Azure ML Clusters</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">Azure ML集群上的分布式机器学习</h1>
                
            
            
                
<p>在前一章中，我们通过使用HyperDrive和AutoML进行搜索和优化，了解了超参数调整，这是超参数优化的一个特例，涉及特征工程、模型选择和模型堆叠。AutoML是<strong>机器学习即服务</strong> ( <strong> MLaaS </strong>)，其中唯一的输入是你的数据、一个ML任务和一个错误度量。很难想象在一台机器或一个CPU/GPU上运行AutoML的所有实验和参数组合——我们正在寻找通过并行化和分布式计算来加快训练过程的方法。</p>
<p>在这一章中，我们将研究分布式和并行计算的算法和框架，以便有效地并行训练ML模型。本章的目标是在Azure中构建一个环境，在这个环境中，您可以通过向您的训练环境添加更多的机器来加速经典ML和<strong>深度学习(DL) </strong>模型的训练过程，从而扩展集群。</p>
<p>首先，我们将看看分布式ML的不同方法和基本构件。您将了解并行训练独立模型(如在HyperDrive和AutoML中所做的)与通过划分训练数据并行训练大型数据集上的单个模型集合之间的区别。然后，我们将研究单个模型的分布式ML，并发现数据分布和模型分布的训练方法。这两种方法通常用于现实世界场景中，以加速或支持大型<strong>深度神经网络</strong> ( <strong> DNNs </strong>)的训练。</p>
<p>之后，我们将发现最流行的分布式ML框架，以及它们如何在Azure中使用以及如何与Azure ML compute结合使用。执行引擎、通信库和分布式ML库的功能之间的转换是平滑的，但通常难以理解。不过，读完这一章，你就会明白在Databricks中用MLlib运行Apache Spark和使用Horovod、Gloo、PyTorch、TensorFlow参数服务器的区别了。</p>
<p>在最后一节，我们将看看两个实际例子，如何实现我们将在Azure中讨论的功能，并将其与Azure ML compute集成。</p>
<p>本章涵盖以下主题:</p>
<ul>
<li>探索分布式ML的方法</li>
<li>在Azure中使用分布式ML</li>
</ul>


            

            
        
    






    
        <title>Exploring methods for distributed ML</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">探索分布式ML的方法</h1>
                
            
            
                
<p>对于许多用户来说，实现ML管道的过程是非常相似的，并且通常与前面章节中描述的步骤相似。当用户开始从实验切换到真实世界的数据，或者从小的例子切换到更大的模型时，他们经常会遇到类似的问题:在大量数据上训练大型参数模型——尤其是DL模型——需要非常长的时间。有时候，时代持续几个小时，而训练需要几天才能融合。</p>
<p>对于许多工程师来说，等待模型收敛的数小时甚至数天意味着宝贵的时间浪费，因为这使得交互式调整训练过程变得更加困难。因此，许多ML工程师需要通过利用各种分布式计算技术来加速他们的培训过程。分布式ML的想法就像通过增加更多的计算资源来加速训练过程一样简单。在最好的情况下，通过向训练集群添加更多的机器(横向扩展),训练性能线性提高。在这一节中，我们将看看最常见的分布式ML模式，并尝试理解和推理它们。在本章的下一节，我们还将把它们应用到一些真实世界的例子中。</p>
<p>一旦数据或模型变大，大多数现代ML管道使用本章讨论的一些技术来加速训练过程。这类似于一旦数据变大，就需要大数据平台(如Spark、Hive等)进行数据预处理。因此，尽管这一章看起来过于复杂，我还是建议你在等待你的模型收敛或者想要更快产生更好的结果的任何时候重温这一章。</p>
<p>通常有三种利用ML分布式计算的模式:</p>
<ul>
<li>并行训练独立模型</li>
<li>在数据的不同子集上并行训练模型的副本</li>
<li>并行训练同一模型的不同部分</li>
</ul>
<p>让我们来看看这些方法。</p>


            

            
        
    






    
        <title>Training independent models on small data in parallel</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">并行训练小数据上的独立模型</h1>
                
            
            
                
<p>我们将首先看最简单的例子，在(小)数据集上训练(小)独立模型。这种并行训练的典型用例是执行超参数搜索或经典ML模型或小型神经网络的优化。这与我们在上一章中讨论的内容非常相似。甚至AutoML——训练和比较多个独立的模型——也在幕后使用这种方法。在并行训练中，我们的目标是通过并行训练这些模型来加速具有不同参数的多个独立模型的训练。</p>
<p>下图显示了这种情况，我们不是在单台计算机上按顺序训练各个模型，而是并行训练它们:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1020 image-border" src="img/12d8bc89-7156-4024-a633-f97ad7347be1.png" style="width:34.67em;height:15.67em;"/></p>
<p>您可以看到，在各个模型的训练过程中，不需要通信或同步。这意味着我们既可以在同一台机器上的多个CPU/GPU上训练，也可以在多台机器上训练。</p>
<p>当使用Azure ML进行超参数调优时，这种并行化很容易实现，只需配置一个具有多个节点的Azure ML计算目标，并通过HyperDrive配置的<kbd>max_concurrent_runs</kbd>参数选择并发运行的数量。在Azure ML HyperDrive中，只需指定一个估计器和<kbd>param_sampling</kbd>，并提交HyperDrive配置作为实验，以便并行运行单个任务，如下所示:</p>
<pre>from azureml.train.hyperdrive import HyperDriveConfig<br/>hyperdrive_run_config = HyperDriveConfig(estimator=estimator,<br/>    hyperparameter_sampling=param_sampling, <br/>    primary_metric_name="accuracy", <br/>    primary_metric_goal=PrimaryMetricGoal.MAXIMIZE,<br/>    max_total_runs=100,<br/>    max_concurrent_runs=4)<br/><br/>from azureml.core.experiment import Experiment<br/>experiment = Experiment(workspace, experiment_name)<br/>hyperdrive_run = experiment.submit(hyperdrive_run_config)</pre>
<p>以下是一些计算超空间驱动或任何其他分布式计算设置的<kbd>max_concurrent_runs</kbd>值的公式:</p>
<ul>
<li class="CDPAlignLeft CDPAlign">对于基于CPU的训练，如果每个节点都有足够的内存来存储训练数据和模型参数，我们可以同时训练至少<em> N <sub>个总共</sub>T7】个模型，使用以下等式:</em></li>
</ul>
<p class="CDPAlignLeft CDPAlign"><img class="aligncenter size-full wp-image-1139 image-border" src="img/03009d3c-1497-4fe5-add0-6ece1edede2e.png" style="width:36.67em;height:8.92em;"/></p>
<ul>
<li>对于基于GPU的训练，假设每个节点都有足够的可用GPU内存，则并发模型的数量<em> N <sub> total </sub> </em>以相同的方式计算:</li>
</ul>
<p class="CDPAlignLeft CDPAlign"><img class="aligncenter size-full wp-image-1140 image-border" src="img/8a9e660c-128f-4c0e-b8b9-fad41a5d4993.png" style="width:37.67em;height:9.17em;"/></p>
<p>以下是如何估计单个模型将消耗多少内存的指南:</p>
<ul>
<li>单个参数的大小:</li>
<li style="padding-left: 30px"><strong>半精度浮点型</strong> : 16位(2字节)</li>
<li style="padding-left: 30px"><strong>单精度浮点型</strong> : 32位(4字节)——这通常是默认值</li>
<li style="padding-left: 30px"><strong>双精度浮点型</strong> : 64位(8字节)</li>
</ul>
<ul>
<li>模型所需的参数数量:</li>
<li style="padding-left: 30px"><strong>参数化</strong> <strong>模型</strong> : <em>所有参数的总和</em></li>
<li style="padding-left: 30px"><strong>非参数模型</strong> : <em>表示的数量(例如决策树)*表示的参数数量</em></li>
<li>然后乘以其他因素:</li>
<li style="padding-left: 30px"><strong>采用反向传播的型号</strong> : <em>总内存* 2 </em></li>
<li style="padding-left: 30px"><strong>使用批处理的型号</strong> : <em>总内存*批处理大小</em></li>
<li style="padding-left: 30px"><strong>模型使用</strong> ( <strong>递归</strong> ) <strong>状态</strong> : <em>每状态内存*递归步数</em></li>
</ul>
<p>虽然这个用例看起来非常相似，但让我们继续下一个用例，在这个用例中，我们有一个无法复制到每台机器上的大型数据集。</p>


            

            
        
    






    
        <title>Training a model ensemble on large datasets in parallel</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">在大数据集上并行训练模型集成</h1>
                
            
            
                
<p>接下来我们将讨论ML中一个非常常见的优化，尤其是在大型数据集上训练模型时。为了训练模型，我们通常需要大量的数据，而这些数据很少能全部放入单台机器的内存中。因此，通常需要将数据分割成块，并在不同的块上训练多个单独的模型。</p>
<p>下图显示了将数据拆分为较小块的两种方法，即水平拆分行(左)或垂直拆分列(右):</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1021 image-border" src="img/a3f52103-2607-445c-b9fb-1951f001d8c8.png" style="width:63.08em;height:15.92em;"/></p>
<p>您还可以混合使用这两种技术，从训练数据中提取一个子集。每当您使用MapReduce、Hive或Spark等大数据领域的工具时，对数据进行分区将有助于您加快训练过程，或者首先支持对大量数据进行训练。</p>
<p>执行数据分布式训练的一个很好的例子是训练完全独立的决策树模型的大规模树集合，也称为<strong>随机</strong> <strong>森林</strong>。通过将数据分成成千上万个随机块，您可以为每个数据块训练一个决策树，并将所有训练好的树组合成一个集成模型。Apache Hivemall是一个基于Hive和Spark的库，它在这两个执行引擎中的任何一个上都可以做到这一点。下面是一个使用HiveQL和Apache Hivemall在Hive上训练多个XGBoost多类集成模型的例子:</p>
<pre>-- explicitly use 3 reducers<br/>-- set mapred.reduce.tasks=3;<br/><br/>create table xgb_softmax_model as<br/>select <br/>  train_xgboost(features, label, <br/>    '-objective multi:softmax -num_class 10 -num_round 10') <br/>    as (model_id, model)<br/>from (<br/>  select features, (label - 1) as label<br/>  from data_train<br/>  cluster by rand(43) -- shuffle data to reducers<br/>) data;</pre>
<p>在前面的函数中，我们使用<kbd>cluster</kbd>关键字将数据行随机移动到reducers。这将对数据进行水平分区，并为每个reducer上的每个分区训练一个XGBoost模型。通过定义缩减器的数量，我们还定义了并行训练的模型的数量。生成的模型存储在一个表中，其中每一行定义一个模型的参数。在预测中，我们将简单地组合所有单个模型，并执行平均投票标准来检索最终结果。</p>
<p>这种方法的另一个例子是在垂直和水平数据分区上训练多个独立模型的标准Spark管道。当我们完成对单个模型的训练后，我们可以在推理过程中使用平均投票标准来找到预测任务的最佳结果。下面是一个使用Python、PySpark和scikit-learn在水平分区数据上并行训练多个模型的小示例脚本:</p>
<pre># read the input data<br/>df = spark.read.parquet("data/")<br/><br/># define your training function<br/>from sklearn.ensemble import RandomForestClassifier<br/>def train_model(data):<br/>   clf = RandomForestClassifier(n_estimators=10)<br/>   return clf.fit(data['train_x'], data['train_y'])<br/><br/># split your data into partitions and train models<br/>num_models = 100<br/>models = df.rdd.repartition(num_models)<br/>  .mapPartitions(train_model)<br/>  .collect()</pre>
<p>在前面的函数中，我们现在可以加载几乎任何数量的数据，并对其进行重新分区，以便每个分区都适合单个节点的本地内存。如果我们有1 TB的训练数据，我们可以将它分成100个10 GB数据块的分区，分布在10个12核工作节点上，每个节点有128 GB RAM。并行训练100个模型的训练时间最多需要几秒钟。一旦所有的模型都训练好了，我们使用<kbd>collect()</kbd>函数将所有训练好的模型返回给头节点。</p>
<p>我们还可以决定将来自每个个体工作者的模型存储到磁盘或分布式文件系统中，但是将结果组合到单个节点上可能更好。你看，在这个例子中，我们有选择两种方法中任何一种的自由，因为所有的模型都是相互独立的。对于模型突然相互依赖的情况，这是不正确的，例如，当最小化全局梯度时，或者在多台机器上分割单个模型时，这两种情况都是以相同方式训练dnn时的常见用例。在这种情况下，我们需要一些新的操作符来控制数据和梯度的控制流。让我们在下一节研究这些操作符。</p>


            

            
        
    






    
        <title>Fundamental building blocks for distributed ML</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">分布式ML的基本构件</h1>
                
            
            
                
<p>正如我们在前面的例子中看到的，我们需要一些基本的构建块或操作符来管理分布式系统中的数据流。我们把这些算子<strong>统称为</strong> <strong>算法</strong>。这些算法实现了分布式计算的通用同步和通信模式，并且在训练ML模型时是必需的。在我们开始学习DNNs的分布式训练方法之前，我们将快速浏览一下这些模式以理解其基础。</p>
<p>分布式系统中最常见的通信模式如下:</p>
<ul>
<li>一对一</li>
<li>一对多(也叫<em>播</em>或<em>散</em></li>
<li>多对一(也称<em>减少</em>或<em>聚集</em></li>
<li>多对多(也称<em>全减</em>或<em>全聚</em></li>
</ul>
<p>下图很好地概述了这些模式，并显示了数据如何在系统的各个参与者之间流动:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1022 image-border" src="img/4ac4c3c3-1a7c-4254-8c61-8f00b8eb6cf5.png" style="width:24.25em;height:7.25em;"/></p>
<p>我们可以马上回想起贝叶斯优化的超参数优化技术。首先，我们需要从主节点向所有工作节点广播训练数据。然后，我们可以从主节点的参数空间中选择参数组合，<strong>也可以将这些参数组合广播给工作节点。最后，我们在工作者节点上执行训练，然后<strong>从主节点上的工作者节点收集</strong>所有模型验证分数。通过比较分数并应用贝叶斯定理，我们可以预测下一个可能的参数组合，并重复<strong>将它们广播</strong>到工作节点。</strong></p>
<p>你注意到前面算法中的一些东西了吗？我们如何知道所有工作节点都完成了训练过程，并且我们收集了所有工作节点的所有分数？为此，我们将使用另一个构建模块，称为<strong>同步</strong>，或<strong>屏障</strong> <strong>同步</strong>。使用屏障同步，我们可以调度任务的执行，使其需要等待所有其他分布式任务完成。下图很好地概括了多处理器中的同步模式:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1023 image-border" src="img/e0369a65-2060-4c5a-8801-99ab7fc5aac5.png" style="width:45.83em;height:16.50em;"/></p>
<p>正如你所看到的，我们在前一章已经隐含地使用了这些算法，它们隐藏在术语<strong>优化</strong>之后。现在我们将通过改变优化器来明确地使用它们，以便在多台机器上训练单个模型。</p>
<p>正如您可能已经意识到的，这些模式并不新，每秒钟都会被您的操作系统使用多次。然而，在这种情况下，我们可以利用这些模式，并通过专门的硬件(例如，通过使用InfiniBand将两个GPU连接在一起)将它们应用于分布式训练过程的执行图。</p>
<p>为了在不同级别的硬件支持(GPU支持和矢量化)下使用这种集体算法，您需要选择一个通信后端。这些后端是库，通常作为单独的进程运行，并实现通信和同步模式。流行的集体算法库包括Gloo、MPI和NCCL。</p>
<p>大多数DL框架，如PyTorch或TensorFlow，都在这些通信后端之一上提供了自己的高级抽象，例如PyTorch RPC和TensorFlow参数服务器。除了使用不同的执行和通信框架，您还可以选择一个通用的分布式计算框架，比如Spark。</p>
<p>如您所见，可能的选择列表是无穷无尽的，并且可能有多种组合。我们甚至还没有谈到Horovod，这是一个用于通过分布式优化器将分布式训练添加到其他DL框架中的框架。好的一面是，这些框架和库大部分都在所有Azure ML运行时中提供，并通过Azure ML SDK得到支持。这意味着您通常只需指定所需的后端，将您的模型提供给任何特定的框架，并让Azure ML处理这些工具的设置、初始化和管理。我们将在本章的后半部分看到这一点。</p>


            

            
        
    






    
        <title>Speeding up DL with data-parallel training</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">利用数据并行训练加速数据挖掘</h1>
                
            
            
                
<p>分布式数据并行训练的另一种变体在DL中非常常见。为了加速更大模型的训练，我们可以在同一模型的分布式副本上使用不同的数据块运行多次训练迭代。当每个训练迭代花费大量时间(例如，几秒钟)时，这一点尤其重要，这是训练大型dnn的典型场景，我们希望利用多GPU环境。</p>
<p>DL的数据分布式训练基于使用分布式梯度下降算法的思想:</p>
<ol>
<li>将模型的副本分发给每个节点。</li>
<li>将数据块分发到每个节点。</li>
</ol>
<ol start="3">
<li>在每个节点上对网络进行全面检查，并计算梯度。</li>
<li>收集单个节点上的所有梯度，并计算平均梯度。</li>
<li>将平均渐变发送到所有节点。</li>
<li>使用平均梯度更新所有模型。</li>
</ol>
<p>下图显示了多个模型的实际情况，分别运行向前/向后传递，并将梯度发送回参数服务器:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1024 image-border" src="img/81f4e4b4-3565-42a0-bbf1-f17e4f883858.png" style="width:33.67em;height:22.50em;"/></p>
<p>如此处所示，服务器计算平均梯度，并将其发送回所有其他节点。我们可以立即看到，突然之间，工作者节点和主节点(让我们称之为参数服务器)之间需要通信，并且在等待所有模型完成梯度计算时也需要同步。</p>
<p>这种用例的一个很好的例子是通过并行化反向传播步骤并将来自每个节点的梯度组合成总梯度来加速DL模型的训练过程。TensorFlow目前使用所谓的<strong>参数</strong> <strong>服务器</strong>支持这种分发模式。在优步开发的Horovod框架为分布式优化器提供了方便的抽象，并插入到许多可用的ML框架或分布式执行引擎中，如TensorFlow、PyTorch和Apache Spark。在<em>Horovod——分布式DL培训框架</em>一节中，我们将看看使用horo VOD和Azure ML的实际例子。</p>


            

            
        
    






    
        <title>Training large models with model-parallel training</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">使用模型并行训练来训练大型模型</h1>
                
            
            
                
<p>最后，DL中的另一个常见用例是训练比单个GPU提供的GPU内存更大的模型。这种方法有点棘手，因为它需要在不同的GPU甚至不同的机器之间分割模型执行图。虽然这在基于CPU的执行中不是一个大问题，并且经常在Spark、Hive或TensorFlow中完成，但我们还需要在多个GPU内存之间传输中间结果。为了有效地做到这一点，需要额外的硬件和驱动程序，如InfiniBand (GPU到GPU通信)和GPUDirect(高效GPU内存访问)。</p>
<p>下图显示了并行计算多个梯度(左侧)和计算分布式模型的单个正向传递(右侧)之间的差异:</p>
<p class="CDPAlignCenter CDPAlign"><img class="aligncenter size-full wp-image-1025 image-border" src="img/b435dfc5-12ec-4f6b-b421-bc17c2f3d29d.png" style="width:57.67em;height:21.33em;"/></p>
<p>后者要复杂得多，因为数据必须在多个GPU和/或多个节点之间来回传递。</p>
<p>一般来说，我们选择两种场景:单机多GPU训练和多机多GPU训练。如您所料，后者要困难得多，因为它需要网络上多台机器之间的通信和同步。</p>
<p class="mce-root"/>
<p>下面是一个使用PyTorch在多个GPU上训练一个小模型的简单Python脚本:</p>
<pre>import torch<br/>import torch.nn as nn<br/>import torch.optim as optim<br/><br/>class ParallelModel(nn.Module):<br/>    def __init__(self):<br/>        super(ParallelModel, self).__init__()<br/>        self.net1 = torch.nn.Linear(10, 10).to('cuda:0')<br/>        self.relu = torch.nn.ReLU()<br/>        self.net2 = torch.nn.Linear(10, 5).to('cuda:1')<br/><br/>    def forward(self, x):<br/>        x = self.relu(self.net1(x.to('cuda:0')))<br/>        return self.net2(x.to('cuda:1'))<br/><br/>model = ParallelModel()<br/>loss_fn = nn.MSELoss()<br/>optimizer = optim.SGD(model.parameters(), lr=0.001)<br/><br/>optimizer.zero_grad()<br/>outputs = model(torch.randn(20, 10))<br/>labels = torch.randn(20, 5).to('cuda:1')<br/>loss_fn(outputs, labels).backward()<br/>optimizer.step()</pre>
<p>正如您所看到的，我们现在将各个层拆分为在多个GPU上运行，而这些层之间的数据需要在向前和向后传递期间进行传输。我们在前面的代码示例中观察到，我们现在将代码更改应用到模型本身，以便指定模型的哪些部分应该在哪个GPU上运行。</p>
<p>请注意，我们也可以使这种分割动态化，例如我们将模型分割成在<em>x</em>GPU上执行的<em> x </em>个连续子图。</p>
<p>有趣的是，本章中讨论的许多技术可以结合起来。例如，我们可以在每台机器上训练一个多GPU模型，同时将数据划分为块，并在多台机器上计算梯度的多个部分——因此采用了数据分布式模型并行方法。</p>


            

            
        
    






    
        <title>Using distributed ML in Azure</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">在Azure中使用分布式ML</h1>
                
            
            
                
<p><em>探索分布式ML的方法</em>部分包含了大量不同的并行化场景、集体算法的各种通信后端，以及使用不同ML框架甚至执行引擎的代码示例。当谈到ML框架时，选择的数量相当大，做出明智的决定并不容易。当Azure ML支持一些现成的框架，而其他框架必须由用户安装、配置和管理时，这种选择变得更加复杂。</p>
<p>在这一部分，我们将经历最常见的场景，学习如何选择正确的框架组合，并在Azure中实现分布式ML管道。</p>
<p>一般来说，在Azure中运行分布式ML有三种选择:</p>
<ul>
<li>第一个显而易见的选择是使用Azure ML、笔记本环境、Azure ML SDK和Azure ML计算集群。对于许多复杂的用例来说，这将是最简单的解决方案。巨大的数据集可以存储在Azure Blob存储上，模型可以被训练成具有不同通信后端的数据并行和/或模型并行模型。通过用评估者抽象来包装你的训练脚本，一切都被管理了。</li>
<li>第二种选择是为您的代码使用不同的创作和执行引擎，而不是Azure ML笔记本和Azure ML计算集群。一个流行的选择是Azure Databricks，它集成了交互式笔记本和Apache Spark作为分布式执行引擎。使用Databricks，您可以使用预先构建的ML图像和自动缩放集群，这为运行分布式ML培训提供了一个很好的环境。</li>
<li>第三种选择是构建并推出您自己的定制解决方案。为此，您需要用虚拟机或Kubernetes构建一个单独的集群，并协调基础设施和代码的设置、安装和管理。虽然这是最灵活的解决方案，但它也是迄今为止设置起来最复杂、最耗时的。对于这本书，在深入研究Azure ML之前，我们将首先研究Horovod优化器、Azure Databricks和Apache Spark。</li>
</ul>


            

            
        
    






    
        <title>Horovod—a distributed DL training framework</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">horo VOD——一个分布式DL培训框架</h1>
                
            
            
                
<p>Horovod是一个支持分布式DL的框架，最初由优步开发并开源。它为以下受支持的框架提供了一种统一的方式来支持现有DL训练代码的分布式训练——tensor flow、Keras、PyTorch和Apache MXNet。设计目标是使任何现有项目从单节点训练到数据并行训练的过渡变得极其简单，从而使这些模型能够在分布式环境中的多个GPU上更快地训练。</p>
<p>在任何支持数据并行训练的框架中，Horovod作为优化器的替代物是一个很好的选择。通过简单地从DL代码中抽象出GPU，它可以通过初始化和更新步骤或更新挂钩与支持的框架很好地集成。从用户的角度来看，只需做最少的代码更改就可以支持模型的数据并行训练。让我们看一个使用Keras的例子，并实现以下步骤:</p>
<ol>
<li>初始化Horovod。</li>
<li>配置Keras从Horovod读取GPU信息。</li>
<li>加载模型并拆分培训数据。</li>
<li>将Keras优化器包装成Horovod分布式优化器。</li>
<li>实施模型训练。</li>
<li>使用<kbd>horovodrun</kbd>执行脚本。</li>
</ol>
<p>具体步骤如下:</p>
<ol>
<li>对于任何使用Horovod的脚本来说，第一步都非常相似——我们首先需要从正确的包中加载<kbd>horovod</kbd>并初始化它:</li>
</ol>
<pre style="padding-left: 60px">import horovod.keras as hvd<br/>hvd.init()</pre>
<ol start="2">
<li>接下来，我们需要执行一个定制的设置步骤，这取决于所使用的框架。这一步将为框架设置GPU配置，并确保它可以通过Horovod调用抽象版本:</li>
</ol>
<pre style="padding-left: 60px">from keras import backend as K<br/>import tensorflow as tf<br/><br/># pin GPU to be used to process local rank (one GPU per process)<br/>config = tf.ConfigProto()<br/>config.gpu_options.allow_growth = True<br/>config.gpu_options.visible_device_list = str(hvd.local_rank())<br/>K.set_session(tf.Session(config=config))</pre>
<ol start="3">
<li class="mce-root">现在，我们可以简单地采用我们的单节点、单GPU Keras模型，并定义所有参数、训练和验证数据。在此步骤中没有任何特殊要求:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># standard model and data<br/>batch_size = 10<br/>epochs = 100<br/>model = load_model(...)<br/>x_train, y_train = load_train_data(...)<br/>x_test, y_test = load_test_data(...)</pre>
<ol start="4">
<li>最后，我们到达了神奇的部分，在这里我们将框架优化器——在这里是来自Keras的<kbd>Adadelta</kbd>——包装成一个Horovod分布式优化器。对于所有后续代码，我们将简单地使用分布式优化器，而不是普通的优化器。我们还需要根据使用的GPU数量来调整学习速率，因为最终的梯度将是单个变化的平均值。这可以使用以下代码来完成:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root"># adjust learning rate based on number of GPUs<br/>opt = keras.optimizers.Adadelta(1.0 * hvd.size())<br/><br/># add Horovod Distributed Optimizer<br/>opt = hvd.DistributedOptimizer(opt)</pre>
<ol start="5">
<li class="mce-root">剩下的部分看起来相当简单。它涉及到编译模型、拟合模型和评估模型，就像单节点的对应部分一样。值得一提的是，我们需要添加一个回调来初始化训练过程中的所有渐变:</li>
</ol>
<pre style="padding-left: 60px" class="mce-root">model.compile(loss=keras.losses.categorical_crossentropy,<br/>    optimizer=opt, <br/>      metrics=['accuracy'])<br/>callbacks = [<br/>    hvd.callbacks.BroadcastGlobalVariablesCallback(0),<br/>]<br/>model.fit(x_train, y_train,<br/>    batch_size=batch_size,<br/>    callbacks=callbacks,<br/>    epochs=epochs,<br/>    verbose=1 if hvd.rank() == 0 else 0,<br/>    validation_data=(x_test, y_test))<br/>score = model.evaluate(x_test, y_test)<br/>print('Test loss:', score[0])<br/>print('Test accuracy:', score[1])</pre>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p class="mceNonEditable"/>
<p>当查看前面的代码时，公平地说，Horovod在使用数据并行方法和分布式梯度计算轻松扩展分布式执行代码方面并没有过分乐观。如果您研究过本机TensorFlow或PyTorch版本，您会发现这需要的代码更改要少得多，并且比参数服务器或RPC框架更具可读性和可移植性。</p>
<p>Horovod框架使用MPI通信后端来处理幕后的集体算法，并且通常需要每个节点的每个GPU运行一个进程。然而，它也可以通过配置选项在Gloo后端或自定义MPI后端上运行。下面是如何使用<kbd>horovodrun</kbd>命令在两台机器<kbd>server1</kbd>和<kbd>server2</kbd>上启动训练过程的示例片段，每台机器使用四个独立的GPU:</p>
<pre><strong>$ horovodrun -np 8 -H server1:4,server2:4 python train.py</strong></pre>
<p>当您只想通过扩展集群来加快训练进度时，在您自己的集群上运行和调试Horovod仍然会很痛苦。因此，Azure ML compute提供了一个为您完成所有繁重工作的包装器，只需要一个带有Horovod注释的训练脚本。我们将在<em>在Azure ML计算上运行horo VOD</em>部分看到这一点。</p>
<p>通过使用底层框架的模型并行特性，并且每台机器只使用一个Horovod进程而不是每块GPU，模型并行训练可以与Horovod相结合。但是，这是一个自定义配置，目前在Azure ML中不支持。</p>


            

            
        
    






    
        <title>Implementing the HorovodRunner API for a Spark job</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">为Spark作业实现HorovodRunner API</h1>
                
            
            
                
<p>在许多公司中，ML是现有数据管道之上的附加数据处理步骤。因此，如果你有大量的数据，并且你已经在管理Spark集群或者使用Azure Databricks来处理这些数据，那么也很容易添加分布式培训功能。</p>
<p>正如我们在本章的<em>探索分布式ML的方法</em>一节中所看到的，我们可以使用并行化或者通过划分训练数据来简单地训练多个模型。然而，我们也可以训练DL模型，并受益于分布式ML技术来加速训练过程。</p>
<p>当使用Databricks ML运行时，您可以利用Horovod for Spark来分发您的培训过程。该功能可通过<kbd>HorovodRunner</kbd> API获得，由Spark的屏障模式执行引擎提供支持，为长时间运行的作业提供稳定的通信后端。使用头节点上的<kbd>HorovodRunner</kbd>,它将培训功能发送给工人，并使用MPI后端启动该功能。这一切都发生在引擎盖下的火花过程。</p>
<p>同样，这也是Horovod非常容易使用的原因之一，因为它实际上只是您当前优化器的替代产品。假设您通常使用PySpark引擎在Azure Databricks上运行Keras模型。但是，您可能希望添加Horovod，通过利用集群中的其他机器并在多台机器上分割梯度下降来加快训练过程。为此，您只需将两行代码添加到上一节的示例中，如下所示:</p>
<pre><strong>hr = HorovodRunner(np=2)</strong><br/><br/>def train():<br/>  # Perform your training here..<br/>  import horovod.keras as hvd<br/>  hvd.init()<br/>  ...<br/><br/><strong>hr.run(train)</strong></pre>
<p>在前面的代码中，我们发现我们只需要用工作节点的数量初始化<kbd>HorovodRunner()</kbd>。用training函数调用<kbd>run()</kbd>方法，会自动启动新的worker，MPI通信后端，发送训练代码给worker，并行执行训练。因此，您现在可以将数据并行训练添加到长期运行的Spark ML作业中。</p>


            

            
        
    






    
        <title>Running Horovod on Azure ML compute</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">在Azure ML计算上运行Horovod</h1>
                
            
            
                
<p>迁移到云服务的好处之一是，您可以将功能作为服务来使用，而不是自己管理基础架构。很好的例子是托管数据库、lambda函数、托管Kubernetes或容器实例，其中选择托管服务意味着您可以专注于您的应用程序代码，而基础架构是在云中为您管理的。</p>
<p>Azure ML服务处于类似的位置，您可以通过SDK使用许多不同的功能(如模型管理、优化、培训和部署)，因此您不必维护ML集群基础架构。当涉及到通过分布式ML加速DNNs时，这带来了巨大的好处。如果你一直坚持使用Azure ML compute，那么转移到数据并行训练就像在训练配置中添加一个参数一样困难——对于本章中讨论的各种选择。</p>
<p>让我们考虑在分布式环境中使用Horovod优化器以数据并行模式运行Keras训练脚本。您需要确保您的工具的所有正确版本都已设置好(从CUDA到cuDNN、GPUDirect、MPI、Horovod、TensorFlow和Keras ),并且能够与您当前的操作系统和硬件很好地配合使用。然后，您需要将训练代码分发到所有机器上，启动MPI进程，然后在集群中的每台机器上使用Horovod和相关的命令行参数调用脚本。我们甚至还没有谈到身份验证、数据访问或自动扩展。</p>
<p>有了Azure ML，你就有了一个可以正常工作的ML环境，并且可以随时更新。让我们来看看之前的Horovod和Keras训练脚本，我们将它存储在一个<kbd>train.py</kbd>文件中。现在，类似于前面的章节，我们创建一个估算器来包装Azure ML SDK的训练调用。为了使用Horovod和MPI后端实现多GPU数据并行训练，我们只需添加相关参数。生成的脚本看起来像下面的代码片段:</p>
<pre>from azureml.train.dnn import TensorFlow, Mpi<br/><br/>estimator = TensorFlow(source_directory=project_folder<em>, <br/></em>              compute_target=compute_target,                       <br/>              entry_script='train.py',                       <br/>              script_params=script_params,                       <br/>              node_<em>c</em>ount=2, <br/>              distributed_training=Mpi(process_count_pernode=1), <br/>              pip_packages=['keras'],                       <br/>              framework_version='1.13',                       <br/>              use_gpu=True)</pre>
<p>使用<kbd>use_gpu</kbd>标志，我们可以为我们的Azure ML计算集群启用带有预编译二进制文件的特定于GPU的机器及其对应的映像。使用<kbd>node_count</kbd>和<kbd>process_count_per_node</kbd>，我们指定数据并行训练的并发级别，其中<kbd>process_count_per_node</kbd>应该对应于每个节点可用的GPU数量。最后，我们将<kbd>distributed_backend</kbd>参数设置为<kbd>mpi</kbd>，以便为这个估计器启用MPI通信后端。另一个可能的选择是使用<kbd>ps</kbd>来启用TensorFlow <kbd>ParameterServer</kbd>后端。</p>
<p>最后，为了启动作业，我们只需提交实验，它将自动在每个节点上设置MPI会话，并为我们调用带有相关参数的训练脚本。我不知道你对此有什么感觉，但对我来说，这确实比以前的手动示例前进了一大步。下面一行显示了如何提交实验:</p>
<pre class="mce-root">run = experiment.submit(estimator)</pre>
<p class="mce-root">将您的训练包装为Azure ML estimator的一部分，可以为多种环境微调您的训练脚本配置，无论是用于分布式梯度下降训练的多GPU数据并行模型还是用于快速推理的单节点实例。通过将分布式DL与Azure ML计算自动扩展集群相结合，您可以通过使用预构建的托管服务来充分利用云，而不是手动摆弄基础架构和配置。</p>


            

            
        
    






    
        <title>Summary</title>
        
        <meta charset="utf-8"/>
    

    
        

                            
                    <h1 class="header-title">摘要</h1>
                
            
            
                
<p>分布式ML是扩展您的培训基础设施的一个很好的方法，可以加快您的培训过程。它被应用于许多现实场景中，并且非常容易与Horovod和Azure ML一起使用。</p>
<p>并行执行类似于超参数搜索，分布式执行类似于贝叶斯优化，我们在前一章已经详细讨论过。分布式执行需要有效地执行通信(例如一对一、一对多、多对一和多对多)和同步(例如屏障同步)的方法。这些所谓的集体算法由通信后端(MPI、Gloo和NCCL)提供，允许高效的GPU到GPU通信。</p>
<p>DL框架在通信后端之上构建更高级别的抽象，以执行模型并行和数据并行训练。在数据并行训练中，我们对输入数据进行分区，以在不同的机器上计算模型的多个独立部分，并在稍后的步骤中将结果相加。DL中的一种常见技术是分布式梯度下降，其中每个节点在输入批次的一个分区上执行梯度下降，并且主节点收集所有单独的梯度以计算组合模型的总体平均梯度。在模型并行训练中，您将一个模型分布在多台机器上。当模型不适合单个GPU的GPU内存时，通常会出现这种情况。</p>
<p>Horovod是其他ML框架的现有优化器的抽象，如TensorFlow、Keras、PyTorch和Apache MXNet。它提供了一个易于使用的界面，可以将数据分布的培训添加到现有模型中，而无需进行大量代码更改。虽然您可以在独立的集群上运行Horovod，但Azure ML服务通过将其功能包装为评估器对象来提供良好的集成。您了解了如何在Azure ML计算集群上运行Horovod，以通过分布式ML加速您的训练过程，只需几行Horovod初始化和当前优化器上的包装器。</p>
<p>在下一章，我们将使用前面章节的所有知识来训练Azure上的推荐引擎。推荐引擎通常建立在其他NLP特征提取或分类模型的基础上，因此结合了我们目前所学的许多技术。</p>


            

            
        
    


</body></html>