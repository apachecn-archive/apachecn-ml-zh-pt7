<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Using Pretrained Models</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">使用预训练模型</h1>

                

            

            

                

<p>在前两章中，你学习了如何使用有监督的ML算法(<a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">第三章</a>、<em>监督学习</em>)和无监督的ML算法(<a href="26788e93-3614-413f-bcde-5580516f9c5f.xhtml" target="_blank">第四章</a>、<em>无监督学习</em>)来解决广泛的问题。这些解决方案从头开始创建模型，并且只包含Go代码。我们没有使用已经训练好的模型，也没有试图从Go中调用Matlab、Python或R代码。然而，在一些情况下这是有益的。在这一章中，我们将介绍几种旨在使用预训练模型和创建多语言ML应用程序的策略——也就是说，主要的应用程序逻辑是用Go编写的，但专业技术和模型可能是用其他语言编写的。</p>

<p>在本章中，您将了解以下主题:</p>

<ul>

<li>如何加载预训练的GoML模型并使用它来生成预测</li>

<li>何时考虑使用纯Go解决方案或多语种解决方案</li>

<li>如何使用os/exec包调用用其他语言编写的ML模型</li>

<li>如何使用HTTP来调用用其他语言编写的ML模型，这些模型可能驻留在不同的机器上，甚至在互联网上</li>

<li>如何使用TensorFlow API for Go运行TensorFlow模型</li>

</ul>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>How to restore a saved GoML model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">如何恢复保存的GoML模型</h1>

                

            

            

                

<p>一旦你完成了创建ML模型的艰苦工作，你可能需要关闭你的电脑。当计算机重新启动时，您的模型会发生什么变化？除非你把它保存到磁盘上，否则它会消失，你需要重新开始训练过程。即使您在gophernotes笔记本中保存了模型超参数，模型本身也不会被保存。如果培训过程很长，您可能需要等待很长时间才能再次使用您的模型。</p>

<p>在下面的例子中，我们将解释如何恢复我们在<a xmlns:epub="http://www.idpf.org/2007/ops" href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">第3章</a>、<em xmlns:epub="http://www.idpf.org/2007/ops">监督学习</em>中创建的模型，并使用GoML API提供的<kbd xmlns:epub="http://www.idpf.org/2007/ops">PersistToFile</kbd>方法将其保存到本地文件系统的一个<kbd xmlns:epub="http://www.idpf.org/2007/ops">model.dat</kbd>文件中。我们将使用它的<kbd xmlns:epub="http://www.idpf.org/2007/ops">RestoreFromFile</kbd>方法恢复它。我们将假设我们在第3章<a xmlns:epub="http://www.idpf.org/2007/ops" href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank"/><a xmlns:epub="http://www.idpf.org/2007/ops" href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank"><em xmlns:epub="http://www.idpf.org/2007/ops">监督学习</em>中创建的所有其他函数都是可用的，例如将一幅图像转换成一片浮点:</a></p>

<pre>// IsImageTrousers invokes the Saved model to predict if image at given index is, in fact, of trousers<br/>// For simplicity, this loads the model from disk on every request, whereas loading it once and caching it<br/>// would be preferable in a commercial application.<br/><br/>func IsImageTrousers(i int) (bool, error) {<br/>  model := linear.Logistic{}<br/>  if err := model.RestoreFromFile("model.dat"); err != nil {<br/>    return false, err<br/>  }<br/>  prediction, err := model.Predict(testImages[i])<br/>  return prediction &gt; 0.5, err<br/>}</pre>

<p>我们现在可以在gophernotes中使用这段代码来生成一个预测，并将其与<kbd>Label</kbd>列中的基本事实进行比较:</p>

<div><div><div><div><pre>// Prediction<br/><br/>IsImageTrousers(16)</pre></div>

</div>

</div>

</div>

<div><div><div><p class="prompt output_prompt">在gophernotes中运行前面的代码单元格将产生以下输出:</p>

<div><pre>true &lt;nil&gt;</pre></div>

</div>

</div>

</div>

<p>让我们检查输出:</p>

<pre>// Ground truth<br/><br/>df.Col("Label").Elem(16).Int() == 1<br/></pre>

<p>我们也可以使用我们在<a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">第3章</a>、<em>监督学习</em>中介绍的相同验证技术，来检查输出的质量是否符合预期。当模型是用Go编写的，并在以后被重用时，这种方法非常有效。然而，如果模型是用Python编写的，并且不能在Go中直接恢复(例如，<kbd>scikit-learn</kbd>模型就是这种情况)，那么使用它进行预测的唯一方法可能是在Python模型和Go应用程序之间设计一些通信。虽然这增加了应用程序的整体复杂性，但它有显著的优势，我们将在下面的部分中讨论。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Deciding when to adopt a polyglot approach</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">决定何时采用多语言方法</h1>

                

            

            

                

<p>正如我们在前面的章节中看到的，围棋生态系统提供了大量的机会来本地解决机器学习问题。然而，固执地要求解决方案保持纯粹的Go可能会导致开发时间增加，甚至降低训练性能，因为其他更专业的ML库可以提供相应Go库中尚未实现的更高级别的API或性能优化。</p>

<p>这两者的一个很好的例子是Python ML库Keras。这个库的目的是提供一个高级API，允许作者执行广泛的ML任务，如数据预处理、模型训练、模型验证和持久性。它的抽象在各种后端中都有具体的实现，比如TensorFlow，众所周知它的性能非常好。由于这些原因，keras是任何语言中最受欢迎的ML库之一:其麻省理工学院许可的GitHub存储库有超过40，000颗星，在GitHub上搜索显示超过20，000个存储库与搜索词Keras匹配，这意味着存储库的名称包含该词。对代码内容的搜索显示，GitHub上超过一百万个文件包含搜索词keras。</p>

<p>然而，仅仅为了利用一个库而用Python编写整个应用程序并不能利用Go提供的好处，我们在第一章、<em xmlns:epub="http://www.idpf.org/2007/ops">介绍Go的机器学习</em>中列举了这些好处。如果这些因素在应用程序的开发中并不重要，那么尽一切办法用Python来创建它，但是，在接下来的内容中，我们将假设您希望两个世界都最好。</p>

<p>因此，有两个选择:第一，完全在Go中开发应用程序。第二，用Python开发ML模型，并从Go代码中调用这个模型，它将包含主要的应用程序和业务逻辑。在以生产现成产品为目标的商业环境中，这两种选择的优势如下:</p>

<p><strong>纯Go应用</strong>:</p>

<ul>

<li>在多种语言的溶液中更容易保持</li>

<li>降低应用程序组件交互的复杂性，因为不需要管理外部ML组件的调用</li>

<li>更容易让团队成员加入</li>

<li>需要更新的依赖项更少</li>

</ul>

<p>现有的库可以提供所需的现成功能和足够的性能，排除了使用其他语言的专用库所带来的任何优势。</p>

<p><strong>多语言应用</strong>:</p>

<ul>

<li>使用来自其他语言专业库的高级抽象，大幅减少复杂ML问题的代码量</li>

<li>在某些情况下，性能优势，因为一些GoML库不是为完全的速度而设计的(深度学习就是一个很好的例子)</li>

<li>可以更好地适应多团队方法，因为数据科学团队更熟悉Python或R库</li>

<li>利用预先存在的模型——学术研究论文通常会发布Caffe或TensorFlow模型，并使用Python或Lua脚本来调用它们</li>

</ul>

<p>总之，对于ML应用程序来说，现有的Go库提供了你所需要的现成的或者很少修改的东西，一个本地的Go解决方案将会降低应用程序的复杂性并增强可维护性。然而，如果不是这样，特别是对于深度学习和计算机视觉等非常复杂的问题，将Go与其他语言的最新工具结合起来是值得的。</p>

<p>在下面的例子中，我们将从Go应用程序中调用各种Python ML模型。我们专门使用Python的原因是Python预装在大多数Linux发行版中，也是ML<sup>【4】【5】</sup>最流行的语言。我们将要描述的解决方案可以应用于用任何编程语言编写的模型。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Example – invoking a Python model using os/exec</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">示例–使用os/exec调用Python模型</h1>

                

            

            

                

<p>为了开始多语言ML应用程序，我们将重温来自<a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">第3章</a>、<em>监督学习</em>的逻辑回归示例。我们将假设模型是用Python而不是Go编写的，并且我们希望从我们的Go应用程序中调用它。为此，我们将使用命令行参数向模型传递输入，并从<strong>标准输出</strong> ( <strong> STDOUT </strong>)中读取模型的预测。</p>

<p>为了在Python和Go之间交换数据，我们将使用使用<strong> JavaScript对象符号</strong> ( <strong> JSON </strong>)格式化的字符串。当然，这种选择是任意的<sup>【6】</sup>，我们可以选择Go和Python标准库支持的任何其他格式，比如XML，或者发明我们自己的格式。JSON的优势在于，在两种语言中使用起来都不费吹灰之力。</p>

<p>我们将遵循以下流程与Python子流程进行通信。通常有三个步骤:请求的序列化、执行子流程和响应的反序列化:</p>

<p class="CDPAlignCenter CDPAlign"><img class="alignnone size-full wp-image-192 image-border" src="img/9c2271a0-d0ce-448b-bd00-dc17353a7b93.png" style="width:21.83em;height:26.58em;"/></p>

<p>图1:我们用来与运行预训练逻辑回归模型的Python子流程通信的流程</p>

<p>我们将从加载MNIST数据集并将其转换为数据帧开始。你可以在<a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml">第三章</a>、<em>监督学习</em>中找到代码。不过这一次，我们将把图像数据转换成一片int，每个int在0到255(每个像素的值)之间，而不是一片floats。这是为了确保与Python模型保持一致:</p>

<pre>// ImageSeriesToInts converts the dataframe's column containing image data for multiple images to a slice of int slices, where each int is between 0 and 255, representing the value of the pixel.<br/><br/>func ImageSeriesToInts(df dataframe.DataFrame, col string) [][]int {<br/><br/>  s := df.Col(col)<br/><br/>  ret := make([][]int, s.Len(), s.Len())<br/><br/>  for i := 0; i &lt; s.Len(); i++ {<br/><br/>    b := []byte(s.Elem(i).String())<br/><br/>    ret[i] = NormalizeBytes(b)<br/><br/>  }<br/><br/>  return ret<br/><br/>}</pre>

<p>接下来，我们将引入一个允许我们启动Python子流程并等待它完成的函数:</p>

<pre>// InvokeAndWait invokes a Python 3 script with the given arguments, waits for it to finish, and returns the concatenated output of its STDOUT and STERRR.<br/>func InvokeAndWait(args ...string) ([]byte, error) {<br/>  var (<br/>    output []byte<br/>    errOutput []byte<br/>    err error<br/>  )<br/>  cmd := exec.Command("python3", args...)<br/>  stdout, err := cmd.StdoutPipe()<br/>  if err != nil {<br/>    return nil, err<br/>  }<br/>  stderr, err := cmd.StderrPipe()<br/>  if err := cmd.Start(); err != nil {<br/>    return nil, err<br/>  }<br/>  if output, err = ioutil.ReadAll(stdout); err != nil {<br/>    return nil, err<br/>  }<br/>  if errOutput, err = ioutil.ReadAll(stderr); err != nil || len(errOutput) &gt; 0 {<br/><br/>    return nil, fmt.Errorf("Error running model: %s", string(errOutput))<br/>  }<br/>  return output, nil<br/>}</pre>

<p>现在，我们准备组装预测函数，它将序列化图像数据，在子流程启动时将其作为参数传递给子流程，等待子流程完成，并反序列化响应:</p>

<pre>// IsImageTrousers invokes the Python model to predict if image at given index is, in fact, of trousers<br/><br/>func IsImageTrousers(i int) (bool, error){<br/>    b, err := json.Marshal(testImages[i])<br/>    if err != nil {<br/>        panic(err)<br/>    }<br/>    b, err = InvokeAndWait("model.py", "predict", string(b))<br/>    if err != nil {<br/>        return false, err<br/>    } else {<br/>        var ret struct {<br/>            IsTrousers bool `json:"is_trousers"`<br/>        }<br/>        err := json.Unmarshal(b, &amp;ret)<br/>        if err != nil {<br/>            return false, err<br/>        }<br/>        return ret.IsTrousers, nil<br/>    }<br/>}</pre>

<p>我们现在可以在gophernotes中使用这段代码来生成一个预测，并将其与<kbd>Label</kbd>列中的基本事实进行比较:</p>

<div><div><div><div><pre>// Prediction<br/>IsImageTrousers(16)</pre></div>

</div>

</div>

</div>

<div><div><div><p class="prompt output_prompt">在gophernotes单元格中运行此命令会提供以下输出:</p>

<div><pre>true &lt;nil&gt;</pre></div>

</div>

</div>

</div>

<p>让我们检查输出:</p>

<pre>// Ground truth<br/>df.Col("Label").Elem(16).Int() == 1</pre>

<p>正如所料，这输出<kbd>true</kbd>。我们可以对几个不同的图像重复这个过程，以获得一些信心，确信一切都正常工作。Go和Python代码都使用<kbd>predict</kbd>参数来表示应该执行哪个动作——我们还可以有一个<kbd>test</kbd>动作来检查Python代码从其参数中重建的图像是否正确，这进一步增加了我们对子流程通信是否正确的信心。</p>

<p>子进程通信可以是特定于操作系统的，尤其是在涉及输出重定向时。Go的一个优点是，我们在这里提出的管道方法在不同的操作系统中同样适用，不需要额外的修改，而在Python等其他语言中，有时需要额外的工作。</p>

<p>虽然代码简洁且易于调试，但启动新的Python进程来处理每个请求的需求会影响具有更小、更快模型的应用程序的性能。此外，它在Go应用程序和它的Python模型之间创建了一个相当紧密的耦合。这可能会给大型团队带来问题，在大型团队中，数据科学团队创建模型，而软件开发团队创建应用程序的其余部分。这也可能产生这样的问题，即模型应该被暴露给多个应用程序，而不仅仅是一个——那么你应该怎么做呢？每个应用程序都有一个模型副本？这可能会导致可维护性问题。在下面的例子中，我们将研究一种将Go应用程序从其Python模型中分离出来的方法。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Example – invoking a Python model using HTTP</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">示例–使用HTTP调用Python模型</h1>

                

            

            

                

<p>如果模型驻留在不同的机器上，我们需要解耦Go和模型逻辑，或者如果我们希望执行多个操作，例如基于用户数据训练特定于用户的模型，然后使用该模型生成预测，该怎么办？在这些情况下，我们之前使用命令行参数的解决方案将变得更加复杂，因为我们添加了更多的参数来区分操作和返回代码。这种类型的调用通常被称为<strong>远程过程调用</strong> ( <strong> RPC </strong>)，SOAP或JSON-RPC等解决方案在业界已经有几十年的历史<sup>【7】</sup>。</p>

<p>在下面的例子中，我们将使用一个更通用的协议:HTTP。严格地说，HTTP是一种数据传输协议，并且经常被用作RPC协议的管道。然而，只需很少的努力，我们就可以通过公开一个接受POST请求的端点，在HTTP之上创建我们自己的最小RPC。这样做的好处是，除了Python或Go中的标准库之外，不需要任何依赖，并且调试协议错误非常简单。缺点是它需要更多的工作来处理诸如序列化之类的问题。</p>

<p>下图说明了我们将遵循的请求/响应流程:</p>

<div><img class="alignnone size-full wp-image-193 image-border" src="img/6df6714f-40d5-4529-89fe-b80f27b22285.png" style="width:55.92em;height:15.25em;"/></div>

<p>图2:GoML应用程序使用HTTP与预训练的Python模型通信的请求/回复过程</p>

<p>与前面的例子不同，我们假设Python HTTP服务器已经在运行。如果您正在使用配套的存储库，那么在使用<kbd>install-python-dependencies.sh</kbd>安装完依赖项之后，您可以使用<kbd>python3 model_http.py</kbd>命令启动Python服务器。这意味着Go代码特别短:</p>

<pre>// Predict returns whether the ith image represents trousers or not based on the logistic regression model<br/><br/>func Predict(i int) (bool, error){<br/>    b, err := json.Marshal(testImages[i])<br/>    if err != nil {<br/>        return false, err<br/>    }<br/>    r := bytes.NewReader(b)<br/>    resp, err := http.Post("http://127.0.0.1:8001", "application/json", r)<br/>    if err != nil {<br/>        return false, err<br/>    }<br/>    body, err := ioutil.ReadAll(resp.Body)<br/>    if err != nil {<br/>        return false, err<br/>    }<br/>    resp.Body.Close()<br/>    var resp struct {<br/>        IsTrousers bool `json:"is_trousers"`<br/>    }<br/>    err := json.Unmarshal(body, &amp;resp)<br/>    return resp.IsTrousers, err <br/>}</pre>

<p>正如我们之前所做的，我们可以生成一些预测，以确保Go和Python流程之间的通信按预期进行:</p>

<div><div><div><div><pre>// Expected: true &lt;nil&gt;<br/><br/>Predict(16)</pre></div>

</div>

</div>

</div>

<div><div><div><p class="prompt output_prompt">正如预期的那样，我们得到了以下内容:</p>

<div><pre>true &lt;nil&gt;</pre></div>

</div>

</div>

</div>

<p>我们可以对其他几幅图像继续这一过程，以确保响应与<kbd>df.Col("Label")</kbd>系列定义的地面真实值相匹配。我们还可以在Python HTTP服务器上创建多个HTTP端点，以允许各种测试，进一步增强我们对进程间通信的信心。</p>

<p>如果您需要调试与HTTP服务器的通信，Postman是一个很好的工具，它是一个免费的GUI工具，允许您创建HTTP请求并检查响应。你可以在:<br/><a href="https://www.getpostman.com/">https://www.getpostman.com/</a>找到邮递员。</p>

<p>在前面的例子中，我们假设模型是用不同的编程语言(Python)创建的，并且只能从该语言访问。然而，有一些流行的深度学习库已经努力变得更加多语言化，因此，提供了使用一种语言创建模型并使用另一种语言的方法。在下面的例子中，我们将看看其中的两个库。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Example – deep learning using the TensorFlow API for Go</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">示例–使用TensorFlow API for Go进行深度学习</h1>

                

            

            

                

<p>深度学习是机器学习的一个子领域，它采用通常具有许多层的神经网络来解决图像或语音识别等复杂问题。在这个例子中，我们将看看如何利用TensorFlow，一个流行的深度学习框架，使用它的Go绑定。</p>

<p>TensorFlow是一个高度优化的库，由Google创建，用于对名为tensor<sup>【8】</sup>的对象执行计算。如果向量是标量(数字)的集合，矩阵是向量的集合，那么张量可以被认为是一个更高维的矩阵，其中标量、向量和矩阵是特例。虽然这看起来有点抽象，但张量是描述神经网络时使用的自然对象，这也是为什么TensorFlow成为最受欢迎的库之一——甚至根据一些评论者的说法，<em>是最受欢迎的</em>——用于商业和学术深度学习开发<sup>【9】【10】</sup>。</p>

<p>2011年，谷歌大脑的团队建立了一个专有的深度学习系统，名为dist belief<sup>【11】</sup>。杰夫·迪恩(Jeff Dean)和杰弗里·辛顿(Geoffrey Hinton)等许多杰出的计算机科学家都在研究它的反向传播和其他神经网络相关算法，这导致该框架在谷歌的许多项目中得到越来越多的采用。2017年，这个框架的第二代，现在叫做TensorFlow，在开源许可下发布<sup>【12】</sup>。</p>

<p>TensorFlow的核心是一个低级API，也称为深度学习计算的后端。实际上，处理商业问题的数据科学家通常不需要每天与TensorFlow API直接交互。相反，许多前端，如我们之前介绍的Keras，可以作为TensorFlow的更高级抽象来使用，并提供最佳的性能和易用性。另一方面，发明新型神经架构的学术研究通常是使用低级API来执行的，因为还不存在新结构的抽象。你在TensorFlow中创建的被称为<strong>图形</strong>的对象，可以在其他语言中持久化和重用，这要感谢最近为使框架更加多语言化所做的努力<sup>【13】</sup>。</p>

<p>在本例中，我们将解释如何安装TensorFlow以及如何使用其Go API来加载预训练TensorFlow模型并使用它进行预测。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Installing TensorFlow</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">安装TensorFlow</h1>

                

            

            

                

<p>TensorFlow的体验通常是巧妙的——也就是说，在你设法正确安装它之后。TensorFlow团队认识到这是一个困难的步骤，在最好的情况下，从源代码构建TensorFlow通常需要几个小时，因此他们现在提供了几个简单的安装选项。值得注意的是，如果您的系统上有兼容的GPU，您应该安装一个GPU选项，因为这通常会显著加速软件，这在培训阶段尤其明显:</p>

<ul>

<li><strong>使用pip </strong>安装:TensorFlow面向Python程序员，他们通常会使用<kbd>pip</kbd>来管理他们的包。在撰写本文时，该方法已经在Ubuntu Linux 16.04或更高版本、macOS 10.12.6 (Sierra)或更高版本(尽管不支持GPU)、Raspbian 9.0或更高版本以及Windows 7或更高版本上进行了测试。</li>

<li>使用Docker映像:这将适用于支持Docker的各种系统。有两个图片可供选择:一个普通的TensorFlow图片和一个包含Jupyter的图片，让您有与gophernotes相同的体验，但只使用Python。</li>

<li>从源代码构建(Build from source):如果您正在使用一个非标准的配置，或者想要对构建过程的一部分进行特定的控制(也许利用一些只对您的特定配置有效的优化)，这是最好的选择。</li>

</ul>

<p>还有第四种选择，即使用Google Colaboratory在Google的云中运行基于TensorFlow的代码，但我们不会深入研究这种选择，因为它目前只适用于Python。</p>

<p>在这个例子中，我们将使用一个Docker图像。Docker可以看作是在同一台机器上打包和运行多个应用程序(称为容器)的解决方案，同时防止它们相互干扰。如果你还不熟悉，去https://docs.docker.com/get-started/<a xmlns:epub="http://www.idpf.org/2007/ops" href="https://docs.docker.com/get-started/">听一个五分钟的教程。</a></p>

<p>我们将使用名为<kbd>tensorflow/tensorflow</kbd>的普通TensorFlow-on-Ubuntu图像，其中不包括Jupyter。我们需要在这个映像上安装Go，这样我们就可以运行我们的代码了。因为我们的代码将依赖于用于Go的TensorFlow绑定，所以我们也将根据官方说明<sup>【14】</sup>安装它们。这也需要我们安装TensorFlow C绑定。因此，我们的docker文件将如下所示。为了简洁起见，省略了一些步骤——您可以在本书的配套资源库中找到完整的docker文件:</p>

<pre>FROM tensorflow/tensorflow<br/><br/>## Install gcc for cgo ##<br/>RUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends \<br/> curl \<br/> git \<br/> wget \<br/> g++ \<br/> gcc \<br/> libc6-dev \<br/> make \<br/> pkg-config \<br/> &amp;&amp; rm -rf /var/lib/apt/lists/*<br/><br/>## Install TensorFlow C library ##<br/>RUN curl -L \<br/> "https://storage.googleapis.com/tensorflow/libtensorflow/libtensorflow-cpu-linux-x86_64-1.13.1.tar.gz" | \<br/> tar -C "/usr/local" -xz<br/>RUN ldconfig<br/><br/>## Install Go ##<br/>ENV GOLANG_VERSION 1.9.2<br/><br/>RUN wget -O go.tgz "https://golang.org/dl/go${GOLANG_VERSION}.${goRelArch}.tar.gz"; \<br/> echo "${goRelSha256} *go.tgz" | sha256sum -c -; \<br/> tar -C /usr/local -xzf go.tgz; \<br/> rm go.tgz; \<br/> \<br/> if [ "$goRelArch" = 'src' ]; then \<br/> echo &gt;&amp;2; \<br/> echo &gt;&amp;2 'error: UNIMPLEMENTED'; \<br/> echo &gt;&amp;2 'TODO install golang-any from jessie-backports for GOROOT_BOOTSTRAP (and uninstall after build)'; \<br/> echo &gt;&amp;2; \<br/> exit 1; \<br/> fi; \<br/> \<br/> export PATH="/usr/local/go/bin:$PATH"; \<br/> go version<br/><br/>ENV GOPATH /go<br/>ENV PATH $GOPATH/bin:/usr/local/go/bin:$PATH<br/><br/>RUN mkdir -p "$GOPATH/src" "$GOPATH/bin" &amp;&amp; chmod -R 777 "$GOPATH"<br/><br/>## Go get tensorflow go library ##<br/>RUN \<br/> go get github.com/tensorflow/tensorflow/tensorflow/go \<br/> github.com/tensorflow/tensorflow/tensorflow/go/op<br/><br/>## Set up the environment so we can just run our code ##<br/>RUN mkdir $GOPATH/src/model<br/><br/>WORKDIR $GOPATH/src/model<br/><br/>ADD . $GOPATH/src/model<br/><br/>CMD ["go", "run", "main.go"]</pre>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Import the pretrained TensorFlow model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">导入预训练张量流模型</h1>

                

            

            

                

<p>在<a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml" target="_blank">第3章</a>、<em>监督学习</em>中，我们解释了如何使用go-deep库在pure Go中创建深度学习模型。虽然这是一个玩具示例，但是训练起来非常慢，并且需要很多多余的代码。如果使用行业领先的深度学习库之一，会容易得多，并产生更多性能代码，但不幸的是，它们是用其他语言编写的。使用Python库Keras，我们创建了一个深度学习模型，它将在我们之前查看的同一问题中充当分类器:<em>给定的图像是一条裤子吗？</em>我们现在将编写一些Go代码来导入我们的预训练模型。</p>

<p>如果只保存模型的权重，而不是更完整的SavedModel格式，会怎么样？在这种情况下，您仍然可以使用<kbd>graph.Import</kbd> func导入它，但是，随后需要做更多的工作来告诉TensorFlow所有的操作和变量。TensorFlow API godocs中有一个例子说明了这个过程<sup>【15】</sup>。</p>

<p>接下来的内容假设模型以<kbd>SavedModel</kbd>格式保存，并且我们知道输入和输出的名称<kbd>Ops</kbd>。如果模型是由其他人使用Keras或其他第三方库创建的，这有时会很棘手。一种选择是使用<kbd>SavedModel</kbd>命令行界面工具来检查模型<sup>【16】</sup>。</p>

<p>如果模型是在Keras中创建的，并且您可以访问Python代码，那么只需检查它的<kbd>input</kbd>和<kbd>output</kbd>属性，就可以看到相应张量的名称。它们后面可能会有一个<kbd>:0</kbd>，您可以忽略它。</p>

<p>要在Go中恢复一个<kbd>SavedModel</kbd>，只需使用<kbd>LoadSavedModel</kbd> func。这将返回一个图形和会话对象，然后您可以对其进行操作，传递输入并检索输出:</p>

<pre>savedModel, err := tf.LoadSavedModel("./saved_model", []string{"serve"}, nil)<br/>if err != nil {<br/>  log.Fatalf("failed to load model: %v", err)<br/>}</pre>

<p>请注意，第二个参数称为标签，通常按照惯例设置。我们现在可以访问输入和输出操作:</p>

<pre>input := savedModel.Graph.Operation("input_input_1")<br/>output := savedModel.Graph.Operation("output_1/BiasAdd")</pre>

<p>如果在这一阶段输入或输出为零，这意味着您没有正确的名称，因此您需要返回到检查模型以找出它们应该是什么。查看<kbd>savedModel.Graph.Operations</kbd>(它是<kbd>Operation</kbd>的一部分)并通过那些包含在<kbd>Name()</kbd>中输入的搜索字符串的操作来过滤操作列表也是有用的。</p>

<p>我们现在可以访问恢复的会话和图形:</p>

<pre>session := savedModel.Session<br/>graph := savedModel.Graph<br/>defer session.Close()<br/>fmt.Println("Successfully imported model!")</pre>

<p>现在，我们可以在TensorFlow Docker容器中运行这段代码并查看结果。我们将从Docker文件构建Docker映像并运行它:</p>

<pre>docker build -t tfgo . &amp;&amp; \<br/>docker run -it tfgo</pre>

<p>如果一切顺利，我们应该在构建容器时看到一些输出(第二次运行时会快得多),最后显示以下消息:</p>

<pre>Successfully built 9658a6232ef8<br/>Successfully tagged tfgo:latest<br/>Successfully imported model!</pre>

<p>前两行告诉我们，我们的Docker映像已经成功构建，最后一行来自我们的Go代码，让我们知道模型导入操作工作正常，没有导致任何错误。</p>

<p>根据您安装Docker的方式，您可能需要超级用户权限来运行这些命令，所以如果需要，只需在它们前面加上<kbd>sudo</kbd>即可。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Creating inputs to the TensorFlow model</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">创建张量流模型的输入</h1>

                

            

            

                

<p>既然我们能够从<kbd>SavedModel</kbd>中重新创建TensorFlow图和会话，我们将创建一个程序，该程序将从MNIST时装数据集中接受一幅图像作为一片字节，并使用这些字节来填充我们之前加载的模型的输入。然后，我们将能够运行模型以获得输出预测。</p>

<p>我们必须创建一个过程，该过程将接受来自MNIST时装数据集的图像，并返回正确形状的张量。我们从第3章<em>监督学习</em>中知道，模型将期望一个784浮点的切片，并且对模型的检查(使用Python中的<kbd>model.summary</kbd>或<kbd>SavedModel</kbd> CLI)将揭示输入应该是一个1 x 784张量的<kbd>float32</kbd>值。</p>

<p>当通过将切片的切片作为参数传递给<kbd>NewTensor</kbd> func来构造张量时，请确保它们的长度都相同。例如，您可以传递每个包含7个元素的3个切片，这将创建一个(3，7)张量，但不是分别包含5、6和7个元素的3个切片-第二维度必须对所有切片都相同。</p>

<p>我们可以构造一个形状正确的空白(零)张量，如下所示:</p>

<pre>func makeBlankInputTensor() (*tf.Tensor, error) {<br/>  t := make([][]float32, 1)<br/>  t[0] = make([]float32, 784)<br/>  tensor, err := tf.NewTensor(t)<br/>  return tensor, err<br/>}</pre>

<p>虽然这本身不是很有用，但它展示了<kbd>NewTensor</kbd> func的用法，它可以从传递的Go <kbd>interface{}</kbd>中推断出正确的张量形状和值类型。使用我们在<a href="48817ff3-5622-4f43-88e7-d3dfccacb25d.xhtml">第三章</a>、<em>监督学习</em>中介绍的<kbd>ImageSeriesToFloats</kbd> func，我们可以很容易地将一幅图像转换成<kbd>float32</kbd>的切片，从而做出输入张量。</p>

<p>我们可以运行模型得到一个预测:</p>

<pre>tensor, err := makeTensorFromImage("/path/to/fashion/MNIST", 12)<br/>if err != nil {<br/>  log.Fatal(err)<br/>}<br/>prediction, err := session.Run(<br/>  map[tf.Output]*tf.Tensor{<br/>    graph.Operation(input.Name()).Output(0): tensor,<br/>  },<br/>  []tf.Output{<br/>    graph.Operation(output.Name()).Output(0),<br/>  },<br/>  nil)<br/>if err != nil {<br/>  log.Fatal(err)<br/>}<br/><br/>probability := prediction[0].Value().([][]float32)[0][0]<br/>if probability &gt; 0.5 {<br/>  fmt.Printf("It's a pair of trousers! Probability: %v\n", probability)<br/>} else {<br/>  fmt.Printf("It's NOT a pair of trousers! Probability: %v\n", probability)<br/>}</pre>

<p>例如，当以空白张量作为输入运行此命令时，输出的最后几行如下所示:</p>

<pre>Successfully built b7318b44f92d<br/>Successfully tagged tfgo:latest<br/>Successfully imported model!<br/>It's NOT a pair of trousers! Probability: 0.04055497</pre>

<p>在下一章中，我们将更详细地探讨使用Docker部署ML应用程序工作负载的模式。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Summary</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">摘要</h1>

                

            

            

                

<p>在这一章中，我们从实用的角度比较了Go-only和polyglot ML解决方案，对比了它们的缺点和优点。然后，我们介绍了两个开发多语言ML解决方案的通用解决方案:os/exec包和JSON-RPC。最后，我们看了两个高度专门化的库，它们自带基于RPC的集成解决方案:TensorFlow和Caffe。您已经学习了如何决定在您的应用程序中是使用Go-only还是polyglot方法来处理ML，如何实现基于RPC的polyglot ML应用程序，以及如何从Go运行TensorFlow模型。</p>

<p>在下一章，我们将讨论ML开发生命周期的最后一步:将一个用Go to production编写的ML应用程序投入生产。</p>





            



            

        

    </body>



</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">

    <head>

        <title>Further readings</title>

        

        <meta charset="utf-8"/>

<meta content="urn:uuid:89844efe-5d6f-4fa2-9e51-796696927998" name="Adept.expected.resource"/>

    </head>



    <body>

        



                            

                    <h1 class="header-title">进一步阅读</h1>

                

            

            

                

<ol>

<li><em>柯</em> <em>拉斯吉图库</em>:<a href="https://github.com/keras-team/keras">https://github.com/keras-team/keras</a>。检索时间2019年4月30日。</li>

<li><em> GitHub搜索keras</em>:<a href="https://github.com/search?utf8=%E2%9C%93&amp;q=keras&amp;type=">https://github.com/search?utf8=%E2%9C%93&amp;amp；q = keras&amp;amp；type= </a>。检索时间2019年4月30日。</li>

<li><em> GitHub内容搜索keras</em>:<a href="https://github.com/search?q=keras&amp;type=Code">https://github.com/search?q=keras&amp;amp；类型=代码</a>。检索时间2019年4月30日。</li>

<li>《经济学人》<em xmlns:epub="http://www.idpf.org/2007/ops"> Python正成为世界上最流行的编码语言。2018年7月26日:<a xmlns:epub="http://www.idpf.org/2007/ops" href="https://www.economist.com/graphic-detail/2018/07/26/python-is-becoming-the-worlds-most-popular-coding-language">https://www . economist . com/graphic-detail/2018/07/26/python-is-being-the-world-most-popular-coding-language。</a>检索时间2019年4月30日。</em></li>

<li>在Unix平台上使用Python:<a xmlns:epub="http://www.idpf.org/2007/ops" href="https://docs.python.org/2/using/unix.html">https://docs.python.org/2/using/unix.html</a>。检索时间2019年4月30日。</li>

<li><em>JSON</em>:<a href="https://www.json.org/">https://www.json.org/</a>。检索时间2019年4月30日。</li>

<li><em>封面-肥皂</em>:<a href="http://xml.coverpages.org/soap.html">http://xml.coverpages.org/soap.html</a>。检索时间2019年4月30日。</li>

<li><em>张量流核心</em>:<a href="https://www.tensorflow.org/overview/">https://www.tensorflow.org/overview/</a>。检索时间2019年4月30日。</li>

<li><em>深度学习框架Power Scores</em>:<a href="https://towardsdatascience.com/deep-learning-framework-power-scores-2018-23607ddf297a">https://towardsdatascience . com/Deep-Learning-Framework-Power-Scores-2018-23607 ddf 297 a</a>。检索时间2019年4月30日。</li>

</ol>

<ol start="10">

<li><em>排名热门深度学习框架</em>:<a href="https://blog.thedataincubator.com/2017/10/ranking-popular-deep-learning-libraries-for-data-science/">https://blog . the data incubator . com/2017/10/Ranking-Popular-Deep-Learning-libraries-for-data-science/</a>。检索时间2019年4月30日。</li>

<li>迪恩杰夫等人。艾尔。<em>异构分布式系统上的大规模机器学习</em>。2015年11月9日。<a href="http://download.tensorflow.org/paper/whitepaper2015.pdf">http://download.tensorflow.org/paper/whitepaper2015.pdf</a>检索时间2019年4月30日。</li>

<li><em>tensor flow</em><kbd>RELEASE.md</kbd>:<a href="https://github.com/tensorflow/tensorflow/blob/07bb8ea2379bd459832b23951fb20ec47f3fdbd4/RELEASE.md">https://github . com/tensor flow/tensor flow/blob/07 bb 8 ea 2379 BD 459832 b 23951 FB 20 EC 47 F3 fdbd 4/release . MD</a>。检索时间2019年4月30日。</li>

<li><em>其他语言的张量流</em>:<a href="https://www.tensorflow.org/guide/extend/bindings">https://www.tensorflow.org/guide/extend/bindings</a>。检索时间2019年4月30日。</li>

<li><em>为Go安装tensor flow</em>:<a href="https://www.tensorflow.org/install/lang_go">https://www.tensorflow.org/install/lang_go</a>。检索于2019年5月1日。</li>

<li><em>tensor flow—godocs</em>:<a href="https://godoc.org/github.com/tensorflow/tensorflow/tensorflow/go">https://godoc . org/github . com/tensor flow/tensor flow/tensor flow/go</a>。检索于2019年5月3日。</li>

<li><em>保存和恢复</em>:<a href="https://www.tensorflow.org/guide/saved_model#install_the_savedmodel_cli">https://www . tensor flow . org/guide/saved _ model # install _ the _ saved model _ CLI</a>。检索于2019年5月3日。</li>

<li><em>标签常量</em>:<a href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/saved_model/tag_constants.py">https://github . com/tensor flow/tensor flow/blob/master/tensor flow/python/saved _ model/Tag _ constants . py</a>。检索于2019年5月22日。</li>

</ol>





            



            

        

    </body>



</html></body></html>