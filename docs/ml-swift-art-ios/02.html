<html><head/><body><html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Classification – Decision Tree Learning</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">分类–决策树学习</h1>
                
            
            
                
<p class="mce-root">在前一章，我们讨论了不同类型的机器学习，包括监督分类任务；在本章中，我们将为此构建第一个Swift应用程序。我们将讨论机器学习开发栈的主要组件，还将练习Python中的数据生成、探索性分析、预处理以及模型训练和评估。此后，我们将把我们的模型转移到Swift。我们还将讨论一类特定的监督学习算法——决策树学习及其扩展:随机森林。<br/></p>
<p>本章中有以下主题在等着我们:</p>
<ul>
<li>机器学习软件开发栈</li>
<li>用于机器学习的Python工具箱:IPython，SciPy，scikit-learn</li>
<li>数据集生成和探索性分析</li>
<li>数据预处理</li>
<li>决策树学习和随机森林</li>
<li>使用不同的性能指标评估模型性能</li>
<li>欠拟合和过拟合</li>
<li>将scikit-learn模型导出到核心ML格式</li>
<li>将训练好的模型部署到iOS</li>
</ul>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Machine learning toolbox</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">机器学习工具箱</h1>
                
            
            
                
<p>多年来，机器学习的编程语言选择是以下之一:Python、R、MATLAB、C++。这不是因为某些特定的语言特性，而是因为围绕它的基础设施:库和工具。Swift是一种相对年轻的编程语言，任何选择它作为机器学习开发的主要工具的人都应该从非常基本的构建块开始，并构建自己的工具和库。最近，苹果对第三方Python机器学习工具变得更加开放:Core ML可以与其中一些工具一起工作。</p>
<p>这里列出了成功的机器学习研究和开发所需的组件，以及这种类型的流行库和工具的示例:</p>
<ul>
<li><strong>线性代数</strong>:机器学习开发人员需要像向量、矩阵和张量这样的数据结构，它们具有紧凑的语法和硬件加速的运算。其他语言的例子:NumPy，MATLAB，和R标准库，Torch。</li>
<li><strong>概率论</strong>:各种随机数据产生:随机数及其集合；概率分布；排列；集合的混洗、加权采样等等。例如:NumPy和R标准库。</li>
<li><strong>数据输入输出</strong>:在机器学习中，我们通常对解析和保存以下格式的数据最感兴趣:纯文本、CSV之类的表格文件、SQL之类的数据库、互联网格式JSON、XML、HTML和web抓取。还有很多特定于领域的格式。</li>
<li><strong>数据角力</strong>:类似表格的数据结构，数据工程工具:数据集清洗、查询、拆分、合并、洗牌等等。熊猫，dplyr。</li>
<li><strong>数据分析/统计</strong>:描述性统计、假设检验和各种统计资料。r标准库和许多CRAN包。</li>
<li><strong>可视化</strong>:统计数据可视化(非饼图):图形可视化、直方图、镶嵌图、热图、树状图、3D-surfaces、空间和多维数据可视化、交互可视化、Matplotlib、Seaborn、Bokeh、ggplot2、ggmap、Graphviz、D3.js</li>
<li><strong>符号计算</strong>:自动微分:SymPy，Theano，亲笔签名。</li>
<li><strong>机器学习包</strong>:机器学习算法和求解器。Scikit-learn、Keras、XGBoost、E1071和caret。</li>
<li><strong>交互式原型开发环境</strong> : Jupyter，R studio，MATLAB，iTorch。</li>
</ul>
<p>这不是指特定领域的工具，如NLP或计算机视觉库。</p>
<p>至于2017年夏季，我不知道Swift是否有质量和功能与上述任何工具相当的替代产品。此外，这些流行的库都不直接与Swift兼容，这意味着你不能从你的iOS Swift代码中调用Keras。这一切都意味着Swift不能成为机器学习研发的首要工具。杀死Python目前还不在Swift的议程上；然而，在不同程度上，有一些兼容的库和工具，它们使用广泛的机器学习问题可以在您的Swift应用程序中得到解决。在接下来的章节中，我们将构建自己的工具，或者在需要时引入第三方工具。我们在<a href="a0699ba2-e643-4a53-914b-890b435be480.xhtml" target="_blank">第十章</a>、<em>自然语言处理</em>中具体说的是机器学习库。尽管如此，对于任何想从事机器学习的人来说，最好至少了解以下列表中的一个:Python、R和MATLAB。</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Prototyping the first machine learning app</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">第一个机器学习应用的原型</h1>
                
            
            
                
<p>通常，在为移动设备实现机器学习应用程序之前，您希望做一个快速而肮脏的原型，只是为了检查您的想法。当你意识到你最初认为的模型能很好地解决你的问题，而实际上却不能时，这可以节省很多时间。制作原型的最快方法是使用上一节中列出的Python或R工具。</p>
<p>Python是一种通用编程语言，具有丰富的基础设施和活跃的社区。它的语法在许多方面与Swift的相似。在本书中，我们将使用它进行原型开发，使用Swift进行实际开发。</p>
<p>当你测试了你的想法，并且模型原型如你所期望的那样工作时，你就可以开始考虑如何把它移植到iOS上了。这里有几个选项:</p>
<p>仅推断选项:</p>
<ul>
<li>检查核心ML，以及它支持的Python库的列表。也许，您将能够以Core ML格式导出您的模型，并在设备上运行它。</li>
<li>如果核心ML不支持，为您的模型编写自定义转换器。</li>
</ul>
<p>训练和推理选项:</p>
<ul>
<li>从头开始写算法。在本书中，我们正在实现一系列机器学习算法，所以你会发现这并不困难。尽管如此，这仍然是最耗时的选择，而且模型的结果可能会有很大的不同。</li>
<li>查看可用的iOS兼容库(参见第十一章、<em xmlns:epub="http://www.idpf.org/2007/ops">机器学习库</em>)。</li>
</ul>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Tools</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">工具</h1>
                
            
            
                
<p>以下是我们在以下教程中使用的工具列表:</p>
<ul>
<li><strong>自制</strong>:这是一个macOS的包管理器。官方网站:<a href="https://brew.sh/" target="_blank">https://brew.sh/</a>。</li>
<li><strong> Python </strong>:这是一种通用编程语言，流行于机器学习和数据科学。官方网站:<a href="https://www.python.org/" target="_blank">https://www.python.org/</a>。</li>
<li>pip:这是一个Python包管理器。与CocoaPods不同，它在全局范围内安装库，而不是以基于项目的方式。</li>
<li><strong> Virtualenv </strong>:这是一个用不同的Python版本和库集创建单独的Python环境的工具。</li>
<li>这是一个用于科学计算的交互式Python REPL。</li>
<li>Jupyter:这是一个IPython的web-GUI。官方网站:<a href="http://jupyter.org/" target="_blank">http://jupyter.org/</a>。</li>
<li><strong> Graphviz </strong>:这是一个图形可视化的开源工具。我们在本章中使用它来绘制模型的内部结构。官方网站:<a href="http://www.graphviz.org/" target="_blank">http://www.graphviz.org/</a>。</li>
</ul>
<p>Python包如下所示:</p>
<ul>
<li>这是一个基于Python的数学、科学和工程开源软件生态系统。官方网站:<a href="https://www.scipy.org/" target="_blank">https://www.scipy.org/</a>。<a href="https://www.scipy.org/" target="_blank"/></li>
<li>这是一个数字库。</li>
<li><kbd>matplotlib</kbd>:这是一个流行的绘图库。</li>
<li><kbd>pydotplus</kbd>:这是一个用于树可视化的库，是Graphviz的对应物。</li>
<li><kbd>scikit-learn</kbd>:这是一个流行的机器学习库。官方网站:<a href="http://scikit-learn.org/" target="_blank">http://scikit-learn.org/</a>。<a href="http://scikit-learn.org/" target="_blank"/></li>
<li><kbd>coremltools</kbd>:是苹果公司的一个软件包，用于将scikit-learn模型保存为核心ML格式。官方网站:<a href="https://pypi.python.org/pypi/coremltools" target="_blank">https://pypi.python.org/pypi/coremltools</a>。</li>
</ul>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Setting up a machine learning environment</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">设置机器学习环境</h1>
                
            
            
                
<p>由于Python 2和Python 3之间的向后兼容性问题，Python社区出现了明显的分化——许多活跃的项目仍然使用Python 2.7(2010年发布)，而许多新工具并不向后兼容，因为它们基于Python 3.x。一些工具同时拥有两个版本。macOS预装了旧版Python 2 . 7 . 10(2015年发布)，而在撰写本书时最新版本是Python 3.6.1。如果没有明确提到相反的情况，我们将在本书中使用系统的默认Python。主要原因是核心ML工具只与Python 2.7.x兼容。</p>
<p>下面的步骤假设您没有安装其他Python版本(比如Anaconda，或者通过自制程序)，除了系统的默认版本。如果您安装了其他Python发行版，您可能知道如何安装所需的包和创建虚拟环境。</p>
<p>首先，在终端中，转到用户的根目录:</p>
<pre><strong>&gt; cd ~</strong></pre>
<p>在Mac系统上，默认情况下，您用来登录的用户具有有限的特权，这是为了增强安全措施而设计的。使用<kbd>sudo</kbd>命令允许您根据具体情况使用附加权限执行任务。该过程有助于通过避免意外动作来简化安全特征。</p>
<p>pip是一个Python包管理器。不像最新版本的Python，系统的默认没有。相反，它应该有旧的遗留包管理器<kbd>easy_install</kbd>。除了pip安装，不要用它做任何事情；这可能会搞乱你的系统。安装东西需要sudo权限:</p>
<pre><strong>&gt; sudo easy_install pip</strong>  </pre>
<p>如果您预先安装了某个版本的pip，您可以使用以下命令将其升级到最新版本:</p>
<pre><strong>&gt; pip install --upgrade pip</strong>  </pre>
<p>许多第三方程序正在使用系统的Python版本，因此为了不干扰它们，更安全的做法是创建单独的Python环境，并在其中安装我们需要的所有依赖项。Virtualenv是一个用于创建独立Python环境的工具。它在macOS Python中也是不存在的，但在从Python 3.3及更高版本开始的所有最新发行版中默认存在。pip安装成功后，我们可以用它来安装<kbd>virtualenv</kbd>:</p>
<pre><strong>&gt; pip install -U virtualenv</strong></pre>
<p><kbd>-U</kbd>选项告诉pip只为当前用户安装软件包。</p>
<p>千万不要用<kbd>sudo</kbd>跑<kbd>pip</kbd>。无论何时你需要<kbd>sudo</kbd>来运行它，你都知道你做错了。</p>
<p>要为图书创建虚拟环境，请运行:</p>
<pre><strong>&gt; cd ~</strong>
<strong>&gt; virtualenv swift-ml-book</strong>
  </pre>
<p>这将创建<kbd>swift-ml-book</kbd>文件夹，并在其中创建Python、pip和其他工具的单独副本。要切换到此环境(激活环境)，请运行以下命令:</p>
<pre><strong>&gt; source swift-ml-book/bin/activate</strong></pre>
<p>现在<kbd>swift-ml-book</kbd>在终端中预置所有的命令，这样你就知道你现在在哪个环境中了。当您想要停用Python 3环境时，运行:</p>
<pre><strong>&gt; deactivate</strong>  </pre>
<p>最后，我们可以安装库；确保您已经激活了环境:</p>
<pre><strong>&gt; pip install -U numpy scipy matplotlib ipython jupyter scikit-learn pydotplus coremltools</strong></pre>
<p>您应该会在命令行上看到一个很长的输出；下载和安装所有依赖项可能需要一段时间。最后，您应该会看到消息<kbd>Successfully installed ...</kbd>，以及已安装软件包的列表。它将比我们提供给pip的那个长得多，因为它包含了一堆暂时的依赖关系。</p>
<p>最重要的是，现在您的终端中应该有两个新命令:<kbd>ipython</kbd>和<kbd>jupyter notebook</kbd>。第一个运行交互式IPython REPL，第二个运行基于网络的IPython GUI，在那里你可以创建笔记本——交互式文档，类似于Swift playgrounds。</p>
<p>此外，我们应该安装Graphviz——一个图形可视化的开源工具。它可以从官方网站下载，或使用自制软件安装:</p>
<pre><strong>&gt; brew install graphviz</strong> </pre>
<p>如果你没有自制软件，安装它。安装说明应该如下所示，但是您最好查看官方网站(<a href="https://brew.sh/" target="_blank">https://brew.sh/</a>)以获得确切的命令:</p>
<pre><strong>&gt; ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"</strong>
  </pre>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>IPython notebook crash course</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">IPython笔记本速成班</h1>
                
            
            
                
<p>如果您熟悉Python和Jupyter笔记本，可以跳过这一部分。</p>
<p>IPython notebook及其基于web的GUI Jupyter是数据驱动的机器学习开发的标准工具。Jupyter也是学习Python及其库的便利工具。您可以将代码片段与markdown格式的注释结合起来。您还可以就地执行代码片段，将它们一个接一个地链接起来，并立即看到计算的结果。它还允许在笔记本电脑中嵌入交互式图表、表格、视频和其他多媒体对象。我们将使用Jupyter笔记本来编写我们模型的快速原型。</p>
<p>要创建新的笔记本，请在终端中运行:</p>
<pre><strong>&gt; jupyter notebook</strong>  </pre>
<p>您将看到类似如下的输出:</p>
<pre><strong>[I 10:51:23.269 NotebookApp] Serving notebooks from local directory: ...</strong>
<strong>[I 10:51:23.269 NotebookApp] 0 active kernels </strong>
<strong>[I 10:51:23.270 NotebookApp] The Jupyter Notebook is running at: http://localhost:8888/?token=3c073db5636e366fd750e661cc597652025fdbf41162c125</strong>
<strong>[I 10:51:23.270 NotebookApp] Use Control-C to stop this server and shut down all kernels (twice to skip confirmation).</strong> </pre>
<p>请注意输出中的那些长URL:<kbd>http://localhost:8888/token=3c073db5636e366fd750e661cc597652025fdbf41162c125</kbd>。</p>
<p>将此地址复制并粘贴到您的浏览器中，以打开Jupyter。</p>
<p>在Python 3中，Jupyter会自动在你的默认浏览器窗口中打开一个新标签，地址为<kbd>http://localhost:8888/tree</kbd>。</p>
<p>按下New按钮，并在下拉菜单中选择Python 2。这将在新的浏览器选项卡中打开一个新的笔记本。</p>
<p>要停止IPython，你需要在终端中按下<em> Ctrl </em> + <em> C </em>，并在提示时输入<kbd>y</kbd>。退出前，不要忘记在笔记本中保存您的更改。</p>
<p>让我们尝试一些东西来了解它是如何工作的。在笔记本的顶部单元格中，打印<kbd>import this</kbd>并按<em> Shift </em> + <em> Enter </em>。您将看到<kbd>The Zen of Python</kbd>——每个Python程序员都应该遵守的规则的简短列表。我们也将努力遵守它们。Python风格指南的扩展版本被称为<strong> PEP 8 </strong>，可以在这里找到:<a href="http://python.org/dev/peps/pep-0008/" target="_blank">python.org/dev/peps/pep-0008/</a>。</p>
<p>在新单元格中键入:</p>
<pre>a = 2**32 
b = 64**(1/2.) 
a = a+b 
a </pre>
<p>然后，按下<em> Shift </em> + <em> Enter </em>。这将计算2 <sup> 32 </sup> + √64，并将结果存储到变量<kbd>a</kbd>中。不熟悉的操作员<kbd>**</kbd>是幂，<kbd>a</kbd>和<kbd>b</kbd>是变量(没有<kbd>let</kbd>或<kbd>var</kbd>)。整数<kbd>1</kbd>和浮点<kbd>2</kbd>之间的类型转换是隐式发生的。Python是弱类型的，所以可以将变量<kbd>b</kbd>的浮点值赋给整数变量<kbd>a</kbd>。Jupyter输出单元格中最后一行的值。另外，请注意，变量<kbd>a</kbd>和<kbd>b</kbd>现在在下一个单元格中可用。</p>
<p>如果你不懂Python，没关系——这是一门相对简单的语言。关于Python的速成课程，请访问:<a href="https://learnxinyminutes.com/docs/python/" target="_blank">https://learnxinyminutes.com/docs/python/</a>。</p>
<p>要查看如何添加和格式化注释，请将光标放在新的单元格中，从仪器面板单元格的下拉菜单中选择，键入<kbd>Markdown</kbd>，并将一些markdown片段放入单元格中；例如，下面的代码片段是一个简单的文本，带有MathJax格式的公式和一张图片:</p>
<pre># This is a sample text: 
$$Formula = {Numerator over Denominator}$$ 
![]( https://imgs.xkcd.com/comics/conditional_risk.png) 
&gt; Sample text to demonstrate the few markdown feature available to easily create documents. [Packt Hyperlink](http://packtpub.com/)  </pre>
<p>您将得到一个格式良好的MathJax公式、一个图像和一些格式化的文本。如果你想知道更多关于降价的格式，只需谷歌一下降价指南，或者小抄。</p>
<p>您还可以从笔记本中执行bash命令；只需在它们前面加上一个感叹号:</p>
<pre>In []: 
! ls 
 
Out[]: 
The content of your work folder goes here... </pre>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Time to practice</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">练习时间到了</h1>
                
            
            
                
<p>在下面的章节中，我们将深入机器学习实践，感受一下它是什么样子的。就像在戏剧中一样，在机器学习中，你有一个角色列表和一个行为列表。</p>
<p>两个主要人物是:</p>
<ul>
<li>资料组</li>
<li>模型</li>
</ul>
<p>三个主要法案是:</p>
<ul>
<li>数据集准备</li>
<li>模特培训</li>
<li>模型评估</li>
</ul>
<p>我们将经历所有这些行为，到本章结束时，我们将有我们的第一个训练模型。首先，我们需要定义一个问题，然后我们可以开始用Python编写一个原型。我们的目的地是Swift中的一个工作模型。不过，不要把问题本身看得太重，因为作为第一个练习，我们要解决一个虚构的问题。</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Machine learning for extra-terrestrial life explorers</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">外星生命探索者的机器学习</h1>
                
            
            
                
<p>Swift无疑是未来的编程语言。在最近的几年里，我们期望看到Swift被雇佣来为智能侦察机器人编程，这些机器人将探索外星球和星球上的生命形式。这些机器人应该能够识别和分类他们将遇到的外星人。让我们建立一个模型，利用它们特有的特征来区分两个外来物种。</p>
<p>这颗遥远星球的生物圈主要由两个物种组成:夜间掠食者rabbosauruses，以及和平的食草性鸭嘴兽(见下图)。机器人只配备了传感器来测量每个个体的三个特征:长度(以米为单位)、颜色和蓬松度。</p>
<div><img height="278" src="img/9e718727-51ff-4520-89a4-0b6283ca2507.png" width="319"/></div>
<p>图2.1:我们第一个机器学习任务中感兴趣的对象。图片由Mykola Sosnovshchenko提供。</p>
<p>本章Python部分的完整代码可以在这里找到:<kbd>ML_Intro.ipynb</kbd>。</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Loading the dataset</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">加载数据集</h1>
                
            
            
                
<p>创建并打开一个新的IPython笔记本。在该章的补充材料中，可以看到文件<kbd>extraterrestrials.csv</kbd>。将其复制到创建笔记本的同一文件夹中。在笔记本的第一个单元格中，执行神奇的命令:</p>
<pre>In []: 
%matplotlib inline </pre>
<p>这是将来在笔记本中查看内联图所必需的。</p>
<p>我们用于数据集加载和操作的库是<kbd>pandas</kbd>。让我们导入它，并加载<kbd>.csv</kbd>文件:</p>
<pre>In []: 
import pandas as pd 
df = pd.read_csv('extraterrestrials.csv', sep='t', encoding='utf-8', index_col=0) </pre>
<p>对象<kbd>df</kbd>是一个数据框。这是一个类似表格的数据结构，用于对不同的数据类型进行有效的操作。要查看内部内容，请执行:</p>
<pre>In []: 
df.head() 
Out[]: </pre>
<table class="MsoTableGrid">
<tbody>
<tr>
<td/>
<td>
<p><strong>长度</strong></p>
</td>
<td>
<p><strong>颜色</strong></p>
</td>
<td>
<p><strong>蓬松</strong></p>
</td>
<td>
<p><strong>标签</strong></p>
</td>
</tr>
<tr>
<td>
<p><strong> 0 </strong></p>
</td>
<td>
<p>27.545139</p>
</td>
<td>
<p>金银铜镍装饰合金</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>拉布斯龙</p>
</td>
</tr>
<tr>
<td>
<p><strong> 1 </strong></p>
</td>
<td>
<p>12.147357</p>
</td>
<td>
<p>金银铜镍装饰合金</p>
</td>
<td>
<p>错误的</p>
</td>
<td>
<p>扁猪</p>
</td>
</tr>
<tr>
<td>
<p><strong> 2 </strong></p>
</td>
<td>
<p>23.454173</p>
</td>
<td>
<p>浅黑色</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>拉布斯龙</p>
</td>
</tr>
<tr>
<td>
<p><strong> 3 </strong></p>
</td>
<td>
<p>29.956698</p>
</td>
<td>
<p>金银铜镍装饰合金</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>拉布斯龙</p>
</td>
</tr>
<tr>
<td>
<p><strong> 4 </strong></p>
</td>
<td>
<p>34.884065</p>
</td>
<td>
<p>浅黑色</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>拉布斯龙</p>
</td>
</tr>
</tbody>
</table>
<p>这将打印表格的前五行。前三列(长度、颜色和蓬松度)是特性，最后一列是类标签。</p>
<p>我们总共有多少样品？运行此代码以找出:</p>
<pre>In []: 
len(df) 
Out[]: 
1000 </pre>
<p>看起来最开始的样本是鸭嘴龙。让我们随机提取五个样本，看看它在数据集的其他部分是否成立:</p>
<pre>In []: 
df.sample(5) 
Out[]: </pre>
<table class="MsoTableGrid">
<tbody>
<tr>
<td/>
<td>
<p><strong>长度</strong></p>
</td>
<td>
<p><strong>颜色</strong></p>
</td>
<td>
<p><strong>毛茸茸的</strong></p>
</td>
<td>
<p><strong>标签</strong></p>
</td>
</tr>
<tr>
<td>
<p><strong> 565 </strong></p>
</td>
<td>
<p>17.776481</p>
</td>
<td>
<p>紫色圆点</p>
</td>
<td>
<p>错误的</p>
</td>
<td>
<p>扁猪</p>
</td>
</tr>
<tr>
<td>
<p><strong> 491 </strong></p>
</td>
<td>
<p>19.475358</p>
</td>
<td>
<p>浅黑色</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>拉布斯龙</p>
</td>
</tr>
<tr>
<td>
<p><strong> 230 </strong></p>
</td>
<td>
<p>15.453365</p>
</td>
<td>
<p>紫色圆点</p>
</td>
<td>
<p>错误的</p>
</td>
<td>
<p>扁猪</p>
</td>
</tr>
<tr>
<td>
<p><strong> 511 </strong></p>
</td>
<td>
<p>17.408234</p>
</td>
<td>
<p>紫色圆点</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>扁猪</p>
</td>
</tr>
<tr>
<td>
<p><strong> 875 </strong></p>
</td>
<td>
<p>24.105315</p>
</td>
<td>
<p>浅黑色</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>拉布斯龙</p>
</td>
</tr>
</tbody>
</table>
<p> </p>
<p>嗯，这没有什么帮助，因为用这种方式分析表格内容太单调乏味了。我们需要一些更高级的工具来执行描述性统计计算和数据可视化。</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Exploratory data analysis</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">探索性数据分析</h1>
                
            
            
                
<p>首先，我们想知道每个班级有多少人。这很重要，因为如果类别分布非常不平衡(例如1到100)，我们将在训练分类模型时遇到问题。您可以通过点符号获得数据框列。例如，<kbd>df.label</kbd>将返回标签列作为新的数据框。数据框类具有各种用于计算汇总统计数据的有用方法。<kbd>value_counts()</kbd>方法返回数据帧中每个元素类型的计数:</p>
<pre>In []: 
df.label.value_counts() 
Out[]: 
platyhog       520 
rabbosaurus    480 
Name: label, dtype: int64 </pre>
<p>对于我们的目的来说，职业分布看起来还不错。现在让我们来探索一下特性。</p>
<p>我们需要将我们的数据按类别分组，并分别计算特征统计数据，以查看生物类别之间的差异。这可以使用<kbd>groupby()</kbd>方法来完成。它采用您要用来对数据进行分组的列的标签:</p>
<pre>In []: 
grouped = df.groupby('label') </pre>
<p>分组后的数据框具有与原始数据框完全相同的方法和列标注。让我们来看看长度特征的描述性统计数据:</p>
<pre>In []: 
grouped.length.describe() 
Out[]: </pre>
<table class="MsoTableGrid">
<tbody>
<tr>
<td>
<p><strong>标签</strong></p>
</td>
<td>
<p><strong>计数</strong></p>
</td>
<td>
<p><strong>的意思是</strong></p>
</td>
<td>
<p>标准。</p>
</td>
<td>
<p><strong>最小。</strong></p>
</td>
<td>
<p><strong> 25% </strong></p>
</td>
<td>
<p><strong> 50% </strong></p>
</td>
<td>
<p><strong> 75% </strong></p>
</td>
<td>
<p>最大值。</p>
</td>
</tr>
<tr>
<td>
<p><strong>鸭嘴兽</strong></p>
</td>
<td>
<p>520.0</p>
</td>
<td>
<p>19.894876</p>
</td>
<td>
<p>4.653044</p>
</td>
<td>
<p>4.164723</p>
</td>
<td>
<p>16.646311</p>
</td>
<td>
<p>20.168655</p>
</td>
<td>
<p>22.850191</p>
</td>
<td>
<p>32.779472</p>
</td>
</tr>
<tr>
<td>
<p><strong> Rabbosaurus </strong></p>
</td>
<td>
<p>480.0</p>
</td>
<td>
<p>29.984387</p>
</td>
<td>
<p>5.072308</p>
</td>
<td>
<p>16.027639</p>
</td>
<td>
<p>26.721621</p>
</td>
<td>
<p>29.956092</p>
</td>
<td>
<p>33.826660</p>
</td>
<td>
<p>47.857896</p>
</td>
</tr>
</tbody>
</table>
<p>从这张表中我们能学到什么？鸭嘴兽的平均长度约为20米，标准偏差约为5。Rabbosauruses平均有30米长，标准偏差为5。最小的鸭嘴龙体长约4米，最大的rabbosaurus体长约48米。这是一个很大的数字，但比最大的地球生命形式要少(例如，见Amphicoelias fragillimus)。</p>
<p>可以使用熟悉的<kbd>value_counts()</kbd>方法查看颜色分布:</p>
<p>我们可以使用<kbd>unstack()</kbd>和<kbd>plot()</kbd>方法，用一种更吸引人的形式来表示这一点:</p>
<pre>In []: 
grouped.color.value_counts() 
Out[]: 
label        color            
platyhog     light black         195 
             purple polka-dot    174 
             pink gold           151 
rabbosaurus  light black         168 
             pink gold           156 
             space gray          156 
Name: color, dtype: int64 </pre>
<p>图2.2:颜色分布</p>
<pre>In []: 
plot = grouped.color.value_counts().unstack().plot(kind='barh', stacked=True, figsize=[16,6], colormap='autumn') 
Out[]: </pre>
<div><strong><img src="img/c3d6b93d-2224-46fa-91ed-5f455903d818.png"/></strong></div>
<p>看起来紫色圆点是一个<kbd>platyhog</kbd>类的强预测符。但是，如果我们看到一个太空灰色的个体，我们可以肯定我们应该赶快跑。</p>
<p>以类似的方式，蓬松度分布可以使用以下方式可视化:</p>
<p>图2.3:蓬松度分布</p>
<pre>In []: 
plot = grouped.fluffy.value_counts().unstack().plot(kind='barh', stacked=True, figsize=[16,6], colormap='winter') 
Out[]: </pre>
<div><img src="img/560fb2b0-5a06-4520-a4db-1788e4794d16.png"/></div>
<p>鸭嘴龙有三种颜色:浅黑色、玫瑰金和太空灰。其中90%是蓬松的(剩下的10%大概是又老又秃的)。另一方面，鸭嘴兽可以是浅黑色、玫瑰金或紫色圆点。30%是毛毛(可能是变种人？).</p>
<p>对于更复杂的数据可视化，我们需要<kbd>matplotlib</kbd>绘图库:</p>
<p>绘制长度分布直方图:</p>
<pre>In []: 
import matplotlib.pyplot as plt </pre>
<p>图2.4:长度分布</p>
<pre>In []: 
plt.figure() 
plt.hist(df[df.label == 'rabbosaurus'].length, bins=15, normed=True) 
plt.hist(df[df.label == 'platyhog'].length, bins=15, normed=True) 
plt.title("Length Distribution Histogram") 
plt.xlabel("Length") 
plt.ylabel("Frequency") 
fig = plt.gcf() 
plt.show() 
Out[]: </pre>
<div><img height="309" src="img/702e9008-b4ac-4e1f-b001-fca8c3c2407d.png" width="463"/></div>
<p>总的来说，人们可以说鸭嘴兽更小，但大约在20到30米之间有很大的重叠范围，仅长度不足以区分两个类别。</p>
<p>数据预处理</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Data preprocessing</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">在下面几节中，我们将看看不同的数据处理技术。</h1>
                
            
            
                
<p>转换分类变量</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Converting categorical variables</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">正如您已经注意到的，数据框可以包含不同类型数据的列。要查看每个列属于哪种类型，我们可以检查数据框的<kbd>dtypes</kbd>属性。您可以将Python属性视为类似于Swift属性:</h1>
                
            
            
                
<p>虽然<kbd>length</kbd>和<kbd>fluffy</kbd>列包含预期的数据类型，但是<kbd>color</kbd>和<kbd>label</kbd>的类型不太透明。那些是什么东西？这意味着这些列可以包含任何类型的对象。目前，我们有字符串，但我们真正想要的是分类变量。如果你不记得上一章的内容，分类变量就像Swift枚举。幸运的是，data frame有简便的方法将列从一种类型转换为另一种类型:</p>
<pre>In []: 
df.dtypes 
Out[]: 
length    float64 
color      object 
fluffy       bool 
label      object 
dtype: object </pre>
<p>就是这样。让我们检查一下:</p>
<pre>In []: 
df.color = df.color.astype('category') 
df.label = df.label.astype('category')  </pre>
<p><kbd>color</kbd>和<kbd>label</kbd>现在都是范畴。要查看这些类别中的所有颜色，请执行:</p>
<pre>In []: 
df.dtypes 
Out []: 
length     float64 
color     category 
fluffy        bool 
label     category 
dtype: object  </pre>
<p>不出所料，我们有四种颜色。<kbd>'|S16'</kbd>代表长度为16个字符的字符串。</p>
<pre>In []: 
colors = df.color.cat.categories.get_values().astype('string') 
colors 
Out[]: 
array(['light black', 'pink gold', 'purple polka-dot', 'space gray'], dtype='|S16') </pre>
<p>从标注中分离要素</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Separating features from labels</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">让我们将我们的特征从标签中分离出来，因为我们将分别将它们输入到模型中:</h1>
                
            
            
                
<p>这个可怕的结构<kbd>df.loc[:,:'fluffy']</kbd>告诉数据帧我们想要所有的行(第一列)，以及从第一列开始的列，以<kbd>'fluffy'</kbd>结束。</p>
<pre>In []: 
features = df.loc[:,:'fluffy'] 
labels = df.label </pre>
<p>一键编码</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>One-hot encoding</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">大多数机器学习算法都不能处理分类变量，所以通常我们希望将它们转换成一个热点向量(统计学家更喜欢称它们为<strong>虚拟变量</strong>)。我们先转换，然后我会解释这是什么:</h1>
                
            
            
                
<p>Most of the machine learning algorithms can't work with the categorical variables, so usually we want to convert them to the one-hot vectors (statisticians prefer to call them <strong>dummy variables</strong>). Let's convert first, and then I will explain what this is:</p>
<pre>In []: 
features = pd.get_dummies(features, columns = ['color']) 
features.head() 
Out[]: </pre>
<table class="MsoTableGrid">
<tbody>
<tr>
<td><kbd>length</kbd></td>
<td>
<p><kbd>fluffy</kbd></p>
</td>
<td>
<p><kbd>color_light black</kbd></p>
</td>
<td>
<p><kbd>color_pink gold</kbd></p>
</td>
<td>
<p><kbd>color_purple polka-dot</kbd></p>
</td>
<td>
<p><kbd>color_space gray</kbd></p>
</td>
<td>
<p>0</p>
</td>
</tr>
<tr>
<td>
<p>27.545139</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>一</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>一</p>
</td>
</tr>
<tr>
<td>
<p>12.147357</p>
</td>
<td>
<p>错误的</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>一</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>2</p>
</td>
</tr>
<tr>
<td>
<p>23.454173</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>一</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>3</p>
</td>
</tr>
<tr>
<td>
<p>29.956698</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>一</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>四</p>
</td>
</tr>
<tr>
<td>
<p>34.884065</p>
</td>
<td>
<p>真实的</p>
</td>
<td>
<p>一</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
<td>
<p>0</p>
</td>
</tr>
</tbody>
</table>
<p>所以现在，我们有四列:<kbd>color_light black</kbd>、<kbd>color_pink gold</kbd>、<kbd>color_purple polka dot</kbd>和<kbd>color_space gray</kbd>，而不是一列<kbd>color</kbd>。每个样本的颜色在相应的列中被编码为1。如果我们可以简单地用1到4的数字来代替颜色，为什么我们还需要这个呢？这就是问题所在:为什么我们更喜欢1比4，而不是4比1，或者2的幂，或者质数？这些颜色本身并不携带任何与之相关的定量信息。它们不能从最大到最小排序。如果我们人工引入这些信息，机器学习算法可能会试图利用这些无意义的信息，最终我们会发现分类器在没有规律的地方发现规律。</p>
<p>拆分数据</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Splitting the data</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">最后，我们希望将数据分成训练集和测试集。我们将只在训练集上训练我们的分类器，所以它永远不会看到测试集，直到我们想要评估它的性能。这是非常重要的一步，因为正如我们将在未来看到的，测试集上的预测质量可能与训练集上测量的质量有很大不同。数据拆分是专门针对机器学习任务的操作，所以我们将导入scikit-learn(一个机器学习包)并使用其中的一些函数:</h1>
                
            
            
                
<p>现在，我们有700个训练样本，每个样本有6个特征，300个测试样本有相同数量的特征。</p>
<pre>In []: 
from sklearn.model_selection import train_test_split 
X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, random_state=42) 
X_train.shape, y_train.shape, X_test.shape, y_test.shape 
Out[]: 
 ((700, 6), (700,), (300, 6), (300,)) </pre>
<p>到处都是决策树</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Decision trees everywhere</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">我们将在第一次机器学习练习中使用的算法被称为<strong>决策树分类器</strong>。决策树是一组描述决策过程的规则(例如，参见<em>图2.5 </em>)。</h1>
                
            
            
                
<p>决策树广泛应用于机器学习之外的不同领域；例如，在商业分析中。决策树的流行是可以理解的:它们易于解释，并且易于可视化。多年来，它们都是使用领域专家的知识手工构建的。幸运的是，现在我们有了机器学习算法，可以很容易地将几乎任何带标签的数据集变成决策树。</p>
<p>训练决策树分类器</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Training the decision tree classifier</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">让我们学习如何训练决策树分类器，如下面的代码片段所示:</h1>
                
            
            
                
<p>我们最感兴趣的是<kbd>DecisionTreeClassifier</kbd>的职业属性:</p>
<pre>In []: 
from sklearn import tree 
tree_model = tree.DecisionTreeClassifier(criterion='entropy', random_state=42) 
tree_model = tree_model.fit(X_train, y_train) 
tree_model 
Out[]: 
DecisionTreeClassifier(class_weight=None,  
            criterion='entropy', max_depth=None, 
            max_features=None, max_leaf_nodes=None, 
            min_impurity_split=1e-07, min_samples_leaf=1, 
            min_samples_split=2, min_weight_fraction_leaf=0.0, 
            presort=False, random_state=42, splitter='best') </pre>
<p><kbd>criterion</kbd>:估计最佳分区的方法(参见<em>决策树学习如何工作</em>部分)。</p>
<ul>
<li><kbd>max_depth</kbd>:最大树深。</li>
<li><kbd>max_features</kbd>:在一次分割中要考虑的属性的最大数量。</li>
<li><kbd>min_samples_leaf</kbd>:叶子中对象的最小数量；例如，如果它等于<kbd>3</kbd>，那么树将只生成那些对于至少三个对象为真的分类规则。</li>
<li>这些属性被称为<strong>超参数</strong>。它们与模型参数不同:前者是用户可以调整的，后者是机器学习算法学习的。在决策树中，参数是其节点中的特定规则。树超参数必须根据输入数据进行调整，这通常使用交叉验证来完成(请继续关注)。</li>
</ul>
<p>决策树分类器文档:<a href="http://scikit-learn.org/stable/modules/tree.html" target="_blank">http://scikit-learn.org/stable/modules/tree.html</a>。</p>
<p>模型的属性不是由模型本身调整(学习)的，而是可用于用户调整的，这些属性被称为超参数。在决策树模型的情况下，这些超参数是<kbd>class_weight</kbd>、<kbd>criterion</kbd>、<kbd>max_depth</kbd>、<kbd>max_features</kbd>等等。它们就像旋钮一样，你可以根据自己的具体需求调节型号。</p>
<p>树木可视化</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Tree visualization</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">让我们看一下可视化树的代码，如下所示:</h1>
                
            
            
                
<p>定义一个变量来存储特征的所有名称:</p>
<pre>In []: 
labels = df.label.astype('category').cat.categories 
labels = list(labels) 
labels 
Out[]: 
[u'platyhog', u'rabbosaurus']  </pre>
<p>然后，使用<kbd>export_graphviz</kbd>函数创建<kbd>graph</kbd>对象:</p>
<pre>In []: 
feature_names = map(lambda x: x.encode('utf-8'), features.columns.get_values()) 
feature_names 
Out[]: 
['length', 
 'fluffy', 
 'color_light black', 
 'color_pink gold', 
 'color_purple polka-dot', 
 'color_space gray'] </pre>
<p>将标记放在下一个单元格中，以查看新创建的文件，如下所示:</p>
<pre>In []: 
import pydotplus  
dot_data = tree.export_graphviz(tree_model, out_file=None,  
                                feature_names=feature_names,   
                                 class_names=labels,   
                                 filled=True, rounded=True,   
                                 special_characters=True) 
dot_data 
Out[]: 
u'digraph Tree {nnode [shape=box, style="filled, rounded", color="black", fontname=helvetica] ;nedge [fontname=helvetica] ;n0 [label=&lt;length &amp;le; 26.6917&lt;br/&gt;entropy = 0.9971&lt;br/&gt;samples = 700&lt;br/&gt;value = [372, ... 
In []: 
graph = pydotplus.graph_from_dot_data(dot_data.encode('utf-8')) 
graph.write_png('tree1.png') 
Out[]: 
True </pre>
<p>图2.5:决策树结构及其片段的特写</p>
<pre>![](tree1.png) </pre>
<div><img src="img/b4390d98-fb7a-4416-a9b5-85e743f67794.png"/></div>
<p>上图显示了我们的决策树的样子。在训练期间，它倒过来生长。数据(特征)从树根(顶部)到树叶(底部)穿过它。为了使用这个分类器从我们的数据集中预测样本的标签，我们应该从根开始，并且移动直到我们到达叶子。在每个节点中，将一个特征与某个值进行比较；例如，在根节点中，树检查长度是否&lt; 26.0261。如果条件满足，我们沿左分支移动；如果没有，沿着右边。</p>
<p>让我们仔细看看树的一部分。除了每个节点中的条件，我们还有一些有用的信息:</p>
<p>熵值</p>
<ul>
<li>支持此节点的训练集中的样本数</li>
<li>有多少样本支持每个结果</li>
<li>现阶段最有可能的结果</li>
<li>做预测</li>
</ul>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Making predictions</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">我们使用<kbd>predict</kbd>函数来获取两个样本的结果标签。第一个是浅黑色，毛绒绒的生物，24米长。第二个是紫色圆点，不蓬松，长34米。如果您已经不记得每个功能的含义，请查阅<kbd>feature_names</kbd>变量:</h1>
                
            
            
                
<p>我们的模型预测第一个样本为<kbd>platyhog</kbd>，第二个样本为<kbd>rabbosaurus</kbd>。决策树还可以提供概率输出(它对预测有多大把握):</p>
<pre>In []: 
samples = [[24,1,0,1,0,0], [34,0,0,0,1,0]] 
tree_model.predict(samples) 
Out[]: 
array([u'platyhog', u'rabbosaurus'], dtype=object) </pre>
<p>该数组包含两个嵌套数组，每个嵌套数组对应一个预测。嵌套数组中的元素是样本属于相应类别的概率。这意味着我们的模型100%确定第一个样本属于第一类，100%确定第二个样本属于第二类。</p>
<pre>In []: 
tree_model.predict_proba(samples) 
Out[]: 
array([[ 1.,  0.], 
       [ 0.,  1.]]) </pre>
<p>但是我们对这些预测有多大把握呢？我们有一整套不同的工具来评估模型的准确性，最简单的是内置的评分函数。</p>
<p>评估准确性</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Evaluating accuracy</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">得分函数使用数据计算模型的准确性。让我们在训练集上计算我们的模型的准确性:</h1>
                
            
            
                
<p>哇，看起来我们的模型100%准确。这不是很好的结果吗？让我们先不要急着检查我们的模型。对测试集的评估是机器学习成功的黄金标准:</p>
<pre>In []: 
tree_model.score(X_train, y_train) 
Out[]: 
1.0 </pre>
<p>现在更糟了。刚刚发生了什么？在这里，我们第一次面临过度拟合的问题，当模型试图适应数据中的每一个怪癖。我们的模型根据训练数据进行了大量的自我调整，以至于在以前看不到的数据上，它缺乏概括的能力。由于任何真实世界的数据都包含噪声和信号，我们希望我们的模型适合信号并忽略噪声成分。过拟合是机器学习中最常见的问题。数据集太小或者模型太灵活是很常见的。相反的情况称为拟合不足，即模型不能很好地拟合复杂的数据:</p>
<pre>In []: 
tree_model.score(X_test, y_test) 
Out[]: 
0.87666666666666671 </pre>
<p>图2.6:拟合不足(右栏)与拟合良好(中间栏)与拟合过度(右栏)。顶行显示分类问题，底行显示回归问题。</p>
<div><img height="328" src="img/5c582b69-1937-4fc2-a4d1-0010adb71e30.png" width="461"/></div>
<p>任何人在网上商店看了某件商品，然后在网上到处看到同一商品的定向广告时，都熟悉过度合身的问题。这个项目很可能不再相关，但机器学习算法已经过度适应了有限的数据集，现在你打开的每个页面上都有小饰品兔子(或你在电子商店看到的任何东西)。</p>
<p>无论如何，我们必须以某种方式与过度拟合作斗争。那么，我们能做什么呢？最简单的解决方案是让模型更简单，灵活性更低(或者说机器学习，减少模型容量)。</p>
<p>调谐超参数</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Tuning hyperparameters</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">简化决策树最简单的方法是限制它的深度。现在有多深？你可以在<em>图2.5 </em>中看到20个裂口，或者21层。同时，我们只有三个特点。如果我们考虑一次性编码的分类颜色，实际上有六种。让我们积极地限制树的最大深度，以便与特征的数量相当。<kbd>tree_model</kbd>对象有一个<kbd>max_depth</kbd>属性，所以我们将其设置为小于特征的数量:</h1>
                
            
            
                
<p>在这些操作之后，我们可以重新训练我们的模型并重新评估它的准确性:</p>
<pre>In []: 
tree_model.max_depth = 4 </pre>
<p>请注意，训练的准确度现在被设置得低了大约6%。测试集怎么样？</p>
<pre>In []: 
tree_model = tree_model.fit(X_train, y_train) 
tree_model.score(X_train, y_train) 
Out[]: 
0.90571428571428569 </pre>
<p>以前看不到的数据的准确性现在提高了约4%。这看起来并不是一个伟大的成就，直到你意识到这是从我们最初的1000只动物中增加的40只正确分类的动物。在现代机器学习竞赛中，第1名<sup>名</sup>和第100名<sup>名</sup>名之间的最终差距可以轻松达到1%左右。</p>
<pre>In []: 
tree_model.score(X_test, y_test) 
Out[]: 
0.92000000000000004 </pre>
<p>剪枝后我们来画一个树形结构。这个可视化的代码和以前一样:</p>
<p>图2.7:限制深度后的树结构</p>
<div><img src="img/bb763fea-f731-44c1-8812-0899aa91722d.png"/></div>
<p>了解模型容量权衡</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Understanding model capacity trade-offs</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">让我们训练不同深度的树:从1个劈叉开始，最多23个劈叉:</h1>
                
            
            
                
<p>图2.8:训练损失与测试损失，取决于最大采油树深度</p>
<pre>In []: 
train_losses = [] 
test_losses = [] 
for depth in xrange(1, 23): 
    tree_model.max_depth = depth 
    tree_model = tree_model.fit(X_train, y_train) 
    train_losses.append(1 - tree_model.score(X_train, y_train)) 
    test_losses.append(1 - tree_model.score(X_test, y_test)) 
figure = plt.figure()  
plt.plot(train_losses, label="training loss", linestyle='--') 
plt.plot(test_losses, label="test loss") 
plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3, ncol=2, mode="expand", borderaxespad=0.) 
Out[]: </pre>
<div><img height="293" src="img/40026563-3be5-4b2e-9919-6be28b91370d.png" width="439"/></div>
<p>在<em> x </em>轴上，我们绘制了树的深度，在<em> y </em>轴上，我们绘制了模型的误差。我们在这里观察到的一个有趣现象对任何机器学习从业者来说都很熟悉:随着模型变得越来越复杂，它越来越容易过度拟合。起初，随着模型容量的增长，训练和测试损失(错误)都减少了，但随后奇怪的事情发生了:当训练集上的错误继续减少时，测试错误开始增加。这意味着该模型非常适合训练示例，以至于它不再能够对看不见的数据进行很好的概括。这就是为什么拥有一个隐藏的数据集并在其上执行模型验证如此重要。从上面的图中，我们可以看到我们或多或少随机选择的<kbd>max_depth=4</kbd>是幸运的:此时的测试误差甚至小于训练误差。</p>
<p>决策树学习如何工作</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>How decision tree learning works</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">决策树学习是一种受监督的非参数算法，用于分类和回归。</h1>
                
            
            
                
<p>根据数据自动构建树</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Building a tree automatically from data</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title"><em>二十个问题</em>游戏是一个传统游戏，其中一个玩家是选择一个对象(或某些变体中的名人)的回答者，不向其他参与者透露它是什么。所有其他玩家都试图通过问类似<em>我能吃这个吗？或者我是人类吗？</em>其中答案只能是<em>是</em>或<em>否</em>。</h1>
                
            
            
                
<p>如果你从未听说过这个游戏，参考维基百科:<a href="https://en.wikipedia.org/wiki/Twenty_Questions" target="_blank">https://en.wikipedia.org/wiki/Twenty_Questions</a>。</p>
<p>这本质上是一个树学习算法。要想在游戏中获胜，你应该提出最具歧视性的问题；比如这个问题，<em>它是活着的吗？</em>在比赛开始时明显比<em>强，难道是黄瓜？</em>。这种以最佳方式剖析假设空间的能力在信息增益准则的概念中被形式化。</p>
<p>组合熵</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Combinatorial entropy</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">信息增益准则基于香农熵概念。香农熵是信息论、物理学和其他领域中的一个非常重要的课题。数学上，它表示为:</h1>
                
            
            
                
<p>其中<em xmlns:epub="http://www.idpf.org/2007/ops"> i </em>是系统的状态，<em xmlns:epub="http://www.idpf.org/2007/ops"> N </em>是可能状态的总数，<em xmlns:epub="http://www.idpf.org/2007/ops">p<sub>I</sub>T11】是系统处于状态<em xmlns:epub="http://www.idpf.org/2007/ops"> i </em>的概率。熵描述了系统中不确定性的数量。系统越有序，熵就越小。</em></p>
<div><img class="fm-editor-equation" height="42" src="img/bb262dca-a28a-4aff-b353-8b849e9e39e5.png" width="113"/></div>
<p>关于信息理论的视觉介绍，请查看克里斯多佛·奥拉的<em xmlns:epub="http://www.idpf.org/2007/ops">视觉信息理论</em>，网址:<a xmlns:epub="http://www.idpf.org/2007/ops" href="http://colah.github.io/posts/2015-09-Visual-Information/" target="_blank">http://colah.github.io/posts/2015-09-Visual-Information/</a>。<br xmlns:epub="http://www.idpf.org/2007/ops"/> <br xmlns:epub="http://www.idpf.org/2007/ops"/>如果你想了解更多关于熵的知识，可以去看看尼斯的互动博客<em xmlns:epub="http://www.idpf.org/2007/ops">熵的解释，作者是阿提什·巴蒂亚，来自<a xmlns:epub="http://www.idpf.org/2007/ops" href="https://aatishb.com/entropy/" target="_blank">https://aatishb.com/entropy/</a>。</em></p>
<p>让我们用一个简单的例子来说明熵如何对决策树的构建有用。为此，我们将简化外星生物分类的任务，假设我们只能测量一个特征:体长。我们有10只个体(<img height="14" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="14"/> =鸭嘴龙和<img height="16" src="img/a9132245-1b41-408a-b597-9b661816dbcd.png" width="16"/> =兔龙)，它们的体长如下:</p>
<p><strong>真实标签</strong></p>
<table class="MsoTableGrid">
<tbody>
<tr>
<td>
<p><img height="18" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="18"/></p>
</td>
<td>
<p><img height="16" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="16"/></p>
</td>
<td>
<p><img height="13" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="13"/></p>
</td>
<td>
<p><img height="17" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="17"/></p>
</td>
<td>
<p><img height="17" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="17"/></p>
</td>
<td>
<p><img height="13" src="img/a9132245-1b41-408a-b597-9b661816dbcd.png" width="13"/></p>
</td>
<td>
<p><img height="13" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="13"/></p>
</td>
<td>
<p><img height="15" src="img/a9132245-1b41-408a-b597-9b661816dbcd.png" width="15"/></p>
</td>
<td>
<p><img height="22" src="img/a9132245-1b41-408a-b597-9b661816dbcd.png" width="22"/></p>
</td>
<td>
<p><img height="20" src="img/a9132245-1b41-408a-b597-9b661816dbcd.png" width="20"/></p>
</td>
<td>
<p><strong>体长，米</strong></p>
</td>
</tr>
<tr>
<td>
<p>一</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>四</p>
</td>
<td>
<p>5</p>
</td>
<td>
<p>6</p>
</td>
<td>
<p>七</p>
</td>
<td>
<p>8</p>
</td>
<td>
<p>9</p>
</td>
<td>
<p>10</p>
</td>
<td>
<p>10</p>
</td>
</tr>
</tbody>
</table>
<p>如果我们从群体中随机抽取一个个体，它可能是一只概率为0.6的鸭嘴龙，或者是一只概率为0.4的拉波龙。我们在这个系统中有两种状态，两种结果。让我们计算它的熵:</p>
<p>所以，这个数据集中的不确定性是0.97。是很多，还是很少？我们还没有可以与之比较的东西，所以让我们在中间(&gt; 5米)划分集合，并计算两个子集的熵:</p>
<div><img class="fm-editor-equation" height="28" src="img/36251733-fadd-41de-940b-452a2dcbdef6.png" width="247"/></div>
<p><strong>真实标签</strong></p>
<table class="MsoTableGrid">
<tbody>
<tr>
<td>
<p><img height="23" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="23"/></p>
</td>
<td>
<p><img height="22" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="22"/></p>
</td>
<td>
<p><img height="20" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="20"/></p>
</td>
<td>
<p><img height="19" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="19"/></p>
</td>
<td>
<p><img height="23" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="23"/></p>
</td>
<td>
<p><img height="23" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="23"/></p>
</td>
<td><img height="19" src="img/a9132245-1b41-408a-b597-9b661816dbcd.png" width="19"/></td>
<td>
<p><img height="14" src="img/06d68652-1650-41ee-aeed-dbfd72bcd1be.png" width="14"/></p>
</td>
<td>
<p><img height="15" src="img/a9132245-1b41-408a-b597-9b661816dbcd.png" width="15"/></p>
</td>
<td>
<p><img height="19" src="img/a9132245-1b41-408a-b597-9b661816dbcd.png" width="19"/></p>
</td>
<td>
<p><img height="24" src="img/a9132245-1b41-408a-b597-9b661816dbcd.png" width="24"/></p>
</td>
<td>
<p><strong>体长</strong></p>
</td>
</tr>
<tr>
<td>
<p>一</p>
</td>
<td>
<p>2</p>
</td>
<td>
<p>3</p>
</td>
<td>
<p>四</p>
</td>
<td>
<p>5</p>
</td>
<td>
<p>5</p>
</td>
<td>6</td>
<td>
<p>七</p>
</td>
<td>
<p>8</p>
</td>
<td>
<p>9</p>
</td>
<td>
<p>10</p>
</td>
<td>
<p><em> H </em>和<em> H </em>现在小于原来的<em> H </em>。这演示了如何通过在正确的位置拆分数据集来减少熵。这个想法存在于决策树学习算法的基础中。</p>
</td>
</tr>
</tbody>
</table>
<div><img class="fm-editor-equation" height="32" src="img/b9a07c0b-0bdb-4d1a-b898-205cc95032b5.png" width="137"/></div>
<div><img class="fm-editor-equation" height="32" src="img/52c50691-71ec-44f6-bccc-e4232c85ea8d.png" width="253"/></div>
<p>我们可以通过使用<strong>信息增益</strong> ( <strong> IG </strong>)标准分割集合来计算我们降低熵的效率:</p>
<p><em>信息增益=熵(父代)-熵(子代)的加权和</em>，或者:</p>
<p><em xmlns:epub="http://www.idpf.org/2007/ops"> q </em>为拆分后的组数，<em xmlns:epub="http://www.idpf.org/2007/ops">N<sub>I</sub>T17】为第I组中元素的个数，<em xmlns:epub="http://www.idpf.org/2007/ops">N</em>—为拆分前元素的总数。在我们的例子中，<em xmlns:epub="http://www.idpf.org/2007/ops"> q = 2 </em>，<em xmlns:epub="http://www.idpf.org/2007/ops"> N = 10 </em>，<em xmlns:epub="http://www.idpf.org/2007/ops">N<sub>1</sub>= N<sub>2</sub>= 5</em>:</em></p>
<div><img class="fm-editor-equation" height="39" src="img/5dbcd2bb-eeb8-499c-8221-dcbda9c132fa.png" width="124"/></div>
<p>这就意味着问问题<em>是体长大于5？</em>给我们一个<em> 0.61 </em>的信息增益。是很多，还是很少？让我们将它与围绕长度分割的信息损失进行比较&gt; 7:</p>
<div><img class="fm-editor-equation" height="33" src="img/7a6c4755-5adc-4980-9841-8b57ad7737f2.png" width="327"/></div>
<p>显然，中间点的选择是幸运的，因为所有其他分裂看起来都没有希望。但是如果你想的话，你可以随意检查。</p>
<div><img class="fm-editor-equation" height="29" src="img/f7e79951-6229-4e31-9dab-dd4a537963e1.png" width="380"/></div>
<p>进一步分割左侧部分没有意义，但我们可以继续分割右侧子集，直到其每个子子集的熵不等于零(参见<em>图2.9 </em>)。</p>
<p>这就是我们的决策树，以及构建它的递归算法。但是现在出现了一个有趣的问题:如何知道哪种分裂产生最大的信息增益？最简单的方法是贪婪搜索:只需检查所有可能的变体。</p>
<p>信息增益只是其中一种启发式，还有更多；例如，在我们的scikit-learn决策树学习器中，我们使用Gini杂质作为启发。根据密西根州立大学(<a href="http://www.cse.msu.edu/~cse802/DecisionTrees.pdf" target="_blank">http://www.cse.msu.edu/~cse802/DecisionTrees.pdf</a>):</p>
<p>“基尼系数是节点N处的预期错误率，如果类别标签是从N处的类别分布中随机选择的。”</p>
<p>查看关于<kbd>DecisionTreeClassifier</kbd>的<kbd>criterion</kbd>属性的文档，了解更多关于scikit-learn中可用于树学习的不同启发式方法的信息。在实践中，基尼系数与信息增益非常相似。一个冲淡理论论述的历史事实:科拉多·基尼是意大利统计学家，著有《T2:法西斯主义的科学基础》(T3，1927)；</p>
<p class="mce-root CDPAlignLeft CDPAlign">图2.9:构建决策树。<em> H </em>代表各组的熵。图片由Mykola Sosnovshchenko提供。</p>
<div><img height="463" src="img/2a0f958b-ddce-4217-9eab-78e987edb4c0.png" width="456"/></div>
<p>用数据评估模型的性能</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Evaluating performance of the model with data</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">定量评估模型预测质量的方法被称为<strong>度量</strong>。分类中最简单的度量是准确性，即正确分类的案例的比例。准确性度量可能会产生误导。假设您有一个包含1000个样本的训练集。其中999个属于A类，1个属于b类，这样的数据集叫做<strong>不平衡</strong>。在这种情况下，基线(最简单的)解决方案是始终预测a类。这样一个模型的精度将为0.999，这可能非常令人印象深刻，但前提是您不知道训练集中类的比率。现在想象一下，在医疗诊断系统中，A类对应健康的结果，B类对应癌症。现在很清楚，0.999的准确度一文不值，而且完全是误导。另一个要考虑的是，不同错误的成本可能不同。更糟糕的是:把一个健康的人诊断为患病，还是把一个患病的人诊断为健康？这导致了两种错误的概念(<em>图2.10 </em>):</h1>
                
            
            
                
<p>I型错误，又称<strong>假阳性</strong>:算法预测<strong>癌症</strong>，而没有癌症</p>
<ul>
<li>第二类错误，又称，<strong>假阴性</strong>:算法预测<strong>无癌</strong>，而有。</li>
<li>图2.9:用文氏图表示的两种错误</li>
</ul>
<div><img height="269" src="img/d2c15ec9-5731-46e2-b714-f8cf947e7912.png" width="298"/></div>
<p>精确度、召回率和F1分数</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Precision, recall, and F1-score</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">考虑到这两种类型的误差，要评估算法的质量，精度度量是没有用的。这就是为什么提出了不同的衡量标准。</h1>
                
            
            
                
<p><strong>精度</strong>和<strong>召回</strong>是用于评估信息检索和二元分类中预测质量的度量。精度是所有预测阳性中真实阳性的比例。它显示了相关的结果。召回，也称为<strong>敏感度</strong>，是所有真阳性样本中真阳性的比例。例如，如果任务是区分猫照片和非猫照片，精度是正确预测的猫与所有预测的猫的分数。回忆是预测的猫占真实猫总数的分数。</p>
<p>如果我们将真阳性案例的数量表示为<em xmlns:epub="http://www.idpf.org/2007/ops">T<sub>P</sub>T9】，将假阳性案例的数量表示为<em xmlns:epub="http://www.idpf.org/2007/ops">F<sub>P</sub>T13】，则精度<em xmlns:epub="http://www.idpf.org/2007/ops"> P </em>计算如下:</em></em></p>
<p>召回<em> R </em>计算如下:</p>
<div><img class="fm-editor-equation" height="37" src="img/d7644c5d-45a0-4b5a-89a0-2c41545c5748.png" width="85"/></div>
<p>其中<em> F <sub> n </sub> </em>是若干个假阴性案例。</p>
<div><img class="fm-editor-equation" height="39" src="img/57cd024f-a6f9-4675-b0bb-3c9f33172824.png" width="90"/>,</div>
<p><em> F1 </em>测量值计算如下:</p>
<p>现在Python中也是如此:</p>
<div><img class="fm-editor-equation" height="29" src="img/aa5faaec-d236-4525-a611-04c75809e6f6.png" width="77"/></div>
<p>k倍交叉验证</p>
<pre>In []: 
import numpy as np 
predictions = tree_model.predict(X_test) 
predictions = np.array(map(lambda x: x == 'rabbosaurus', predictions), dtype='int') 
true_labels = np.array(map(lambda x: x == 'rabbosaurus', y_test), dtype='int') 
from sklearn.metrics import precision_score, recall_score, f1_score 
precision_score(true_labels, predictions) 
Out[]: 
0.87096774193548387 
In []: 
recall_score(true_labels, predictions) 
Out[]: 
0.88815789473684215 
In []: 
f1_score(true_labels, predictions) 
Out[]: 
0.87947882736156346 </pre>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>K-fold cross-validation</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">这种方法是在大约会还不是问题，每个人都没有什么数据，但仍然需要建立可靠的模型的时候发明并流行起来的。我们做的第一件事是很好地洗牌，然后将它随机分成几个相等的部分，比如10个(这是k-fold中的<em> k </em>)。我们将第一部分作为测试集，并在剩余的九个部分上训练模型。然后，在没有像往常一样参与训练的测试集上评估训练的模型。接下来，我们拿出10个部分中的第二个，并在剩余的9个部分(包括之前用作测试集的部分)上训练模型。我们对未参加培训的零件再次验证新模型。我们继续这个过程，直到10个部分中的每一个都处于测试集的角色中。最终质量指标由10次测试中每一次的平均指标决定:</h1>
                
            
            
                
<p>图2.10:交叉验证结果</p>
<pre>In []: 
from sklearn.model_selection import cross_val_score 
scores = cross_val_score(tree_model, features, df.label, cv=10) 
np.mean(scores) 
Out[]: 
0.88300000000000001 
In []: 
plot = plt.bar(range(1,11), scores) 
Out[]: </pre>
<div><img height="298" src="img/d01159cd-81f6-49dd-9500-f55c82a557b8.png" width="447"/></div>
<p>从上图中，您可以看到模型的准确性取决于您如何分割数据，但不是很大。通过计算交叉验证结果的平均值和方差，您可以了解您的模型在不同数据上的泛化能力，以及它的稳定性。</p>
<p>混淆矩阵</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Confusion matrix</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">混淆矩阵有助于了解哪些类型的错误更容易发生:</h1>
                
            
            
                
<p>这是如何阅读和解释这样的矩阵:</p>
<pre>In []: 
from sklearn.metrics import confusion_matrix 
confusion_matrix(y_test, tree_model.predict(X_test)) 
Out[]: 
array([[128,  20], 
       [ 17, 135]]) </pre>
<p>This is how to read and interpret such matrices:</p>
<table>
<tbody>
<tr>
<td><strong>预测标签</strong></td>
<td colspan="3"><strong>真实标签</strong></td>
</tr>
<tr>
<td rowspan="3"><strong>True labels</strong></td>
<td><strong>鸭嘴兽</strong></td>
<td><strong> Rabbosaurus </strong></td>
<td><strong>鸭嘴兽</strong></td>
</tr>
<tr>
<td>128</td>
<td>20</td>
<td><strong> Rabbosaurus </strong></td>
</tr>
<tr>
<td>17</td>
<td>135</td>
<td>135</td>
</tr>
</tbody>
</table>
<p>矩阵对角线上的数字越大越好。</p>
<p>在Swift中实施首个机器学习应用</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Implementing first machine learning app in Swift</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">您可以通过两种方式将您的模型从Python转移到Swift:转移一个经过训练的模型，或者在Swift中从头开始训练一个模型。在决策树的情况下，第一个选项很容易，因为训练好的模型可以表示为一组if-else条件，这对于手动编码来说是微不足道的。只有在您希望应用程序在运行时学习的情况下，才需要从头开始训练模型。在这个例子中，我们将坚持第一种方法，但是我们将使用核心ML工具导出用于iOS的scikit-learn模型，而不是手动编码规则。</h1>
                
            
            
                
<p>核心ML简介</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Introducing Core ML</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">Core ML首次亮相苹果WWDC 2017。将核心ML定义为机器学习框架并不公平，因为它缺乏学习能力；它更像是一套将预先训练好的模型插入到你的苹果应用程序中的转换脚本。尽管如此，对于新手来说，在iOS上开始运行他们的第一个模型是一个简单的方法。</h1>
                
            
            
                
<p>核心ML功能</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Core ML features</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">以下是ML的核心特性列表:</h1>
                
            
            
                
<p>Python包包含了几个流行的机器学习框架的转换器:scikit-learn、Keras、Caffe、LIBSVM和XGBoost。</p>
<ul>
<li>核心ML框架允许在设备上运行推理(做出预测)。Scikit-learn转换器还支持一些数据转换和模型流水线。</li>
<li>硬件加速(加速框架和引擎盖下的金属)。</li>
<li>支持iOS、macOS、tvOS和watchOS。</li>
<li>与Swift实现OOP风格互操作性的自动代码生成。</li>
<li>最大的核心ML限制是它不支持模型训练。</li>
</ul>
<p>为iOS导出模型</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Exporting the model for iOS</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">在我们的Jupyter笔记本中，执行以下代码来导出模型:</h1>
                
            
            
                
<p>Scikit-learn转换器文档:<a href="https://apple.github.io/coremltools/generated/coremltools.converters.sklearn.convert.html" target="_blank">http://python hosted . org/coremltools/generated/coremltools . converters . sk learn . convert . html # coremltools . converters . sk learn . convert</a></p>
<pre>In []: 
import coremltools as coreml 
coreml_model = coreml.converters.sklearn.convert(tree_model, feature_names, 'label') 
coreml_model.author = "Author name goes here..." 
coreml_model.license = "License type goes here ..." 
coreml_model.short_description = "Decision tree classifier for extraterrestrials." 
coreml_model.input_description['data'] = "Extraterrestrials features" 
coreml_model.output_description['prob'] =  "Probability of belonging to class." 
coreml_model.save('DecisionTree.mlmodel') </pre>
<p>代码在Jupyter笔记本文件旁边创建了<kbd>tree.mlmodel</kbd>文件。这个文件可以包含一个模型、一个模型管道(几个模型一个接一个地链接在一起)，或者一个scikit-learn模型列表。根据文档，scikit-learn转换器支持以下类型的机器学习模型:</p>
<p>决策树学习</p>
<ul>
<li>树形系综</li>
<li>随机森林</li>
<li>梯度推进</li>
<li>线性和逻辑回归(参见<a href="848b7d83-6d0a-46d3-a9b5-18caf49b4c74.xhtml" target="_blank">第五章</a>、<em>关联规则学习</em>)</li>
<li>支持向量机(几种类型)</li>
<li>它还支持以下数据转换:</li>
</ul>
<p>标准化者</p>
<ul>
<li>估算者</li>
<li>标准缩放器</li>
<li>字典矢量器</li>
<li>一键编码器</li>
<li>请注意，您可以将一键编码作为pipeline的一部分嵌入，因此您不需要在Swift代码中自己做这件事。这很方便，因为您不需要跟踪分类变量级别的正确顺序。</li>
</ul>
<p><kbd>.mlmodel</kbd>文件可以是三种类型之一:分类器、回归器或转换器，这取决于列表中的最后一个模型或管道。理解scikit-learn模型(或其他源框架)和在设备上运行的核心ML模型之间没有直接的对应关系是很重要的。因为核心ML源是封闭的，我们不知道它是如何在幕后操作的，也不能确定转换前后的模型会产生相同的结果。这意味着您需要在设备部署后验证模型，以衡量其性能和准确性。</p>
<p>集成学习随机森林</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Ensemble learning random forest</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">给LOTR迷一句话的解释:如果决策树是树人，随机森林将是一个树人。对于其他人，随机森林算法是这样工作的:</h1>
                
            
            
                
<p>将数据分成大小相等的随机子集，可能会替换</p>
<ul>
<li>在每个子集上，构建一个决策树，为每个分裂选择一个固定大小的随机特征子集</li>
<li>要进行推断，请在树之间进行投票(分类)，或者对它们的预测进行平均(回归)</li>
<li>这种树集成在某些领域非常受欢迎，因为它们的预测质量胜过大多数其他模型。</li>
</ul>
<p>最有可能的是，由于内存和时间限制，这不是您想要在移动设备上训练的模型，但是由于Core ML，您仍然可以使用它进行推理。工作流程如下所示:</p>
<p>在scikit-learn中预先训练随机森林</p>
<ul>
<li>以scikit-learn格式导出模型</li>
<li>在<kbd>coremltool</kbd> Python包的帮助下转换成苹果<kbd>mlmodel</kbd>格式</li>
<li>使用核心ML框架将其导入到您的iOS项目中</li>
<li>顺便说一下，如果你在调试器或游乐场中查看GameplayKit的树学习器的内部结构，你会发现它也使用了随机森林。</li>
</ul>
<p>训练随机森林</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Training the random forest</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">训练随机森林模型与训练决策树没有太大的不同:</h1>
                
            
            
                
<p>文档位于:<a href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html" target="_blank">http://sci kit-learn . org/stable/modules/generated/sk learn . ensemble . randomforestclassifier . html</a>。</p>
<pre>In []: 
from sklearn.ensemble import RandomForestClassifier 
rf_model = RandomForestClassifier(criterion = 'entropy', random_state=42) 
rf_model = rf_model.fit(X_train, y_train) 
print(rf_model) 
Out[]: 
RandomForestClassifier(bootstrap=True, class_weight=None, criterion='entropy', 
            max_depth=None, max_features='auto', max_leaf_nodes=None, 
            min_impurity_split=1e-07, min_samples_leaf=1, 
            min_samples_split=2, min_weight_fraction_leaf=0.0, 
            n_estimators=10, n_jobs=1, oob_score=False, random_state=42, 
            verbose=0, warm_start=False) </pre>
<p>随机森林精度评估</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Random forest accuracy evaluation</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">训练数据丢失:</h1>
                
            
            
                
<p>测试数据损失:</p>
<pre>In []: 
rf_model.score(X_train, y_train) 
Out[]: 
0.98999999999999999 </pre>
<p>交叉验证:</p>
<pre>In []: 
rf_model.score(X_test, y_test) 
Out[]: 
0.90333333333333332 </pre>
<p>精确度和召回率:</p>
<pre>In []:<br/>scores = cross_val_score(rf_model, features, df.label, cv=10) 
np.mean(scores) 
Out[]: 
0.89700000000000002 
In []: 
print("Accuracy: %0.2f (+/- %0.2f)" % (scores.mean(), scores.std() * 2)) 
Accuracy: 0.90 (+/- 0.06) </pre>
<p><em> F1- </em>得分:</p>
<pre>In []: 
predictions = rf_model.predict(X_test) 
predictions = np.array(map(lambda x: x == 'rabbosaurus', predictions), dtype='int') 
true_labels = np.array(map(lambda x: x == 'rabbosaurus', y_test), dtype='int') 
precision_score(true_labels, predictions) 
Out[]: 
0.9072847682119205 
In []: 
recall_score(true_labels, predictions) 
Out[]: 
0.90131578947368418 </pre>
<p>混淆矩阵:</p>
<pre>In []: 
f1_score(true_labels, predictions) 
Out[]: 
0.90429042904290435 </pre>
<p>您可以像导出决策树一样导出iOS的随机林。</p>
<pre>In []: 
confusion_matrix(y_test, rf_model.predict(X_test)) 
Out[]: 
array([[134,  14], 
       [ 15, 137]]) </pre>
<p>将核心ML模型导入iOS项目</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Importing the Core ML model into an iOS project</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">创建一个新的iOS项目，并将<kbd>DecisionTree.mlmodel</kbd>拖放到Xcode的项目树中。点击它可以看到一个机器学习模型导航器屏幕:</h1>
                
            
            
                
<p>图2.11:机器学习导航器屏幕</p>
<div><img height="546" src="img/a67734d1-98b7-4dc9-9bac-4f2ae52ddafa.png" width="503"/></div>
<p>在该屏幕上，您可以找到熟悉的模型描述、模型类型(在本例中是由于某种原因的管道)、代表应用中模型的Swift类的名称，以及输入和输出列表。如果点击模型类部分类名旁边的小箭头，自动生成的文件<kbd>DecisionTree.swift</kbd>将被打开。这提醒了一个核心数据框架，在那里你已经为<kbd>NSMangedObject</kbd>子类自动生成了文件。<kbd>DecisionTree.swift</kbd>包含三类:</p>
<p><kbd>DecisionTreeInput</kbd> : <kbd>MLFeatureProvider</kbd>，包含输入特征(六个，全双)。</p>
<ul>
<li><kbd>DecisionTreeOutput</kbd> : <kbd>MLFeatureProvider</kbd>，包含类别标签和类别概率。</li>
<li><kbd>DecisionTree</kbd> : <kbd>NSObject</kbd>，模型本身的类。它包含初始化和预测的方法。</li>
<li>方法<kbd>init(contentsOf: url)</kbd>允许在运行时替换模型，但前提是要保留输入和输出结构。例如，这是从包中的文件加载模型的方式:</li>
</ul>
<p>同样，您可以用远程URL的内容创建一个模型。</p>
<pre>let bundle = Bundle.main 
let assetPath = bundle.url(forResource: "DecisionTree", withExtension:"mlmodelc") 
let sklDecisionTree = DecisionTree(contentsOf: assetPath!) </pre>
<p>将<kbd>RandomForest.ml</kbd>模型拖放到项目中，以比较iOS上模型的准确性。</p>
<p>评估模型在iOS上的性能</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Evaluating performance of the model on iOS</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">我在这里没有描述Swift中的<kbd>.csv</kbd>解析；如果你对细节感兴趣，请看补充材料。假设您已经成功地以两个数组的形式加载了测试数据，<kbd>[Double]</kbd>用于特性，<kbd>[String]</kbd>用于标签，试一试下面的代码:</h1>
                
            
            
                
<p>要创建决策树并对其进行评估，请尝试以下方法:</p>
<pre>let (xMat, yVec) = loadCSVData() </pre>
<p>要创建随机林并对其进行评估，请尝试使用以下代码:</p>
<pre>let sklDecisionTree = DecisionTree() 
 
let xSKLDecisionTree = xMat.map { (x: [Double]) -&gt; DecisionTreeInput in 
    return DecisionTreeInput(length: x[0], 
                             fluffy: x[1], 
                             color_light_black: x[2], 
                             color_pink_gold: x[3], 
                             color_purple_polka_dot: x[4], 
                             color_space_gray: x[5]) 
} 
 
let predictionsSKLTree = try! xSKLDecisionTree 
    .map(sklDecisionTree.prediction) 
    .map{ prediction in 
        return prediction.label == "rabbosaurus" ? 0 : 1 
} 
 
let groundTruth = yVec.map{ $0 == "rabbosaurus" ? 0 : 1 } 
 
let metricsSKLDecisionTree = evaluateAccuracy(yVecTest: groundTruth, predictions: predictionsSKLTree) 
print(metricsSKLDecisionTree) </pre>
<p>这是一个如何在Swift应用程序中评估模型预测质量的示例。包含评估结果的结构如下:</p>
<pre>let sklRandomForest = RandomForest() 
 
let xSKLRandomForest = xMat.map { (x: [Double]) -&gt; RandomForestInput in 
    return RandomForestInput(length: x[0], 
                             fluffy: x[1], 
                             color_light_black: x[2], 
                             color_pink_gold: x[3], 
                             color_purple_polka_dot: x[4], 
                             color_space_gray: x[5]) 
} 
 
let predictionsSKLRandomForest = try! xSKLRandomForest.map(sklRandomForest.prediction).map{$0.label == "rabbosaurus" ? 0 : 1} 
 
let metricsSKLRandomForest = evaluateAccuracy(yVecTest: groundTruth, predictions: predictionsSKLRandomForest) 
print(metricsSKLRandomForest) </pre>
<p>对于质量评估函数，代码如下:</p>
<pre>struct Metrics: CustomStringConvertible { 
let confusionMatrix: [[Int]] 
let normalizedConfusionMatrix: [[Double]] 
let accuracy: Double 
let precision: Double 
let recall: Double 
let f1Score: Double 
 
var description: String { 
    return """ 
    Confusion Matrix: 
    (confusionMatrix) 
     
    Normalized Confusion Matrix: 
    (normalizedConfusionMatrix) 
     
    Accuracy: (accuracy) 
    Precision: (precision) 
    Recall: (recall) 
    F1-score: (f1Score) 
    """ 
} 
} </pre>
<p>计算混淆矩阵</p>
<pre>func evaluateAccuracy(yVecTest: [Int], predictions: [Int]) -&gt; Metrics { </pre>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Calculating the confusion matrix</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">我们将使用一种简单的方法来计算混淆矩阵；但是，这不适用于多类分类。这里，<kbd>p</kbd>代表预测值，<kbd>t</kbd>代表地面实况:</h1>
                
            
            
                
<p>通过总计数归一化矩阵:</p>
<pre>let pairs: [(Int, Int)] = zip(predictions, yVecTest).map{ ($0.0, $0.1) } 
var confusionMatrix = [[0,0], [0,0]] 
for (p, t) in pairs { 
    switch (p, t) { 
    case (0, 0): 
        confusionMatrix[0][0] += 1 
    case (0, _): 
        confusionMatrix[1][0] += 1 
    case (_, 0): 
        confusionMatrix[0][1] += 1 
    case (_, _): 
        confusionMatrix[1][1] += 1 
    } 
} 
     
let totalCount = Double(yVecTest.count) </pre>
<p>Normalize the matrix by total count:</p>
<p class="mce-root">正如我们已经知道的，准确性是真实预测的数量除以案例总数。</p>
<pre>let normalizedConfusionMatrix = confusionMatrix.map{$0.map{Double($0)/totalCount}} </pre>
<p>要计算准确性，请尝试使用以下代码:</p>
<p>要计算真阳性、假阳性和假阴性计数，您可以使用混淆矩阵中的数字，但让我们以正确的方式来做:</p>
<pre>let truePredictionsCount = pairs.filter{ $0.0 == $0.1 }.count 
let accuracy = Double(truePredictionsCount) / totalCoun  </pre>
<p>要计算精度:</p>
<pre> 
let truePositive = Double(pairs.filter{ $0.0 == $0.1 &amp;&amp; $0.0 == 0 }.count) 
let falsePositive = Double(pairs.filter{ $0.0 != $0.1 &amp;&amp; $0.0 == 0 }.count) 
let falseNegative = Double(pairs.filter{ $0.0 != $0.1 &amp;&amp; $0.0 == 1 }.count) </pre>
<p>要计算召回率:</p>
<pre>let precision = truePositive / (truePositive + falsePositive) </pre>
<p>计算<em> F1- </em>的分数:</p>
<pre>let recall = truePositive / (truePositive + falseNegative) </pre>
<p>下面是我在iOS上做决策树的结果:</p>
<pre>let f1Score = 2 * precision * recall / (precision + recall) 
     
return Metrics(confusionMatrix: confusionMatrix, normalizedConfusionMatrix: normalizedConfusionMatrix, accuracy: accuracy, precision: precision, recall: recall, f1Score: f1Score) 
} </pre>
<p>对于随机森林:</p>
<pre>Confusion Matrix: 
[[135, 17],  
[20, 128]] 
 
Normalized Confusion Matrix: 
[[0.45000000000000001, 0.056666666666666664],  
[0.066666666666666666, 0.42666666666666669]] 
 
Accuracy: 0.876666666666667 
Precision: 0.870967741935484 
Recall: 0.888157894736842 
F1-score: 0.879478827361563 
 </pre>
<p>恭喜你！我们已经训练了两个机器学习算法，将它们部署到iOS，并评估了它们的准确性。有趣的是，虽然决策树指标完全匹配，但随机森林的性能在核心ML上稍差。不要忘记在任何类型的转换之后都要验证你的模型。</p>
<pre>Confusion Matrix: 
[[138, 14],  
[18, 130]] 
 
Normalized Confusion Matrix: 
[[0.46000000000000002, 0.046666666666666669],  
[0.059999999999999998, 0.43333333333333335]] 
 
Accuracy: 0.893333333333333 
Precision: 0.884615384615385 
Recall: 0.907894736842105 
F1-score: 0.896103896103896 </pre>
<p>决策树学习的利与弊</p>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Decision tree learning pros and cons</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">优势:</h1>
                
            
            
                
<p>易于理解和解释，非常适合视觉表现。这是一个白盒模型的例子，它密切模仿人类的决策过程。</p>
<ul>
<li>可以处理数字和分类特征。</li>
<li>几乎不需要数据预处理:不需要一次性编码、虚拟变量等等。</li>
<li>非参数模型:没有关于数据形状的假设。</li>
<li>快速推理。</li>
<li>特征选择自动发生:不重要的特征不会影响结果。存在相互依赖的要素(多重共线性)也不会影响质量。</li>
<li>缺点:</li>
</ul>
<p>它倾向于过度适应。这通常可以通过以下三种方式之一来缓解:</p>
<ul>
<li>限制树深度<ul>
<li>设置叶子中对象的最小数量</li>
<li>通过删除从叶子到根部的不重要的分裂来修剪树木</li>
<li>它是不稳定的——数据的微小变化都会极大地影响树的结构和最终预测。</li>
</ul>
</li>
<li>寻找全局最优决策树的问题是NP完全的。这就是为什么我们使用不同的启发式和贪婪搜索。不幸的是，这种方法不能保证学习到全局最优的树，只能学习到局部最优的树。</li>
<li>不灵活，也就是说你不能很容易地把一个新的数据整合到其中。如果您获得了新的标记数据，您应该在整个数据集上从头开始重新训练树。这使得决策树对于任何需要动态模型调整的应用程序来说都不是一个好的选择。</li>
<li>摘要</li>
</ul>


            

            
        
    </body>

</html>
<html xmlns:epub="http://www.idpf.org/2007/ops">
    <head>
        <title>Summary</title>
        
        <meta charset="utf-8"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000005314597" name="Adept.expected.resource"/>
    </head>

    <body>
        

                            
                    <h1 class="header-title">在这一章中，我们有了构建机器学习应用程序的第一次经验，从数据开始，一直到工作的iOS应用程序。在本章中，我们经历了几个阶段:</h1>
                
            
            
                
<p>使用Jupyter、pandas和Matplotlib进行探索性数据分析</p>
<ul>
<li>数据准备——拆分和处理分类变量</li>
<li>使用scikit-learn建立模型原型</li>
<li>模型调整和评估</li>
<li>使用Core ML为移动平台移植原型</li>
<li>移动设备上的模型验证</li>
<li>我们在本章中学习了几个机器学习主题:模型参数与超参数，过拟合与欠拟合，评估指标:交叉验证，准确度，精确度，召回率，以及<em> F </em> <em> 1- </em>得分。这些是贯穿本书的基本主题。</li>
</ul>
<p>我们已经熟悉了两种机器学习算法，即决策树和随机森林，一种模型集成。</p>
<p>在下一章，我们将继续探索分类算法，并将学习基于实例的学习算法。我们还将开发一个可以在设备上正确学习的iOS应用程序，这次不是为了外星人分类，而是为了一些现实世界的问题，我保证。</p>
<p>In the next chapter, we're going to continue exploring classification algorithms, and will learn about instance-based learning algorithms. We will also build an iOS app that can learn right on the device, this time not for alien classification, but for some real-world problem, I promise.</p>
<p class="mce-root"/>
<p class="mce-root"/>
<p class="mce-root"/>


            

            
        
    </body>

</html></body></html>