<html><head/><body>









		<title>Preface</title>

		

		

	

	

		<div><h1 id="_idParaDest-4" class="Introduction-Title--PACKT-"><a id="_idTextAnchor004"/>前言</h1>

			<p class="normal">在过去的几年里，机器学习已经成为大多数行业中越来越重要的领域。几个曾经被认为不可能自动化的过程现在完全由计算机管理，使人类能够专注于更具创造性的任务。标准算法的显著改进以及硬件价格的持续下降使得这场革命成为可能。仅仅在十年前，复杂性还是一个巨大的障碍，现在甚至一台个人电脑也能解决这个问题。高级开源框架的普遍可用性允许每个人设计和训练极其强大的模型。</p>

			<p class="normal">第二版<em class="italics">掌握机器学习算法</em>的主要目标是向读者介绍复杂的技术(如半监督和流形学习、概率模型和神经网络)，平衡数学理论和用Python编写的实际例子(使用最先进和最常用的框架)。我想保持一种务实的方法，专注于应用，但永远不要忘记理论基础。事实上，这个领域的扎实知识只能通过理解底层逻辑来获得，而底层逻辑总是用数学概念来表达。这种额外的努力得到的回报是对每一个具体选择有了更坚实的认识，并帮助读者理解如何在具体的业务环境中应用、修改和改进所有的算法。</p>

			<p class="normal">机器学习是一个非常广泛的领域，不可能涵盖一本书的所有主题。在这种情况下，我已经尽我所能涵盖了属于监督、半监督、非监督和强化学习的算法选择，提供了进一步研究每一种算法所必需的所有参考。这些例子被设计成易于理解，而无需深入了解代码；事实上，我认为更重要的是展示一般情况，让读者改进和适应它们以应对特定的场景。我为我的错误道歉:尽管已经做了很多修改，但还是有可能遗漏了一些细节(包括公式和代码中的)。</p>

			<p class="normal">特别是，第二版纠正了第一版中存在的一些打字错误和错误，提高了一些复杂主题的可读性，并且基于最新版本的生产就绪框架(如TensorFlow 2.0)。鉴于这项工作的整体复杂性，我很抱歉，因为尽管作者和所有编辑的辛勤工作，它总是有可能找到不精确或错误。</p>

			<p class="normal">我在生命中的一个特定时期完成了这本书，我想把它献给我的父亲，一位艺术家和艺术教授，他一直是我的向导，教我如何总是有可能将科学的严谨与艺术的方法结合起来。归根结底，数据科学需要创造力，相反，创造力可以在数据科学中找到一片极其肥沃的土壤！</p>

			<h1 id="_idParaDest-5" class="title" lang="en-GB" xml:lang="en-GB">这本书是给谁的</h1>

			<p class="normal">这本书是数据科学专业人员和机器学习工程师的相关内容(理论和实践)来源，他们希望深入研究复杂的机器学习算法、模型的校准，并改善训练模型的预测。要从这本精通指南中获得最佳效果，需要扎实的基础机器学习知识。此外，鉴于某些主题的复杂性，良好的数学背景是必要的。</p>

			<h1 id="_idParaDest-6" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor006"/>这本书涵盖了什么</h1>

			<p class="normal"><em class="italics">第1章</em>、<em class="italics">机器学习模型基础</em>，解释了关于机器学习模型最重要的理论概念，包括偏差、方差、过拟合、欠拟合、数据归一化和缩放。</p>

			<p class="normal"><em class="italics">第2章</em>、<em class="italics">损失函数和正则化</em>，继续探讨基本概念，重点是损失函数，并讨论其性质和应用。本章还向读者介绍了正则化的概念，它在大多数监督方法中起着基本的作用。</p>

			<p class="normal"><em class="italics">第3章</em>，<em class="italics">半监督学习简介</em>，向读者介绍半监督学习的主要元素，讨论主要假设，重点关注生成算法、自我训练和协同训练。</p>

			<p class="normal"><em class="italics">第4章</em>，<em class="italics">高级半监督分类</em>，讨论了最重要的归纳和直推半监督分类方法，这些方法克服了<em class="italics">第3章</em>中分析的更简单算法的局限性。</p>

			<p class="normal"><em class="italics">第5章</em>，<em class="italics">基于图的半监督学习</em>，继续探索属于基于图和流形学习模型家族的半监督学习算法。在不同的上下文中分析标签传播和非线性维度减少，提供一些可以使用scikit-learn功能立即利用的有效解决方案。</p>

			<p class="normal"><em class="italics">第六章</em>、<em class="italics">聚类和无监督模型</em>，介绍了一些常见且重要的无监督算法，如K-最近邻(基于K-d树和球树)、K-means(带K-means++初始化)。此外，本章还讨论了可用于评估聚类结果的最重要的指标。</p>

			<p class="normal"><em class="italics">第7章</em>、<em class="italics">高级聚类和无监督模型</em>，继续讨论更复杂的聚类算法，如谱聚类、DBSCAN和模糊聚类，它们可以解决更简单的方法无法正确管理的问题。</p>

			<p class="normal"><em class="italics">第8章</em>、<em class="italics">聚类和无监督营销模型</em>，向读者介绍了双聚类的概念，它可以在营销环境中用来创建推荐系统。本章还介绍了Apriori算法，它允许我们在非常大的交易数据库上执行市场购物篮分析。</p>

			<p class="normal"><em class="italics">第9章，</em> <em class="italics">广义线性模型和回归</em>，讨论广义线性模型的主要概念以及如何执行不同种类的回归分析(包括正则化、保序、多项式和逻辑回归)。</p>

			<p class="normal"><em class="italics">第10章</em>，<em class="italics">时间序列分析介绍</em>，向读者介绍时间序列分析的主要概念，重点是随机过程的属性和可以用来进行有效预测的基本模型(AR、MA、ARMA和ARIMA)。</p>

			<p class="normal"><em class="italics">第11章</em>、<em class="italics">贝叶斯网络和隐马尔可夫模型</em>，介绍了使用直接无环图、马尔可夫链和顺序过程进行概率建模的概念。本章重点介绍PyStan之类的工具和HMM之类的算法，它们可以用来对时序进行建模。</p>

			<p class="normal"><em class="italics">第12章</em>，<em class="italics">EM算法</em>，解释了期望最大化(EM)算法的一般结构。我们讨论了一些常见的应用，如一般参数估计，地图和最大似然估计方法，高斯混合。</p>

			<p class="normal"><em class="italics">第十三章</em>、<em class="italics">成分分析和降维</em>，向读者介绍主成分分析、因子分析和独立成分分析的主要概念。这些工具允许我们对不同种类的数据集进行有效的成分分析，如果需要，还可以在控制信息损失的情况下进行降维。</p>

			<p class="normal"><em class="italics">第14章</em>，<em class="italics">赫布学习</em>，介绍了赫布法则，这是最古老的神经科学概念之一，其应用非常强大。本章解释了单个神经元如何工作，并介绍了两个复杂的模型(Sanger网络和Rubner-Tavan网络)，它们可以在没有输入协方差矩阵的情况下执行主成分分析。</p>

			<p class="normal"><em class="italics">第15章</em>，<em class="italics">集成学习的基础</em>，解释了集成学习的主要概念(打包、提升和堆叠)，重点是随机森林和AdaBoost(及其用于分类和回归的变体)。</p>

			<p class="normal"><em class="italics">第16章</em>、<em class="italics">高级提升算法</em>，继续讨论最重要的集成学习模型，重点是梯度提升(使用XGBoost示例)和投票分类器。</p>

			<p class="normal"><em class="italics">第17章</em>，<em class="italics">神经网络建模</em>，介绍了神经计算的概念，从感知器的行为开始，继续分析多层感知器、激活函数、反向传播、随机梯度下降、丢失和批量标准化。</p>

			<p class="normal"><em class="italics">第18章</em>、<em class="italics">优化神经网络</em>，分析了可以提高随机梯度下降性能的最重要的优化算法(包括Momentum、RMSProp和Adam)，以及如何将正则化技术应用于深度网络的各层。</p>

			<p class="normal"><em class="italics">第19章</em>、<em class="italics">深度卷积网络</em>，解释卷积的概念，并讨论如何构建和训练一个有效的图像处理深度卷积网络。所有示例均基于Keras/TensorFlow 2。</p>

			<p class="normal"><em class="italics">第二十章</em>，<em class="italics">递归神经网络</em>，介绍了管理时间序列的递归神经网络的概念，讨论了LSTM和GRU细胞的结构，展示了一些时间序列建模和预测的实例。</p>

			<p class="normal"><em class="italics">第21章</em>，<em class="italics">自动编码器</em>，解释了自动编码器的主要概念，讨论了它在降维、去噪和数据生成(可变自动编码器)中的应用。</p>

			<p class="normal"><em class="italics">第二十二章</em>，<em class="italics">生成性对抗网络介绍</em>，解释了对抗训练的概念。我们关注深度卷积gan和Wasserstein GANs。这两种技术都是非常强大的生成模型，可以学习输入数据分布的结构，并在没有任何附加信息的情况下生成全新的样本。</p>

			<p class="normal"><em class="italics">第23章</em>、<em class="italics">深度信念网络</em>，介绍了马尔可夫随机场、受限玻尔兹曼机、深度信念网络的概念。这些模型可以在有监督和无监督的情况下使用，并具有优异的性能。</p>

			<p class="normal"><em class="italics">第24章</em>，<em class="italics">强化学习介绍</em>，解释了强化学习的主要概念(代理、策略、环境、奖励、价值)，并应用它们介绍策略和价值迭代算法以及时差学习(TD(0))。这些示例基于自定义的棋盘环境。</p>

			<p class="normal"><em class="italics">第25章</em>、<em class="italics">高级策略估计算法</em>，扩展了上一章定义的概念，讨论了TD(λ)算法、TD(0)Actor-critical、SARSA和Q-Learning。还展示了深度Q学习的一个基本示例，以允许读者立即将这些概念应用到更复杂的环境中。此外，还介绍了OpenAI Gym环境，并展示和分析了一个策略梯度实例。</p>

			<h1 id="_idParaDest-7" class="title" lang="en-GB" xml:lang="en-GB">为了充分利用这本书</h1>

			<ul>

				<li class="list">读者必须具备最常见的机器学习算法的基础知识，清楚地了解它们的数学结构和应用。</li>

				<li class="list">因为Python是本例中选择的语言，所以读者必须熟悉这种语言，尤其是像scikit-learn、TensorFlow 2、pandas和PyStan这样的框架。</li>

				<li class="list">考虑到某些主题的复杂性，强烈建议您具备微积分、概率论、线性代数和统计学方面的良好知识。</li>

			</ul>

			<h2 id="_idParaDest-8" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor008"/>下载示例代码文件</h2>

			<p class="normal">你可以从你在<a href="http://www.packt.com">http://www.packt.com</a>的账户下载本书的示例代码文件。如果你在别处购买了这本书，你可以访问http://www.packtpub.com/support并注册，文件会直接通过电子邮件发送给你。</p>

			<p class="normal">您可以按照以下步骤下载代码文件:</p>

			<ol>

				<li class="list">在<a href="http://www.packt.com">http://www.packt.com</a>登录或注册。</li>

				<li class="list">选择<strong class="screen-text">支架</strong>拉环。</li>

				<li class="list">点击<strong class="screen-text">代码下载</strong>。</li>

				<li class="list">在<strong class="screen-text">搜索</strong>框中输入图书名称，并按照屏幕上的说明进行操作。</li>

			</ol>

			<p class="normal">下载文件后，请确保使用最新版本的解压缩或解压文件夹:</p>

			<ul>

				<li class="list">WinRAR / 7-Zip for Windows</li>

				<li class="list">适用于Mac的Zipeg / iZip / UnRarX</li>

				<li class="list">用于Linux的7-Zip / PeaZip</li>

			</ul>

			<p class="normal">该书的代码包也托管在GitHub上，网址是<a href="https://github.com/PacktPublishing/Mastering-Machine-Learning-Algorithms-Second-Edition">https://GitHub . com/packt publishing/Mastering-Machine-Learning-Algorithms-Second-Edition</a>。我们也有来自我们丰富的书籍和视频目录的其他代码包，可在<a href="https://github.com/PacktPublishing/">https://github.com/PacktPublishing/</a>获得。看看他们！</p>

			<h2 id="_idParaDest-9" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor009"/>下载彩色图片</h2>

			<p class="normal">我们还提供了一个PDF文件，其中有本书中使用的截图/图表的彩色图像。可以在这里下载:<a href="https://static.packt-cdn.com/downloads/9781838820299_ColorImages.pdf">https://static . packt-cdn . com/downloads/9781838820299 _ color images . pdf</a>。</p>

			<h2 id="_idParaDest-10" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor010"/>习惯用法</h2>

			<p class="normal">本书通篇使用了许多文本约定。</p>

			<p class="normal"><code class="Code-In-Text--PACKT-">CodeInText</code>:表示文本中的码字、数据库表名、文件夹名、文件名、文件扩展名、路径名、伪URL、用户输入和Twitter句柄。例如，“将下载的<code class="Code-In-Text--PACKT-">WebStorm-10*.dmg</code>磁盘镜像文件挂载为系统中的另一个磁盘。”</p>

			<p class="normal">代码块设置如下:</p>

			<pre>ax[0].set_title('L1 regularization', fontsize=18)
ax[0].set_xlabel('Parameter', fontsize=18)
ax[0].set_ylabel(r'$|\theta_i|$', fontsize=18)</pre>

			<p class="normal">当我们希望将您的注意力吸引到代码块的特定部分时，相关的行或项目以粗体显示:</p>

			<pre>ax[0].set_title('L1 regularization', fontsize=18)
ax[0].set_xlabel('Parameter', fontsize=18)
ax[0].set_ylabel(r'$|\theta_i|$', fontsize=18)</pre>

			<p class="normal">任何命令行输入或输出都按如下方式编写:</p>

			<pre>pip install -U scikit-fuzzy</pre>

			<p class="normal"><strong class="bold">粗体</strong>:表示一个新的术语、一个重要的单词或你在屏幕上看到的单词，例如在菜单或对话框中，也可以像这样在文本中应用<a id="_idTextAnchor011"/> ear。例如:“从<strong class="bold">管理</strong>面板中选择<strong class="bold">系统信息</strong>。”</p>

			<div><div><p class="Information-Box--PACKT-">警告或重要提示如下所示。</p>

				</div>

			</div>

			<div><div><p>提示和技巧是这样出现的。</p>

				</div>

			</div>

			<h1 id="_idParaDest-11" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor012"/>取得联系</h1>

			<p class="normal">我们随时欢迎读者的反馈。</p>

			<p class="normal"><strong class="bold">总体反馈</strong>:如果您对本书的任何方面有疑问，请在邮件主题中提及书名，并发邮件至<code class="Code-In-Text--PACKT-">customercare@packtpub.com</code>联系我们。</p>

			<p class="normal"><strong class="bold">勘误表</strong>:虽然我们已经尽力确保内容的准确性，但错误还是会发生。如果你在这本书里发现了一个错误，请告诉我们，我们将不胜感激。请访问，<a href="http://www.packtpub.com/support/errata">www.packtpub.com/support/errata</a>，选择您的图书，点击勘误表提交表单链接，输入详细信息。</p>

			<p class="normal"><strong class="bold">盗版</strong>:如果您在互联网上遇到我们作品的任何形式的非法拷贝，如果您能提供我们的地址或网站名称，我们将不胜感激。请通过<code class="Code-In-Text--PACKT-">copyright@packt.com</code>联系我们，并提供材料链接。</p>

			<p class="normal">如果你有兴趣成为一名作家:如果有一个你擅长的主题，并且你有兴趣写一本书或者为一本书投稿，请访问<a href="http://authors.packtpub.com">authors.packtpub.com</a>。</p>

			<h2 id="_idParaDest-12" class="title" lang="en-GB" xml:lang="en-GB"><a id="_idTextAnchor013"/>评论</h2>

			<p class="normal">请留下评论。一旦你阅读并使用了这本书，为什么不在你购买它的网站上留下评论呢？潜在的读者可以看到并使用您不带偏见的意见来做出购买决定，我们Packt可以了解您对我们产品的看法，我们的作者可以看到您对他们的书的反馈。谢谢大家！</p>

			<p class="normal">欲了解更多关于Packt的信息，请访问packt.com。</p>

		</div>



</body></html>